{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "22942f7e-3446-4009-b551-cca7fcc25d73",
      "metadata": {},
      "source": [
        "# Reflexion\n",
        "\n",
        "[Reflexion](https://arxiv.org/abs/2303.11366) by Shinn, et. al., is an architecture designed to learn through verbal feedback and self-reflection. The agent explicitly critiques its responses for tasks to generate a higher quality final response, at the expense of longer execution time.\n",
        "\n",
        "![reflexion diagram](https://github.com/langchain-ai/langgraph/blob/main/examples/reflexion/img/reflexion.png)\n",
        "\n",
        "The paper outlines 3 main components:\n",
        "\n",
        "1. Actor (agent) with self-reflection\n",
        "2. External evaluator (task-specific, e.g. code compilation steps)\n",
        "3. Episodic memory that stores the reflections from (1).\n",
        "\n",
        "In their code, the last two components are very task-specific, so in this notebook, you will build the _actor_ in LangGraph.\n",
        "\n",
        "To skip to the graph definition, see the [Construct Graph section](#Construct-Graph) below."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "906edf48-7c81-48b8-8250-fdc34043d01b",
      "metadata": {},
      "source": [
        "## 0. Prerequisites\n",
        "\n",
        "Install `langgraph` (for the framework), `langchain_openai` (for the LLM), and `langchain` + `tavily-python` (for the search engine).\n",
        "\n",
        "We will use tavily search as a tool. You can get an API key [here](https://app.tavily.com/sign-in) or replace with a different tool of your choosing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4029de8f",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "01300b25",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"../../.env\", verbose=True)\n",
        "\n",
        "from loguru import logger\n",
        "logger.add('./reflexion.log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a917bb70-f84c-48e6-8d32-d14f9df2ca2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "def _set_if_undefined(var: str) -> None:\n",
        "    if os.environ.get(var):\n",
        "        return\n",
        "    os.environ[var] = getpass.getpass(var)\n",
        "\n",
        "\n",
        "# Optional: Configure tracing to visualize and debug the agent\n",
        "# _set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Agent_Reflexion\"\n",
        "\n",
        "# _set_if_undefined(\"ANTHROPIC_API_KEY\")\n",
        "# _set_if_undefined(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "567b6c4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "# llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\")\n",
        "# You could also use OpenAI or another provider\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af543598-52d0-4ec3-a05f-d2954ff793ee",
      "metadata": {},
      "source": [
        "## 1. Actor (with reflection)\n",
        "\n",
        "The main component of Reflexion is the \"actor\", which is an agent that reflects on its response and re-executes to improve based on self-critique. It's main sub-components include:\n",
        "1. Tools/tool execution\n",
        "2. Initial responder: generate an initial response (and self-reflection)\n",
        "3. Revisor: re-respond (and reflec) based on previous reflections\n",
        "\n",
        "We'll first define the tool execution context.\n",
        "\n",
        "#### Construct tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5a2ac853-b8a6-40de-b7fe-3f9f3c5ca4d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "\n",
        "search = TavilySearchAPIWrapper()\n",
        "tavily_tool = TavilySearchResults(api_wrapper=search, max_results=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "093fbaa0-9a71-4c32-9872-02a9aec9b35d",
      "metadata": {},
      "source": [
        "#### Initial responder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5fffa8d5-068a-4f0b-adfc-b4daf30ef294",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, ToolMessage\n",
        "from langchain_core.output_parsers.openai_tools import PydanticToolsParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field, ValidationError\n",
        "\n",
        "\n",
        "class Reflection(BaseModel):\n",
        "    missing: str = Field(description=\"Critique of what is missing.\")\n",
        "    superfluous: str = Field(description=\"Critique of what is superfluous\")\n",
        "\n",
        "\n",
        "class AnswerQuestion(BaseModel):\n",
        "    \"\"\"Answer the question. Provide an answer, reflection, and then follow up with search queries to improve the answer.\"\"\"\n",
        "\n",
        "    answer: str = Field(description=\"~250 word detailed answer to the question.\")\n",
        "    reflection: Reflection = Field(description=\"Your reflection on the initial answer.\")\n",
        "    search_queries: list[str] = Field(\n",
        "        description=\"1-3 search queries for researching improvements to address the critique of your current answer.\"\n",
        "    )\n",
        "\n",
        "\n",
        "class ResponderWithRetries:\n",
        "    def __init__(self, runnable, validator):\n",
        "        self.runnable = runnable\n",
        "        self.validator = validator\n",
        "\n",
        "    def respond(self, state: list):\n",
        "        response = []\n",
        "        for attempt in range(3):\n",
        "            response = self.runnable.invoke(\n",
        "                {\"messages\": state}, {\"tags\": [f\"attempt:{attempt}\"]}\n",
        "            )\n",
        "            try:\n",
        "                self.validator.invoke(response)\n",
        "                return response\n",
        "            except ValidationError as e:\n",
        "                state = state + [\n",
        "                    response,\n",
        "                    ToolMessage(\n",
        "                        content=f\"{repr(e)}\\n\\nPay close attention to the function schema.\\n\\n\"\n",
        "                        + self.validator.schema_json()\n",
        "                        + \" Respond by fixing all validation errors.\",\n",
        "                        tool_call_id=response.tool_calls[0][\"id\"],\n",
        "                    ),\n",
        "                ]\n",
        "        return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4a0264b8-ed2d-4f15-9d3c-085aa3a5edab",
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "actor_prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"You are expert researcher.\n",
        "Current time: {time}\n",
        "\n",
        "1. {first_instruction}\n",
        "2. Reflect and critique your answer. Be severe to maximize improvement.\n",
        "3. Recommend search queries to research information and improve your answer.\"\"\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        (\n",
        "            \"user\",\n",
        "            \"\\n\\n<system>Reflect on the user's original question and the\"\n",
        "            \" actions taken thus far. Respond using the {function_name} function.</reminder>\",\n",
        "        ),\n",
        "    ]\n",
        ").partial(\n",
        "    time=lambda: datetime.datetime.now().isoformat(),\n",
        ")\n",
        "initial_answer_chain = actor_prompt_template.partial(\n",
        "    first_instruction=\"Provide a detailed ~250 word answer.\",\n",
        "    function_name=AnswerQuestion.__name__,\n",
        ") | llm.bind_tools(tools=[AnswerQuestion])\n",
        "validator = PydanticToolsParser(tools=[AnswerQuestion])\n",
        "\n",
        "first_responder = ResponderWithRetries(\n",
        "    runnable=initial_answer_chain, validator=validator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5922e1fe-7533-4f41-8b1d-d812707c1968",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-08-04 00:37:18.759\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[34m\u001b[1m================================== Ai Message ==================================\n",
            "Tool Calls:\n",
            "  AnswerQuestion (call_8VFhKFpqDDMBvFGjgp9Fl8cK)\n",
            " Call ID: call_8VFhKFpqDDMBvFGjgp9Fl8cK\n",
            "  Args:\n",
            "    answer: Reflection is a crucial aspect of AI for several reasons. Firstly, it enables self-improvement. By reflecting on past actions, decisions, and outcomes, an AI system can identify what worked well and what didn't, thereby refining its algorithms and decision-making processes. This iterative learning process is fundamental for developing more accurate and efficient models. Secondly, reflection helps in error detection and correction. By reviewing its own performance, an AI can spot mistakes or biases in its functioning, which can then be addressed to enhance reliability and fairness. Thirdly, reflection aids in transparency and explainability. In complex AI systems, understanding the rationale behind certain decisions can be challenging. Reflective processes can help elucidate the internal workings of the AI, making it easier for humans to comprehend and trust its operations. Lastly, reflection supports adaptability. In dynamic environments where conditions and requirements constantly change, an AI's ability to reflect allows it to adapt its strategies and responses accordingly, ensuring sustained relevance and effectiveness.\n",
            "    reflection: {'missing': 'The initial answer lacks specific examples or case studies that illustrate the benefits of reflection in AI. Such examples could provide concrete evidence of how reflection has been successfully implemented in AI systems. Additionally, the answer does not address potential challenges or limitations associated with implementing reflective processes in AI.', 'superfluous': 'The explanation of why reflection is useful in AI is comprehensive but could be more concise. Some points are reiterated in different forms, which might be unnecessary. For instance, the aspects of self-improvement and error detection could be merged into a single point to avoid redundancy.'}\n",
            "    search_queries: ['examples of reflection in AI', 'challenges of implementing reflection in AI', 'benefits of reflective processes in AI systems']\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "example_question = \"Why is reflection useful in AI?\"\n",
        "initial = first_responder.respond([HumanMessage(content=example_question)])\n",
        "logger.debug(initial.pretty_repr())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4c7af31-b469-46fc-b441-0acb28515c7a",
      "metadata": {},
      "source": [
        "#### Revision\n",
        "\n",
        "The second part of the actor is a revision step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2605fd8d-c663-446f-ba25-751190195749",
      "metadata": {},
      "outputs": [],
      "source": [
        "revise_instructions = \"\"\"Revise your previous answer using the new information.\n",
        "    - You should use the previous critique to add important information to your answer.\n",
        "        - You MUST include numerical citations in your revised answer to ensure it can be verified.\n",
        "        - Add a \"References\" section to the bottom of your answer (which does not count towards the word limit). In form of:\n",
        "            - [1] https://example.com\n",
        "            - [2] https://example.com\n",
        "    - You should use the previous critique to remove superfluous information from your answer and make SURE it is not more than 250 words.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Extend the initial answer schema to include references.\n",
        "# Forcing citation in the model encourages grounded responses\n",
        "class ReviseAnswer(AnswerQuestion):\n",
        "    \"\"\"Revise your original answer to your question. Provide an answer, reflection,\n",
        "\n",
        "    cite your reflection with references, and finally\n",
        "    add search queries to improve the answer.\"\"\"\n",
        "\n",
        "    references: list[str] = Field(\n",
        "        description=\"Citations motivating your updated answer.\"\n",
        "    )\n",
        "\n",
        "\n",
        "revision_chain = actor_prompt_template.partial(\n",
        "    first_instruction=revise_instructions,\n",
        "    function_name=ReviseAnswer.__name__,\n",
        ") | llm.bind_tools(tools=[ReviseAnswer])\n",
        "revision_validator = PydanticToolsParser(tools=[ReviseAnswer])\n",
        "\n",
        "revisor = ResponderWithRetries(runnable=revision_chain, validator=revision_validator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0479b98d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answer': \"Reflection is a crucial aspect of AI for several reasons. Firstly, it enables self-improvement. By reflecting on past actions, decisions, and outcomes, an AI system can identify what worked well and what didn't, thereby refining its algorithms and decision-making processes. This iterative learning process is fundamental for developing more accurate and efficient models. Secondly, reflection helps in error detection and correction. By reviewing its own performance, an AI can spot mistakes or biases in its functioning, which can then be addressed to enhance reliability and fairness. Thirdly, reflection aids in transparency and explainability. In complex AI systems, understanding the rationale behind certain decisions can be challenging. Reflective processes can help elucidate the internal workings of the AI, making it easier for humans to comprehend and trust its operations. Lastly, reflection supports adaptability. In dynamic environments where conditions and requirements constantly change, an AI's ability to reflect allows it to adapt its strategies and responses accordingly, ensuring sustained relevance and effectiveness.\",\n",
              " 'reflection': {'missing': 'The initial answer lacks specific examples or case studies that illustrate the benefits of reflection in AI. Such examples could provide concrete evidence of how reflection has been successfully implemented in AI systems. Additionally, the answer does not address potential challenges or limitations associated with implementing reflective processes in AI.',\n",
              "  'superfluous': 'The explanation of why reflection is useful in AI is comprehensive but could be more concise. Some points are reiterated in different forms, which might be unnecessary. For instance, the aspects of self-improvement and error detection could be merged into a single point to avoid redundancy.'},\n",
              " 'search_queries': ['examples of reflection in AI',\n",
              "  'challenges of implementing reflection in AI',\n",
              "  'benefits of reflective processes in AI systems']}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial.tool_calls[0][\"args\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6fd51f17-c0b0-44b6-90e2-55a66cb8f5a7",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-08-04 00:41:19.987\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[34m\u001b[1mcontent='' additional_kwargs={'tool_calls': [{'id': 'call_dBsVLeqcE1qIlWGq8PWtbfKN', 'function': {'arguments': '{\"answer\": \"Reflection is a crucial aspect of AI for several reasons. Firstly, it enables self-improvement. By reflecting on past actions, decisions, and outcomes, an AI system can identify what worked well and what didn\\'t, thereby refining its algorithms and decision-making processes. This iterative learning process is fundamental for developing more accurate and efficient models. Secondly, reflection helps in error detection and correction. By reviewing its own performance, an AI can spot mistakes or biases in its functioning, which can then be addressed to enhance reliability and fairness. Thirdly, reflection aids in transparency and explainability. In complex AI systems, understanding the rationale behind certain decisions can be challenging. Reflective processes can help elucidate the internal workings of the AI, making it easier for humans to comprehend and trust its operations. Lastly, reflection supports adaptability. In dynamic environments where conditions and requirements constantly change, an AI\\'s ability to reflect allows it to adapt its strategies and responses accordingly, ensuring sustained relevance and effectiveness.\", \"reflection\": {\"missing\": \"The initial answer lacks specific examples or case studies that illustrate the benefits of reflection in AI. Such examples could provide concrete evidence of how reflection has been successfully implemented in AI systems. Additionally, the answer does not address potential challenges or limitations associated with implementing reflective processes in AI.\", \"superfluous\": \"The explanation of why reflection is useful in AI is comprehensive but could be more concise. Some points are reiterated in different forms, which might be unnecessary. For instance, the aspects of self-improvement and error detection could be merged into a single point to avoid redundancy.\"}, \"search_queries\": [\"examples of reflection in AI\", \"challenges of implementing reflection in AI\", \"benefits of reflective processes in AI systems\"], \"references\": [\"https://www.unite.ai/ais-inner-dialogue-how-self-reflection-enhances-chatbots-and-virtual-assistants/\", \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/\", \"https://www.nature.com/articles/s42256-020-00281-z\", \"https://www.nature.com/articles/s42256-021-00435-7\", \"https://teachingresources.stanford.edu/resources/enhancing-reflective-practices-with-ai/\"]}', 'name': 'ReviseAnswer'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 477, 'prompt_tokens': 3149, 'total_tokens': 3626}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-d22320fe-4a52-499d-a9e7-fc960abb5598-0' tool_calls=[{'name': 'ReviseAnswer', 'args': {'answer': \"Reflection is a crucial aspect of AI for several reasons. Firstly, it enables self-improvement. By reflecting on past actions, decisions, and outcomes, an AI system can identify what worked well and what didn't, thereby refining its algorithms and decision-making processes. This iterative learning process is fundamental for developing more accurate and efficient models. Secondly, reflection helps in error detection and correction. By reviewing its own performance, an AI can spot mistakes or biases in its functioning, which can then be addressed to enhance reliability and fairness. Thirdly, reflection aids in transparency and explainability. In complex AI systems, understanding the rationale behind certain decisions can be challenging. Reflective processes can help elucidate the internal workings of the AI, making it easier for humans to comprehend and trust its operations. Lastly, reflection supports adaptability. In dynamic environments where conditions and requirements constantly change, an AI's ability to reflect allows it to adapt its strategies and responses accordingly, ensuring sustained relevance and effectiveness.\", 'reflection': {'missing': 'The initial answer lacks specific examples or case studies that illustrate the benefits of reflection in AI. Such examples could provide concrete evidence of how reflection has been successfully implemented in AI systems. Additionally, the answer does not address potential challenges or limitations associated with implementing reflective processes in AI.', 'superfluous': 'The explanation of why reflection is useful in AI is comprehensive but could be more concise. Some points are reiterated in different forms, which might be unnecessary. For instance, the aspects of self-improvement and error detection could be merged into a single point to avoid redundancy.'}, 'search_queries': ['examples of reflection in AI', 'challenges of implementing reflection in AI', 'benefits of reflective processes in AI systems'], 'references': ['https://www.unite.ai/ais-inner-dialogue-how-self-reflection-enhances-chatbots-and-virtual-assistants/', 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/', 'https://www.nature.com/articles/s42256-020-00281-z', 'https://www.nature.com/articles/s42256-021-00435-7', 'https://teachingresources.stanford.edu/resources/enhancing-reflective-practices-with-ai/']}, 'id': 'call_dBsVLeqcE1qIlWGq8PWtbfKN', 'type': 'tool_call'}] usage_metadata={'input_tokens': 3149, 'output_tokens': 477, 'total_tokens': 3626}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "revised = revisor.respond(\n",
        "    [\n",
        "        HumanMessage(content=example_question),\n",
        "        initial,\n",
        "        ToolMessage(\n",
        "            tool_call_id=initial.tool_calls[0][\"id\"],\n",
        "            content=json.dumps(\n",
        "                tavily_tool.invoke(\n",
        "                    {\"query\": initial.tool_calls[0][\"args\"][\"search_queries\"][0]}\n",
        "                )\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e9ea2e09",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-08-04 00:42:19.326\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[34m\u001b[1m================================== Ai Message ==================================\n",
            "Tool Calls:\n",
            "  ReviseAnswer (call_dBsVLeqcE1qIlWGq8PWtbfKN)\n",
            " Call ID: call_dBsVLeqcE1qIlWGq8PWtbfKN\n",
            "  Args:\n",
            "    answer: Reflection is a crucial aspect of AI for several reasons. Firstly, it enables self-improvement. By reflecting on past actions, decisions, and outcomes, an AI system can identify what worked well and what didn't, thereby refining its algorithms and decision-making processes. This iterative learning process is fundamental for developing more accurate and efficient models. Secondly, reflection helps in error detection and correction. By reviewing its own performance, an AI can spot mistakes or biases in its functioning, which can then be addressed to enhance reliability and fairness. Thirdly, reflection aids in transparency and explainability. In complex AI systems, understanding the rationale behind certain decisions can be challenging. Reflective processes can help elucidate the internal workings of the AI, making it easier for humans to comprehend and trust its operations. Lastly, reflection supports adaptability. In dynamic environments where conditions and requirements constantly change, an AI's ability to reflect allows it to adapt its strategies and responses accordingly, ensuring sustained relevance and effectiveness.\n",
            "    reflection: {'missing': 'The initial answer lacks specific examples or case studies that illustrate the benefits of reflection in AI. Such examples could provide concrete evidence of how reflection has been successfully implemented in AI systems. Additionally, the answer does not address potential challenges or limitations associated with implementing reflective processes in AI.', 'superfluous': 'The explanation of why reflection is useful in AI is comprehensive but could be more concise. Some points are reiterated in different forms, which might be unnecessary. For instance, the aspects of self-improvement and error detection could be merged into a single point to avoid redundancy.'}\n",
            "    search_queries: ['examples of reflection in AI', 'challenges of implementing reflection in AI', 'benefits of reflective processes in AI systems']\n",
            "    references: ['https://www.unite.ai/ais-inner-dialogue-how-self-reflection-enhances-chatbots-and-virtual-assistants/', 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/', 'https://www.nature.com/articles/s42256-020-00281-z', 'https://www.nature.com/articles/s42256-021-00435-7', 'https://teachingresources.stanford.edu/resources/enhancing-reflective-practices-with-ai/']\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "logger.debug(revised.pretty_repr())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cf86d9d",
      "metadata": {},
      "source": [
        "## Create Tool Node\n",
        "\n",
        "Next, create a node to execute the tool calls. While we give the LLMs different schema names (and use those for validation), we want them both to route to the same tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fccd6a17",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.tools import StructuredTool\n",
        "\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "\n",
        "def run_queries(search_queries: list[str], **kwargs):\n",
        "    \"\"\"Run the generated queries.\"\"\"\n",
        "    return tavily_tool.batch([{\"query\": query} for query in search_queries])\n",
        "\n",
        "\n",
        "tool_node = ToolNode(\n",
        "    [\n",
        "        StructuredTool.from_function(run_queries, name=AnswerQuestion.__name__),\n",
        "        StructuredTool.from_function(run_queries, name=ReviseAnswer.__name__),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e623a6c9-b69b-438c-9e6e-34a8883e0623",
      "metadata": {},
      "source": [
        "## Construct Graph\n",
        "\n",
        "\n",
        "Now we can wire all our components together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3c57318f-a30c-4dbd-9b88-f2633e8cb3b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "from langgraph.graph import END, MessageGraph, START\n",
        "\n",
        "MAX_ITERATIONS = 5\n",
        "builder = MessageGraph()\n",
        "builder.add_node(\"draft\", first_responder.respond)\n",
        "\n",
        "\n",
        "builder.add_node(\"execute_tools\", tool_node)\n",
        "builder.add_node(\"revise\", revisor.respond)\n",
        "# draft -> execute_tools\n",
        "builder.add_edge(\"draft\", \"execute_tools\")\n",
        "# execute_tools -> revise\n",
        "builder.add_edge(\"execute_tools\", \"revise\")\n",
        "\n",
        "# Define looping logic:\n",
        "\n",
        "\n",
        "def _get_num_iterations(state: list):\n",
        "    i = 0\n",
        "    for m in state[::-1]:\n",
        "        if m.type not in {\"tool\", \"ai\"}:\n",
        "            break\n",
        "        i += 1\n",
        "    return i\n",
        "\n",
        "\n",
        "def event_loop(state: list) -> Literal[\"execute_tools\", \"__end__\"]:\n",
        "    # in our case, we'll just stop after N plans\n",
        "    num_iterations = _get_num_iterations(state)\n",
        "    if num_iterations > MAX_ITERATIONS:\n",
        "        return END\n",
        "    return \"execute_tools\"\n",
        "\n",
        "\n",
        "# revise -> execute_tools OR end\n",
        "builder.add_conditional_edges(\"revise\", event_loop)\n",
        "builder.add_edge(START, \"draft\")\n",
        "graph = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7541f82c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2634a3ea-7423-4579-9f4e-390e439c3209",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-08-04 00:43:21.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mStep 0\u001b[0m\n",
            "\u001b[32m2024-08-04 00:43:21.403\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[34m\u001b[1m================================ Human Message =================================\n",
            "\n",
            "How should we handle the climate crisis?\u001b[0m\n",
            "\u001b[32m2024-08-04 00:43:45.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mStep 1\u001b[0m\n",
            "\u001b[32m2024-08-04 00:43:45.035\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[34m\u001b[1m================================== Ai Message ==================================\n",
            "Tool Calls:\n",
            "  AnswerQuestion (call_MfKa4iFYXva9f1RpraTODbgR)\n",
            " Call ID: call_MfKa4iFYXva9f1RpraTODbgR\n",
            "  Args:\n",
            "    answer: Addressing the climate crisis requires a multifaceted approach that involves coordinated efforts at the individual, community, national, and global levels. Here are some key strategies to handle the climate crisis effectively:\n",
            "\n",
            "1. **Policy and Governance**: Governments must implement strong climate policies that promote renewable energy, energy efficiency, and sustainable practices. This includes setting ambitious targets for reducing greenhouse gas emissions, investing in green infrastructure, and enforcing regulations that limit pollution.\n",
            "\n",
            "2. **Renewable Energy Transition**: Transitioning from fossil fuels to renewable energy sources such as solar, wind, and hydroelectric power is crucial. This reduces dependency on non-renewable resources and helps lower carbon emissions.\n",
            "\n",
            "3. **Conservation and Biodiversity**: Protecting natural ecosystems and biodiversity is vital. Forests, wetlands, and oceans act as carbon sinks, absorbing CO2 from the atmosphere. Efforts should be made to prevent deforestation, promote reforestation, and conserve marine habitats.\n",
            "\n",
            "4. **Innovation and Technology**: Investing in research and development of new technologies that can mitigate climate change is essential. This includes advancements in carbon capture and storage, electric vehicles, and sustainable agriculture practices.\n",
            "\n",
            "5. **Public Awareness and Education**: Educating the public about the impacts of climate change and promoting sustainable lifestyle choices can drive collective action. Grassroots movements and environmental advocacy can influence policy changes and corporate behavior.\n",
            "\n",
            "6. **International Cooperation**: Climate change is a global issue that requires international collaboration. Countries need to work together through agreements like the Paris Accord to share knowledge, resources, and strategies for combating climate change.\n",
            "\n",
            "7. **Adaptation and Resilience**: Developing strategies to adapt to the already changing climate is crucial. This includes building resilient infrastructure, developing early warning systems for extreme weather events, and supporting communities that are most vulnerable to climate impacts.\n",
            "    reflection: {'missing': \"The answer could benefit from more specific examples and case studies to illustrate the strategies mentioned. Additionally, it doesn't address the economic and social dimensions of the climate crisis in depth, such as the impact on jobs, poverty, and health.\", 'superfluous': 'The answer might be too broad in its current state, lacking focus on the most urgent or impactful actions. Some points might overlap, such as public awareness and education, which could be combined for conciseness.', 'search_queries': ['examples of successful climate policies', 'impact of renewable energy transition on jobs', 'case studies on climate adaptation and resilience']}\u001b[0m\n"
          ]
        },
        {
          "ename": "ValidationError",
          "evalue": "1 validation error for AnswerQuestionSchema\nsearch_queries\n  field required (type=value_error.missing)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m events \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m      2\u001b[0m     [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow should we handle the climate crisis?\u001b[39m\u001b[38;5;124m\"\u001b[39m)],\n\u001b[1;32m      3\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(events):\n\u001b[1;32m      6\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(step[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpretty_repr())\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/langgraph/pregel/__init__.py:963\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[1;32m    962\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m--> 963\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/langgraph/pregel/__init__.py:1489\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(done, inflight, step)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m   1488\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1489\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1492\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1494\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/langgraph/pregel/retry.py:72\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     70\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/langchain_core/runnables/base.py:2873\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2869\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m   2870\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2871\u001b[0m )\n\u001b[1;32m   2872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2873\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2875\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/langgraph/utils.py:95\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[1;32m     94\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m---> 95\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/langgraph/prebuilt/tool_node.py:85\u001b[0m, in \u001b[0;36mToolNode._func\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ToolMessage(\n\u001b[1;32m     81\u001b[0m         content\u001b[38;5;241m=\u001b[39mstr_output(output), name\u001b[38;5;241m=\u001b[39mcall[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m], tool_call_id\u001b[38;5;241m=\u001b[39mcall[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     82\u001b[0m     )\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m---> 85\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39mexecutor\u001b[38;5;241m.\u001b[39mmap(run_one, message\u001b[38;5;241m.\u001b[39mtool_calls)]\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/concurrent/futures/_base.py:609\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/concurrent/futures/_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/langchain_core/runnables/config.py:559\u001b[0m, in \u001b[0;36mContextThreadPoolExecutor.map.<locals>._wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontexts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/langgraph/prebuilt/tool_node.py:79\u001b[0m, in \u001b[0;36mToolNode._func.<locals>.run_one\u001b[0;34m(call)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_one\u001b[39m(call: ToolCall):\n\u001b[0;32m---> 79\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_by_name\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ToolMessage(\n\u001b[1;32m     81\u001b[0m         content\u001b[38;5;241m=\u001b[39mstr_output(output), name\u001b[38;5;241m=\u001b[39mcall[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m], tool_call_id\u001b[38;5;241m=\u001b[39mcall[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     82\u001b[0m     )\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/langchain_core/tools.py:427\u001b[0m, in \u001b[0;36mBaseTool.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, Dict, ToolCall],\n\u001b[1;32m    423\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    425\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    426\u001b[0m     tool_input, kwargs \u001b[38;5;241m=\u001b[39m _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/langchain_core/tools.py:615\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[1;32m    614\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[1;32m    616\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[1;32m    617\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/langchain_core/tools.py:578\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m    577\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m--> 578\u001b[0m tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    580\u001b[0m     tool_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/langchain_core/tools.py:501\u001b[0m, in \u001b[0;36mBaseTool._to_args_and_kwargs\u001b[0;34m(self, tool_input)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_args_and_kwargs\u001b[39m(\u001b[38;5;28mself\u001b[39m, tool_input: Union[\u001b[38;5;28mstr\u001b[39m, Dict]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tuple, Dict]:\n\u001b[0;32m--> 501\u001b[0m     tool_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/langchain_core/tools.py:454\u001b[0m, in \u001b[0;36mBaseTool._parse_input\u001b[0;34m(self, tool_input)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43minput_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    456\u001b[0m             k: \u001b[38;5;28mgetattr\u001b[39m(result, k)\n\u001b[1;32m    457\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdict()\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    458\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m tool_input\n\u001b[1;32m    459\u001b[0m         }\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tool_input\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/pydantic/v1/main.py:526\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m    524\u001b[0m         exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m expected dict not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ValidationError([ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY)], \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/x/lib/python3.9/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for AnswerQuestionSchema\nsearch_queries\n  field required (type=value_error.missing)"
          ]
        }
      ],
      "source": [
        "events = graph.stream(\n",
        "    [HumanMessage(content=\"How should we handle the climate crisis?\")],\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for i, step in enumerate(events):\n",
        "    logger.info(f\"Step {i}\")\n",
        "    logger.debug(step[-1].pretty_repr())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7159e30c-728e-480d-8252-915404cc756d",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "Congrats on building a Reflexion actor! I'll leave you with a few observations to save you some time when choosing which parts of this agent to adapt to your workflow:\n",
        "1. This agent trades off execution time for quality. It explicitly forces the agent to critique and revise the output over several steps, which usually (not always) increases the response quality but takes much longer to return a final answer\n",
        "2. The 'reflections' can be paired with additional external feedback (such as validators), to further guide the actor.\n",
        "3. In the paper, 1 environment (AlfWorld) uses external memory. It does this by storing summaries of the reflections to an external store and using them in subsequent trials/invocations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39e44dd6",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
