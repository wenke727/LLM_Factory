{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env', verbose=True)\n",
    "\n",
    "from typing import Literal, TypedDict, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from langgraph.graph import StateGraph, END, MessageGraph\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, we will first define the tools we want to use. For this simple example, we will use a web search tool. However, it is really easy to create your own tools - see documentation here on how to do that.\n",
    "\n",
    "\n",
    "We can now wrap these tools in a simple LangGraph ToolNode. This class receives the list of messages (containing tool_calls, calls the tool(s) the LLM has requested to run, and returns the output as new ToolMessage(s).\n",
    "\n",
    "After we've done this, we should make sure the model knows that it has these tools available to call. We can do this by converting the LangChain tools into the format for OpenAI tool calling using the bind_tools() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [TavilySearchResults(max_results=1)]\n",
    "tool_node = ToolNode(tools)\n",
    "model = ChatOpenAI(name='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "model = model.bind_tools(tools)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agent State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we'll use the more general StateGraph. This graph is parameterized by a state object that it passes around to each node. Remember that each node then returns operations to update that state. These operations can either SET specific attributes on the state (e.g. overwrite the existing values) or ADD to the existing attribute. Whether to set or add is denoted by annotating the state object you construct the graph with.\n",
    "\n",
    "For this example, the state we will track will just be a list of messages. We want each node to just add messages to that list. Therefore, we will use a TypedDict with one key (messages) and annotate it so that we always add to the messages key when updating it using the is always added to with the second parameter (operator.add). (Note: the state can be any type, including pydantic BaseModel's)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在你提到的代码段中，`AgentState` 使用了 Python 的 `TypedDict` 和 `Annotated` 类型，这些都是类型注解工具，用来帮助定义字典的键和相关的类型信息，以及如何处理这些类型的更新。这个代码主要是为了设定一个状态对象，这个状态对象被用于 LangChain 中的状态图（StateGraph）中。下面我会详细解释每个部分的意义和作用：\n",
    "\n",
    "### TypedDict\n",
    "`TypedRetypedDict` 是 Python 的一个类型注解工具，它允许你为字典的每个键指定应该有的类型。这是非常有用的，特别是在需要清晰定义字典结构的场景中，比如 API 的数据传输对象（DTOs）或复杂的配置对象。在你的代码中，`TypedDict` 用来定义一个名为 `AgentState` 的字典类型，这个字典有一个键 `messages`。\n",
    "\n",
    "### Annotated\n",
    "`Annotated` 是 Python 类型系统的一部分，用于为已存在的类型添加元数据。在你的代码中，`Annotated` 被用来给 `list` 类型附加一个特定的函数 `add_messages`，这个函数定义了当状态更新时应如何处理这个列表。\n",
    "\n",
    "### add_messages 函数\n",
    "`add_messages` 函数定义了如何更新 `messages` 这个列表。通常，在不同的节点中，你可能需要添加消息而不是替换现有的消息，所以这个函数确保每次更新状态时，新的消息将被添加到现有的列表中，而不是覆盖它。\n",
    "\n",
    "### 将它们组合起来\n",
    "结合使用 `TypedDict` 和 `Annotated` 允许你详细地控制如何更新 `AgentState` 中的 `messages` 列表。每次状态更新时，都会调用 `add_messages` 函数来处理新旧列表的合并，这确保了状态的连续性和数据的完整性。\n",
    "\n",
    "这种方式在构建需要维护复杂状态的应用程序时非常有用，比如聊天机器人或其他需要追踪对话状态的交互式应用程序。\n",
    "\n",
    "希望这样的解释可以帮助你更好地理解这些代码的作用！如果你有任何疑问或需要进一步的解释，请随时提问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_messages(left: list, right: list):\n",
    "    \"\"\" Add-don't-overwrite\"\"\"\n",
    "    return left + right\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The `add_messages` function within the annotation defines\n",
    "    # *how* updates should be merged into the state.\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to define a few different nodes in our graph. In langgraph, a node can be either a regular python function or a runnable.\n",
    "\n",
    "There are two main nodes we need for this:\n",
    "\n",
    "The agent: responsible for deciding what (if any) actions to take.\n",
    "A function to invoke tools: if the agent decides to take an action, this node will then execute that action. We already defined this above.\n",
    "We will also need to define some edges. Some of these edges may be conditional. The reason they are conditional is that the destination depends on the contents of the graph's State.\n",
    "\n",
    "The path that is taken is not known until that node is run (the LLM decides). For our use case, we will need one of each type of edge:\n",
    "\n",
    "Conditional Edge: after the agent is called, we should either:\n",
    "\n",
    "a. Run tools if the agent said to take an action, OR\n",
    "\n",
    "b. Finish (respond to the user) if the agent did not ask to run tools\n",
    "\n",
    "Normal Edge: after the tools are invoked, the graph should always return to the agent to decide what to do next\n",
    "\n",
    "Let's define the nodes, as well as a function to define the conditional edge to take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    messages = state['messages']\n",
    "    last_msg = messages[-1]\n",
    "\n",
    "    if last_msg.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    return \"__end__\"\n",
    "\n",
    "def call_model(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    return {'messages': [response]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now put it all together and define the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node('tools', tool_node)\n",
    "\n",
    "workflow.set_entry_point('agent')\n",
    "\n",
    "workflow.add_conditional_edges(\"agent\", should_continue)\n",
    "workflow.add_edge(\"tools\", 'agent')\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use it! This now exposes the same interface as all other LangChain runnables. This runnable accepts a list of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langsmith.client:Failed to get info from https://api.smith.langchain.com: SSLError(MaxRetryError(\"HTTPSConnectionPool(host='api.smith.langchain.com', port=443): Max retries exceeded with url: /info (Caused by SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1129)')))\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"What's the weather in Nanshan, Shenzhen\"),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_NNxFyMnAsP3bIGheLstAaLJN', 'function': {'arguments': '{\"query\":\"weather in Nanshan, Shenzhen\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 92, 'total_tokens': 117}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2c262894-2ca1-45ac-92f1-8d4ec1cecac3-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Nanshan, Shenzhen'}, 'id': 'call_NNxFyMnAsP3bIGheLstAaLJN'}], usage_metadata={'input_tokens': 92, 'output_tokens': 25, 'total_tokens': 117}),\n",
       "  ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'Shenzhen\\', \\'region\\': \\'Guangdong\\', \\'country\\': \\'China\\', \\'lat\\': 22.53, \\'lon\\': 114.13, \\'tz_id\\': \\'Asia/Hong_Kong\\', \\'localtime_epoch\\': 1718118490, \\'localtime\\': \\'2024-06-11 23:08\\'}, \\'current\\': {\\'last_updated_epoch\\': 1718118000, \\'last_updated\\': \\'2024-06-11 23:00\\', \\'temp_c\\': 28.2, \\'temp_f\\': 82.8, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 9.4, \\'wind_kph\\': 15.1, \\'wind_degree\\': 170, \\'wind_dir\\': \\'S\\', \\'pressure_mb\\': 1007.0, \\'pressure_in\\': 29.74, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 94, \\'cloud\\': 0, \\'feelslike_c\\': 34.5, \\'feelslike_f\\': 94.1, \\'windchill_c\\': 27.2, \\'windchill_f\\': 81.0, \\'heatindex_c\\': 32.1, \\'heatindex_f\\': 89.7, \\'dewpoint_c\\': 25.3, \\'dewpoint_f\\': 77.6, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 1.0, \\'gust_mph\\': 13.9, \\'gust_kph\\': 22.3}}\"}]', name='tavily_search_results_json', tool_call_id='call_NNxFyMnAsP3bIGheLstAaLJN'),\n",
       "  AIMessage(content='The current weather in Nanshan, Shenzhen is as follows:\\n- Temperature: 28.2°C (82.8°F)\\n- Condition: Clear\\n- Wind: 15.1 km/h from the south\\n- Humidity: 94%\\n- Pressure: 1007.0 mb\\n- Visibility: 10.0 km\\n- UV Index: 1.0\\n\\nFor more details, you can visit [Weather API](https://www.weatherapi.com/).', response_metadata={'token_usage': {'completion_tokens': 101, 'prompt_tokens': 535, 'total_tokens': 636}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e3687b26-a677-4e1c-8a7c-82d785723c92-0', usage_metadata={'input_tokens': 535, 'output_tokens': 101, 'total_tokens': 636})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {'messages': [HumanMessage(\"What's the weather in Nanshan, Shenzhen\")]}\n",
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
