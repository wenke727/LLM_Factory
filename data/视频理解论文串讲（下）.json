{
    "font_size": 0.4,
    "font_color": "#FFFFFF",
    "background_alpha": 0.5,
    "background_color": "#9C27B0",
    "Stroke": "none",
    "body": [
        {
            "from": 1.5,
            "to": 2.3,
            "location": 2,
            "content": " 大家好 \n(欢迎加入字幕组）"
        },
        {
            "from": 2.33,
            "to": 4.3,
            "location": 2,
            "content": " 上次呢我们讲完了上半部分啊 "
        },
        {
            "from": 4.3,
            "to": 6.27,
            "location": 2,
            "content": " 就是2D网络和一些双流网络 "
        },
        {
            "from": 6.27,
            "to": 7.73,
            "location": 2,
            "content": " 以及他们的变体啊 "
        },
        {
            "from": 7.73,
            "to": 9.8,
            "location": 2,
            "content": " 今天呢我们就来讲一下下半部分 "
        },
        {
            "from": 9.9,
            "to": 12,
            "location": 2,
            "content": " 就是3 d 网络和Video transformer啊 "
        },
        {
            "from": 12,
            "to": 13.87,
            "location": 2,
            "content": " 在视频理解领域里的应用 "
        },
        {
            "from": 14.53,
            "to": 16.7,
            "location": 2,
            "content": " 那上次其实我们也讲了很多工作了啊 "
        },
        {
            "from": 16.7,
            "to": 18.37,
            "location": 2,
            "content": " 他们的这个效果呢也都不错 "
        },
        {
            "from": 18.47,
            "to": 20.3,
            "location": 2,
            "content": " 而且呢用上这种光流以后呢 "
        },
        {
            "from": 20.3,
            "to": 21.9,
            "location": 2,
            "content": " 听起来啊也很合理 "
        },
        {
            "from": 22.13,
            "to": 24.47,
            "location": 2,
            "content": " 一个网络呢去学习这种图像特征啊 "
        },
        {
            "from": 24.47,
            "to": 26.77,
            "location": 2,
            "content": " 另外一个网络呢去学习这种运动特征 "
        },
        {
            "from": 27.17,
            "to": 28.7,
            "location": 2,
            "content": " 各司其职互不打扰啊 "
        },
        {
            "from": 28.7,
            "to": 30.2,
            "location": 2,
            "content": " 最后结果呢也非常好 "
        },
        {
            "from": 30.5,
            "to": 31.53,
            "location": 2,
            "content": " 那为什么研究者 "
        },
        {
            "from": 31.53,
            "to": 33.13,
            "location": 2,
            "content": " 这么想把这个双流网络 "
        },
        {
            "from": 33.13,
            "to": 33.87,
            "location": 2,
            "content": " 替换掉啊 "
        },
        {
            "from": 33.87,
            "to": 36.33,
            "location": 2,
            "content": " 想用这个3 d 卷机神经网络来做呢卷积"
        },
        {
            "from": 36.77,
            "to": 37.77,
            "location": 2,
            "content": " 其实主要原因呢 "
        },
        {
            "from": 37.77,
            "to": 39.6,
            "location": 2,
            "content": " 就在这个光流抽取这一块 "
        },
        {
            "from": 39.87,
            "to": 40.53,
            "location": 2,
            "content": " 比如说呢 "
        },
        {
            "from": 40.53,
            "to": 43.17,
            "location": 2,
            "content": " 大家之前常用的一种算光流的方法啊 "
        },
        {
            "from": 43.17,
            "to": 45.13,
            "location": 2,
            "content": " 叫 tvl one这种算法 "
        },
        {
            "from": 45.47,
            "to": 45.8,
            "location": 2,
            "content": " 他呢 "
        },
        {
            "from": 45.8,
            "to": 47.87,
            "location": 2,
            "content": " 如果我们使用一种 gpu 的实现的话 "
        },
        {
            "from": 47.87,
            "to": 50.17,
            "location": 2,
            "content": " 他只需要0.06秒啊 "
        },
        {
            "from": 50.17,
            "to": 52.2,
            "location": 2,
            "content": " 就能处理一个视频帧的一个对 "
        },
        {
            "from": 52.73,
            "to": 55.67,
            "location": 2,
            "content": " 你乍一听呢可能觉得啊0:06秒挺快的呀 "
        },
        {
            "from": 55.9,
            "to": 57.93,
            "location": 2,
            "content": " 但是呢如果你想一下这个视频数据集 "
        },
        {
            "from": 57.93,
            "to": 58.9,
            "location": 2,
            "content": " 他有多大 "
        },
        {
            "from": 58.9,
            "to": 59.7,
            "location": 2,
            "content": " 你就会发现 "
        },
        {
            "from": 59.7,
            "to": 61.8,
            "location": 2,
            "content": " 提前抽取这个光流是一个非常耗时"
        },
        {
            "from": 61.8,
            "to": 62.6,
            "location": 2,
            "content": " 的事情 "
        },
        {
            "from": 63.1,
            "to": 65.1,
            "location": 2,
            "content": " 那我们先拿一个比较小的数据集啊 "
        },
        {
            "from": 65.1,
            "to": 66.6,
            "location": 2,
            "content": " ucf 101来说的话 "
        },
        {
            "from": 66.6,
            "to": 68.17,
            "location": 2,
            "content": " 他呢就有1万个视频 "
        },
        {
            "from": 68.4,
            "to": 71.17,
            "location": 2,
            "content": " 那 ucf 101他这个平均视频长度呢 "
        },
        {
            "from": 71.17,
            "to": 72.33,
            "location": 2,
            "content": " 大概是6秒啊 "
        },
        {
            "from": 72.33,
            "to": 75.1,
            "location": 2,
            "content": " 如果我们按这个帧率30 fps 来算的话呢 "
        },
        {
            "from": 75.1,
            "to": 75.73,
            "location": 2,
            "content": " 那最后呢 "
        },
        {
            "from": 75.73,
            "to": 77.2,
            "location": 2,
            "content": " 这个 ucf 101数据集 "
        },
        {
            "from": 77.2,
            "to": 79.8,
            "location": 2,
            "content": " 大概就有180万张这个视频帧 "
        },
        {
            "from": 80.13,
            "to": 82.7,
            "location": 2,
            "content": " 那如果我们把这个180万和这个0.06秒 "
        },
        {
            "from": 82.7,
            "to": 85.67,
            "location": 2,
            "content": " 一乘你就会发现如果你只有一个 gpu "
        },
        {
            "from": 85.67,
            "to": 87.13,
            "location": 2,
            "content": " 而且不做什么优化的话呢 "
        },
        {
            "from": 87.13,
            "to": 89.33,
            "location": 2,
            "content": " 你最后需要1.5天的时间去抽取 "
        },
        {
            "from": 89.33,
            "to": 90.17,
            "location": 2,
            "content": " 这个光流 "
        },
        {
            "from": 90.73,
            "to": 91.17,
            "location": 2,
            "content": " 那现在啊 "
        },
        {
            "from": 91.17,
            "to": 91.93,
            "location": 2,
            "content": " 如果我们换了一个 "
        },
        {
            "from": 91.93,
            "to": 93.33,
            "location": 2,
            "content": " 稍微大一点的数据集啊 "
        },
        {
            "from": 93.33,
            "to": 95.37,
            "location": 2,
            "content": " 就是大家常用的这个 k400数据集 "
        },
        {
            "from": 95.37,
            "to": 97.27,
            "location": 2,
            "content": " 它里面呢有24万个视频 "
        },
        {
            "from": 97.5,
            "to": 98.47,
            "location": 2,
            "content": " 那这个时候呢 "
        },
        {
            "from": 98.53,
            "to": 100.97,
            "location": 2,
            "content": " k400的平均视频长度大概是10秒啊 "
        },
        {
            "from": 100.97,
            "to": 103.93,
            "location": 2,
            "content": " 如果我们还按这个帧率30 fps 来算的话 "
        },
        {
            "from": 103.97,
            "to": 106.33,
            "location": 2,
            "content": " 它最后就有7,200万个视频帧 "
        },
        {
            "from": 106.73,
            "to": 108.97,
            "location": 2,
            "content": " 那这时候你再跟这个0.06秒一乘了 "
        },
        {
            "from": 108.97,
            "to": 111.13,
            "location": 2,
            "content": " 你就会发现你如果你只有一个 gpu "
        },
        {
            "from": 111.13,
            "to": 112.5,
            "location": 2,
            "content": " 而且不做任何优化的话 "
        },
        {
            "from": 112.5,
            "to": 114.13,
            "location": 2,
            "content": " 最后你要抽50天 "
        },
        {
            "from": 114.47,
            "to": 115.57,
            "location": 2,
            "content": " 当然一般做视频呢 "
        },
        {
            "from": 115.57,
            "to": 116.9,
            "location": 2,
            "content": " 也不可能只有一个 gpu "
        },
        {
            "from": 116.9,
            "to": 119.17,
            "location": 2,
            "content": " 而且呢因为这个 tvl one算法 "
        },
        {
            "from": 119.17,
            "to": 120.27,
            "location": 2,
            "content": " 他很省内存 "
        },
        {
            "from": 120.3,
            "to": 121.17,
            "location": 2,
            "content": " 所以一个 gpu 呢 "
        },
        {
            "from": 121.17,
            "to": 122.87,
            "location": 2,
            "content": " 也可以同时跑好多个对儿"
        },
        {
            "from": 123,
            "to": 125.3,
            "location": 2,
            "content": " 所以最后呢肯定是花不到50天的 "
        },
        {
            "from": 125.6,
            "to": 127,
            "location": 2,
            "content": " 但是对于一般实验室来说 "
        },
        {
            "from": 127,
            "to": 129.33,
            "location": 2,
            "content": " 抽个一两个礼拜还是很正常的 "
        },
        {
            "from": 129.7,
            "to": 130.73,
            "location": 2,
            "content": " 那这也就意味着 "
        },
        {
            "from": 130.73,
            "to": 132.87,
            "location": 2,
            "content": " 每当你想尝试一个新的数据集 "
        },
        {
            "from": 133,
            "to": 134.77,
            "location": 2,
            "content": " 你都要先去抽取这个光流 "
        },
        {
            "from": 134.77,
            "to": 136.73,
            "location": 2,
            "content": " 然后才能做这种模型的开发 "
        },
        {
            "from": 136.87,
            "to": 138.93,
            "location": 2,
            "content": " 那在这抽光流的一两个礼拜时间里呢 "
        },
        {
            "from": 138.93,
            "to": 140.1,
            "location": 2,
            "content": " 你什么也干不了 "
        },
        {
            "from": 140.13,
            "to": 142.5,
            "location": 2,
            "content": " 就这个预处理啊实在是太耗时了 "
        },
        {
            "from": 142.5,
            "to": 144.2,
            "location": 2,
            "content": " 而且呢它也很占空间 "
        },
        {
            "from": 144.7,
            "to": 146.4,
            "location": 2,
            "content": " 即使是按照双流方法里那样 "
        },
        {
            "from": 146.4,
            "to": 148.8,
            "location": 2,
            "content": " 把这个光流啊存成这个 jpg 图片 "
        },
        {
            "from": 149.1,
            "to": 151.07,
            "location": 2,
            "content": " 那对于 ucf101数据集来说呢"
        },
        {
            "from": 151.1,
            "to": 152.4,
            "location": 2,
            "content": " 大概也需要20多 g "
        },
        {
            "from": 152.37,
            "to": 154.07,
            "location": 2,
            "content": " 的这个存储空间去存储 "
        },
        {
            "from": 154.33,
            "to": 155.57,
            "location": 2,
            "content": " 然后对于 k 400来说呢 "
        },
        {
            "from": 155.57,
            "to": 158.13,
            "location": 2,
            "content": " 大概是需要500G 的存储空间去存储 "
        },
        {
            "from": 158.3,
            "to": 159.47,
            "location": 2,
            "content": " 那你有可能会想啊 "
        },
        {
            "from": 159.47,
            "to": 161.57,
            "location": 2,
            "content": " 这个存储空间一点都不贵很便宜吗 "
        },
        {
            "from": 161.57,
            "to": 163.37,
            "location": 2,
            "content": " 现在都是4个 T 8个 T的硬盘 "
        },
        {
            "from": 163.37,
            "to": 164.8,
            "location": 2,
            "content": " 500G根本不算什么 "
        },
        {
            "from": 164.9,
            "to": 165.97,
            "location": 2,
            "content": " 但是你还要考虑到 "
        },
        {
            "from": 165.97,
            "to": 167.33,
            "location": 2,
            "content": " 这个运算的时候的 io "
        },
        {
            "from": 167.67,
            "to": 169.6,
            "location": 2,
            "content": " 如果你的训练数据集这么大的话 "
        },
        {
            "from": 169.6,
            "to": 172.07,
            "location": 2,
            "content": " 那训练的时候呢是很容易卡 io 的 "
        },
        {
            "from": 172.4,
            "to": 173.8,
            "location": 2,
            "content": " 而且呢抽取光流 "
        },
        {
            "from": 173.8,
            "to": 176.67,
            "location": 2,
            "content": " 不光是说对训练啊有着一定的影响 "
        },
        {
            "from": 176.8,
            "to": 179.13,
            "location": 2,
            "content": " 他呢对这个推理也是有影响的 "
        },
        {
            "from": 179.13,
            "to": 180.93,
            "location": 2,
            "content": " 因为你不论用在哪个场景里 "
        },
        {
            "from": 180.93,
            "to": 182.7,
            "location": 2,
            "content": " 你都要先去抽取这个光流 "
        },
        {
            "from": 182.93,
            "to": 184.2,
            "location": 2,
            "content": " 那假设我们就用 tvl one "
        },
        {
            "from": 184.2,
            "to": 185.73,
            "location": 2,
            "content": " 这种算法去抽光流的话 "
        },
        {
            "from": 185.73,
            "to": 188.77,
            "location": 2,
            "content": " 那他处理一个视频对呢大概是花0.06秒 "
        },
        {
            "from": 188.87,
            "to": 190.37,
            "location": 2,
            "content": " 那你一除以0.06 "
        },
        {
            "from": 190.37,
            "to": 191.17,
            "location": 2,
            "content": " 你换算过来呢 "
        },
        {
            "from": 191.17,
            "to": 193.5,
            "location": 2,
            "content": " 他的这个帧率呢就是15 fps "
        },
        {
            "from": 194.07,
            "to": 196.6,
            "location": 2,
            "content": " 那这个 fps 呢是低于这个实时要求的 "
        },
        {
            "from": 196.6,
            "to": 199.2,
            "location": 2,
            "content": " 因为实时的处理一般是需要25 fps "
        },
        {
            "from": 199.2,
            "to": 200.47,
            "location": 2,
            "content": " 或者30 fps "
        },
        {
            "from": 200.77,
            "to": 202.97,
            "location": 2,
            "content": " 那这也就意味着你什么模型都没用 "
        },
        {
            "from": 202.97,
            "to": 205.6,
            "location": 2,
            "content": " 你光抽光流你就已经不是实时了 "
        },
        {
            "from": 205.67,
            "to": 207.1,
            "location": 2,
            "content": " 那你再加上模型 "
        },
        {
            "from": 207.1,
            "to": 208.7,
            "location": 2,
            "content": " 那就肯定更不是实时了 "
        },
        {
            "from": 208.73,
            "to": 209.5,
            "location": 2,
            "content": " 但可惜呢 "
        },
        {
            "from": 209.5,
            "to": 210.93,
            "location": 2,
            "content": " 视频理解一般的应用呢 "
        },
        {
            "from": 210.93,
            "to": 212.9,
            "location": 2,
            "content": " 很多都是需要实时处理的 "
        },
        {
            "from": 213.27,
            "to": 213.77,
            "location": 2,
            "content": " 所以说呢 "
        },
        {
            "from": 213.77,
            "to": 215.17,
            "location": 2,
            "content": " 其实后面的很多工作啊 "
        },
        {
            "from": 215.17,
            "to": 216.4,
            "location": 2,
            "content": " 都是针对这些缺点 "
        },
        {
            "from": 216.4,
            "to": 218.33,
            "location": 2,
            "content": " 去攻击这些基于光流的方法啊 "
        },
        {
            "from": 218.33,
            "to": 219.53,
            "location": 2,
            "content": " 比如说双流网络 "
        },
        {
            "from": 219.7,
            "to": 221.8,
            "location": 2,
            "content": " 就尽量想避开使用双流网络 "
        },
        {
            "from": 221.8,
            "to": 224,
            "location": 2,
            "content": " 如果我能直接从视频里进行学习 "
        },
        {
            "from": 224,
            "to": 224.93,
            "location": 2,
            "content": " 那该多好 "
        },
        {
            "from": 225.07,
            "to": 227.4,
            "location": 2,
            "content": " 所以这也就有了从2017年到现在啊 "
        },
        {
            "from": 227.4,
            "to": 229.37,
            "location": 2,
            "content": " 这个3 d 卷积神经网络的火热 "
        },
        {
            "from": 229.87,
            "to": 231.33,
            "location": 2,
            "content": " 因为3 d 卷积神经网络 "
        },
        {
            "from": 231.33,
            "to": 233.57,
            "location": 2,
            "content": " 他按道理来说你就是想去学习一个 "
        },
        {
            "from": 233.57,
            "to": 234.6,
            "location": 2,
            "content": " 这个时空特征 "
        },
        {
            "from": 234.6,
            "to": 235.93,
            "location": 2,
            "content": " 就他既有这个 spatial "
        },
        {
            "from": 235.93,
            "to": 237.57,
            "location": 2,
            "content": " 又有这个 temporal 上的信息 "
        },
        {
            "from": 237.6,
            "to": 238.9,
            "location": 2,
            "content": " 他是一起学习的 "
        },
        {
            "from": 238.97,
            "to": 239.2,
            "location": 2,
            "content": " 所以 "
        },
        {
            "from": 239.2,
            "to": 241.47,
            "location": 2,
            "content": " 你没有必要单独的再去对这个运动信 "
        },
        {
            "from": 241.47,
            "to": 242.77,
            "location": 2,
            "content": " 息或者时序信息进行 "
        },
        {
            "from": 242.77,
            "to": 243.77,
            "location": 2,
            "content": " 单独建模了 "
        },
        {
            "from": 243.77,
            "to": 245.87,
            "location": 2,
            "content": " 也就意味着你不需要这种光流了 "
        },
        {
            "from": 246.5,
            "to": 248.6,
            "location": 2,
            "content": " 但事实上呢我们回头也可以看到啊 "
        },
        {
            "from": 248.6,
            "to": 250.33,
            "location": 2,
            "content": " 因为这个3 d 网络越做越大 "
        },
        {
            "from": 250.33,
            "to": 252.57,
            "location": 2,
            "content": " 或者说这个 Video transformer呢也越做越大 "
        },
        {
            "from": 252.57,
            "to": 254.33,
            "location": 2,
            "content": " 所以说其实这个效率上的问题呢 "
        },
        {
            "from": 254.33,
            "to": 255.67,
            "location": 2,
            "content": " 并没有得到解决 "
        },
        {
            "from": 255.87,
            "to": 258.13,
            "location": 2,
            "content": " 大部分模型呢也都不是实时的 "
        },
        {
            "from": 258.33,
            "to": 260.3,
            "location": 2,
            "content": " 而且呢如果你给这些3 d 网络 "
        },
        {
            "from": 260.3,
            "to": 261.17,
            "location": 2,
            "content": " 或者给这些 "
        },
        {
            "from": 261.17,
            "to": 262.1,
            "location": 2,
            "content": " 啊 Video transformer "
        },
        {
            "from": 262.1,
            "to": 263.97,
            "location": 2,
            "content": " 去加上这种光流输入的话 "
        },
        {
            "from": 264.17,
            "to": 266.37,
            "location": 2,
            "content": " 其实他们都还能继续提高性能 "
        },
        {
            "from": 266.53,
            "to": 267.3,
            "location": 2,
            "content": " 也就意味着 "
        },
        {
            "from": 267.3,
            "to": 268.1,
            "location": 2,
            "content": " 光流这个东西 "
        },
        {
            "from": 268.1,
            "to": 269.8,
            "location": 2,
            "content": " 其实还是很好的一个特征 "
        },
        {
            "from": 270.77,
            "to": 272.5,
            "location": 2,
            "content": " 那我们直接进入正文啊 "
        },
        {
            "from": 272.5,
            "to": 273.9,
            "location": 2,
            "content": " 今天要说的第一篇论文呢 "
        },
        {
            "from": 273.9,
            "to": 276.77,
            "location": 2,
            "content": " 就是 iccv 15的这篇啊 c3d 网络  "
        },
        {
            "from": 277.17,
            "to": 279.3,
            "location": 2,
            "content": " 题目呢就是用3 d 卷积神经网络 "
        },
        {
            "from": 279.3,
            "to": 281.07,
            "location": 2,
            "content": " 去学习这种时空上的特征 "
        },
        {
            "from": 281.67,
            "to": 283.87,
            "location": 2,
            "content": " 作者团队呢来自FAI和Dartmouth"
        },
        {
            "from": 284.07,
            "to": 286.67,
            "location": 2,
            "content": " 那其实呢Lorenzo后面也已经去了FAI "
        },
        {
            "from": 286.67,
            "to": 288.7,
            "location": 2,
            "content": " 所以说其实就都是FAI的工作 "
        },
        {
            "from": 289.2,
            "to": 290.6,
            "location": 2,
            "content": " 我们从摘要的第一句话呢 "
        },
        {
            "from": 290.6,
            "to": 291.57,
            "location": 2,
            "content": " 其实就可以看出来 "
        },
        {
            "from": 291.57,
            "to": 293.5,
            "location": 2,
            "content": " 这篇文章的主要贡献是什么 "
        },
        {
            "from": 293.57,
            "to": 294.77,
            "location": 2,
            "content": " 其实作者已经说了 "
        },
        {
            "from": 294.77,
            "to": 295.27,
            "location": 2,
            "content": " 他们呢 "
        },
        {
            "from": 295.27,
            "to": 297.73,
            "location": 2,
            "content": " 就是提出了一个简单但是有效的方法 "
        },
        {
            "from": 297.73,
            "to": 300.5,
            "location": 2,
            "content": " 啊去学习视频中的这种时空特征啊 "
        },
        {
            "from": 300.5,
            "to": 301.3,
            "location": 2,
            "content": " 用什么工具呢 "
        },
        {
            "from": 301.3,
            "to": 302.47,
            "location": 2,
            "content": " 就是用一个简单的这个 "
        },
        {
            "from": 302.47,
            "to": 304.3,
            "location": 2,
            "content": " 3 d 卷积神经网络就可以了 "
        },
        {
            "from": 304.57,
            "to": 305.53,
            "location": 2,
            "content": " 那他们的贡献呢 "
        },
        {
            "from": 305.53,
            "to": 307.57,
            "location": 2,
            "content": " 主要就是用了一个更深的3 d 卷积 "
        },
        {
            "from": 307.57,
            "to": 308.37,
            "location": 2,
            "content": " 神经网络 "
        },
        {
            "from": 308.37,
            "to": 309.33,
            "location": 2,
            "content": " 而且呢是在一个 "
        },
        {
            "from": 309.33,
            "to": 311.53,
            "location": 2,
            "content": " 特别大的这个数据集上去进行训练 "
        },
        {
            "from": 311.77,
            "to": 312.77,
            "location": 2,
            "content": " 而这个数据集呢 "
        },
        {
            "from": 312.77,
            "to": 314.07,
            "location": 2,
            "content": " 就是我们上回讲的 "
        },
        {
            "from": 314.07,
            "to": 316.4,
            "location": 2,
            "content": " deep video 那篇论文里提出来的 sports one million "
        },
        {
            "from": 316.53,
            "to": 318.53,
            "location": 2,
            "content": " 就是有100万个视频的那个数据集 "
        },
        {
            "from": 319.17,
            "to": 319.9,
            "location": 2,
            "content": " 然后作者呢 "
        },
        {
            "from": 319.9,
            "to": 322.37,
            "location": 2,
            "content": " 其实在这个引言部分也已经提到了 "
        },
        {
            "from": 322.47,
            "to": 324.13,
            "location": 2,
            "content": " 就是他们呢并不是第一个用这个 "
        },
        {
            "from": 324.13,
            "to": 326.57,
            "location": 2,
            "content": " 3 d 卷积神经网络来做视频理解的啊 "
        },
        {
            "from": 326.57,
            "to": 328.8,
            "location": 2,
            "content": " 其实之前这个15和18这两个工作呢 "
        },
        {
            "from": 328.8,
            "to": 331.07,
            "location": 2,
            "content": " 也都是用3 d 卷积神经网络来做的啊 "
        },
        {
            "from": 331.07,
            "to": 332.1,
            "location": 2,
            "content": " 没有什么区别 "
        },
        {
            "from": 332.4,
            "to": 334.9,
            "location": 2,
            "content": " 最主要的区别呢就是 c 3 d 这篇论文 "
        },
        {
            "from": 334.9,
            "to": 336.33,
            "location": 2,
            "content": " 就是他们这篇论文呢 "
        },
        {
            "from": 336.47,
            "to": 338.77,
            "location": 2,
            "content": " 是在用了大规模的这个数数据集 "
        },
        {
            "from": 338.77,
            "to": 339.8,
            "location": 2,
            "content": " 去训练模型 "
        },
        {
            "from": 340.1,
            "to": 342.6,
            "location": 2,
            "content": " 而且呢用了这种现代的这种深度学习 "
        },
        {
            "from": 342.6,
            "to": 344.07,
            "location": 2,
            "content": " 其实就是更深的网络 "
        },
        {
            "from": 344.4,
            "to": 346.2,
            "location": 2,
            "content": " 从而呢能在一系列的任务上呢 "
        },
        {
            "from": 346.2,
            "to": 347.57,
            "location": 2,
            "content": " 得到了非常好的结果 "
        },
        {
            "from": 348.13,
            "to": 348.5,
            "location": 2,
            "content": " 所以呢 "
        },
        {
            "from": 348.5,
            "to": 350.6,
            "location": 2,
            "content": " 站在我们现在的角度再去回看这篇论 "
        },
        {
            "from": 350.6,
            "to": 352.93,
            "location": 2,
            "content": " 文的话他的想法上还是很简单的 "
        },
        {
            "from": 352.93,
            "to": 354.5,
            "location": 2,
            "content": " 所以我们直接来看这个效果 "
        },
        {
            "from": 354.5,
            "to": 356.1,
            "location": 2,
            "content": " 和这个模型总览图 "
        },
        {
            "from": 356.87,
            "to": 357.5,
            "location": 2,
            "content": " 那首先呢 "
        },
        {
            "from": 357.5,
            "to": 359.1,
            "location": 2,
            "content": " 作者把他们的这个最后结果啊 "
        },
        {
            "from": 359.1,
            "to": 360.4,
            "location": 2,
            "content": " 放到这个表1里啊 "
        },
        {
            "from": 360.4,
            "to": 362.13,
            "location": 2,
            "content": " 直接放到这个论文的第二页 "
        },
        {
            "from": 362.4,
            "to": 364.6,
            "location": 2,
            "content": " 因为呢这算是他们论文的一个卖点啊 "
        },
        {
            "from": 364.6,
            "to": 366.17,
            "location": 2,
            "content": " 就是说在这四个数据集上呢 "
        },
        {
            "from": 366.17,
            "to": 367.87,
            "location": 2,
            "content": " 他们都取得了最好的这个结果 "
        },
        {
            "from": 367.87,
            "to": 369.2,
            "location": 2,
            "content": " 然后在这两个数据集上呢 "
        },
        {
            "from": 369.2,
            "to": 370.47,
            "location": 2,
            "content": " 他们也取得了不错啊 "
        },
        {
            "from": 370.47,
            "to": 372,
            "location": 2,
            "content": " 就是 competitive 的结果 "
        },
        {
            "from": 372.77,
            "to": 374.87,
            "location": 2,
            "content": " 那接下来我们直接看模型的结构啊 "
        },
        {
            "from": 374.87,
            "to": 375.3,
            "location": 2,
            "content": " 在这里 "
        },
        {
            "from": 375.3,
            "to": 377.67,
            "location": 2,
            "content": " 作者其实是用一个简略图画画出来的 "
        },
        {
            "from": 377.67,
            "to": 379,
            "location": 2,
            "content": " 而不是一个特别 fansy "
        },
        {
            "from": 379,
            "to": 380.3,
            "location": 2,
            "content": " 特别好看的一张图 "
        },
        {
            "from": 380.7,
            "to": 382.13,
            "location": 2,
            "content": " 那大体的这个网络结构呢 "
        },
        {
            "from": 382.13,
            "to": 385.47,
            "location": 2,
            "content": " 就是你有这个Conv1 pool1然后Conv2 pool2啊 "
        },
        {
            "from": 385.47,
            "to": 387.33,
            "location": 2,
            "content": " Conv3a 3b pool3 "
        },
        {
            "from": 387.33,
            "to": 391.1,
            "location": 2,
            "content": " 还有Conv4a 4b pool4啊Conv5a 5b pool5 "
        },
        {
            "from": 391.2,
            "to": 392.87,
            "location": 2,
            "content": " 然后最后呢还有两层 fc "
        },
        {
            "from": 393,
            "to": 395.1,
            "location": 2,
            "content": " 最后呢还有一个分类层 fc 8 "
        },
        {
            "from": 395.4,
            "to": 396.67,
            "location": 2,
            "content": " 所以说整体来看呢 "
        },
        {
            "from": 396.67,
            "to": 398.57,
            "location": 2,
            "content": " 这个网络结构呢是有11层的 "
        },
        {
            "from": 398.9,
            "to": 400.7,
            "location": 2,
            "content": " 至于所有的这个3 d 卷积层里 "
        },
        {
            "from": 400.7,
            "to": 402.7,
            "location": 2,
            "content": " 的这个卷积核是怎么构造呢 "
        },
        {
            "from": 402.77,
            "to": 403.67,
            "location": 2,
            "content": " 作者这里也说了 "
        },
        {
            "from": 403.67,
            "to": 406.1,
            "location": 2,
            "content": " 其实就是把所有的这种3*3的卷积核呢 "
        },
        {
            "from": 406.1,
            "to": 407.93,
            "location": 2,
            "content": " 都变成了这个3*3*3 "
        },
        {
            "from": 408.67,
            "to": 410.7,
            "location": 2,
            "content": " 那其实我们看到这呢你就会发现哎 "
        },
        {
            "from": 410.7,
            "to": 413.07,
            "location": 2,
            "content": " 这个网络怎么跟 vgg 这么像呢 "
        },
        {
            "from": 413.27,
            "to": 414.4,
            "location": 2,
            "content": " 那其实说白了 "
        },
        {
            "from": 414.53,
            "to": 417.17,
            "location": 2,
            "content": " 他其实就是一个3 d 版本的 vgg 网络 "
        },
        {
            "from": 417.33,
            "to": 418.6,
            "location": 2,
            "content": " 那如果我们回顾一下 "
        },
        {
            "from": 418.6,
            "to": 420.27,
            "location": 2,
            "content": " vgg16那个网络的话呢 "
        },
        {
            "from": 420.37,
            "to": 421.6,
            "location": 2,
            "content": " 其实在Conv1这块呢 "
        },
        {
            "from": 421.6,
            "to": 423.73,
            "location": 2,
            "content": " 他是有两层Conv然后一层pooling "
        },
        {
            "from": 423.93,
            "to": 426.07,
            "location": 2,
            "content": " 然后又有两层Conv一层pooling "
        },
        {
            "from": 426.3,
            "to": 428.77,
            "location": 2,
            "content": " 然后从第345这三个 block 来说呢 "
        },
        {
            "from": 428.77,
            "to": 430.6,
            "location": 2,
            "content": " 他是三个Conv加一个pooling "
        },
        {
            "from": 430.6,
            "to": 431.97,
            "location": 2,
            "content": " 三个Conv加一个pooling "
        },
        {
            "from": 431.97,
            "to": 433.3,
            "location": 2,
            "content": " 三个Conv加一个pooling "
        },
        {
            "from": 433.73,
            "to": 435.77,
            "location": 2,
            "content": " 所以说相当于呢 c 3 d 网络 "
        },
        {
            "from": 435.77,
            "to": 438.4,
            "location": 2,
            "content": " 就是把 v g g 网络每一个 block 里面呢 "
        },
        {
            "from": 438.4,
            "to": 439.93,
            "location": 2,
            "content": " 都减少了一层 Conv "
        },
        {
            "from": 440.07,
            "to": 441.4,
            "location": 2,
            "content": " 然后把所有的 conv kernel 呢 "
        },
        {
            "from": 441.4,
            "to": 443.57,
            "location": 2,
            "content": " 都从3*3变成3*3*3了 "
        },
        {
            "from": 443.9,
            "to": 445.77,
            "location": 2,
            "content": " 所有的改动呢其实就是这些 "
        },
        {
            "from": 446,
            "to": 447.47,
            "location": 2,
            "content": " 所以这也就是为什么作者说 "
        },
        {
            "from": 447.47,
            "to": 448.47,
            "location": 2,
            "content": " 他们的这个方法呢 "
        },
        {
            "from": 448.47,
            "to": 450.3,
            "location": 2,
            "content": " 设计非常简单而且直观 "
        },
        {
            "from": 450.47,
            "to": 452.1,
            "location": 2,
            "content": " 是因为确实很简单 "
        },
        {
            "from": 452.47,
            "to": 455.37,
            "location": 2,
            "content": " 也没有像 inception net 啊那种multi pass "
        },
        {
            "from": 455.37,
            "to": 457.13,
            "location": 2,
            "content": " 就是多路径的那种结构 "
        },
        {
            "from": 457.33,
            "to": 458.93,
            "location": 2,
            "content": " 而且当时也还没有 Resnet "
        },
        {
            "from": 458.93,
            "to": 460.47,
            "location": 2,
            "content": " 所以说也没有残差连接 "
        },
        {
            "from": 460.7,
            "to": 462.53,
            "location": 2,
            "content": " 所以就是简简单单的这种啊 "
        },
        {
            "from": 462.53,
            "to": 463.93,
            "location": 2,
            "content": " 卷积操作的堆叠啊 "
        },
        {
            "from": 463.93,
            "to": 465.53,
            "location": 2,
            "content": " 就是conv pooling conv pooling "
        },
        {
            "from": 466.33,
            "to": 467.93,
            "location": 2,
            "content": " 那现在呢我们给定一个输入 "
        },
        {
            "from": 467.93,
            "to": 470,
            "location": 2,
            "content": " 然后走一遍这个模型的前向过程 "
        },
        {
            "from": 470,
            "to": 471.27,
            "location": 2,
            "content": " 就能更好的理解这个模 "
        },
        {
            "from": 471.27,
            "to": 472.57,
            "location": 2,
            "content": " 型是怎么运作的了 "
        },
        {
            "from": 472.7,
            "to": 473.87,
            "location": 2,
            "content": " 那在这篇论文里呢 "
        },
        {
            "from": 473.87,
            "to": 476.8,
            "location": 2,
            "content": " 他的输入呢是16*112*112啊 "
        },
        {
            "from": 476.8,
            "to": 478.93,
            "location": 2,
            "content": " 16呢就是说明有16个视频帧啊 "
        },
        {
            "from": 478.93,
            "to": 481.73,
            "location": 2,
            "content": " 也就是十句上你的这个维度是16 "
        },
        {
            "from": 482.17,
            "to": 485.4,
            "location": 2,
            "content": " 然后你的这个空间上呢是112*112啊 "
        },
        {
            "from": 485.4,
            "to": 487.9,
            "location": 2,
            "content": " 之所以没有用这个224*224呢 "
        },
        {
            "from": 487.9,
            "to": 489.8,
            "location": 2,
            "content": " 是因为这个 gpu 内存塞不下嘛 "
        },
        {
            "from": 489.8,
            "to": 491.33,
            "location": 2,
            "content": " 啊作者后来也实验了一下 "
        },
        {
            "from": 491.33,
            "to": 493.67,
            "location": 2,
            "content": " 发现112*112其实效果也一样 "
        },
        {
            "from": 493.7,
            "to": 495.37,
            "location": 2,
            "content": " 因为一般对于分类任务来说呢 "
        },
        {
            "from": 495.37,
            "to": 497.73,
            "location": 2,
            "content": " 其实这个图片大小啊不是那么的重要 "
        },
        {
            "from": 498.17,
            "to": 501.57,
            "location": 2,
            "content": " 所以这个3 d 网络的输入呢就是16*112*112了 "
        },
        {
            "from": 501.67,
            "to": 503.7,
            "location": 2,
            "content": " 然后过完一层conv和pooling之后呢 "
        },
        {
            "from": 503.7,
            "to": 504.93,
            "location": 2,
            "content": " 因为第一层的这个pooling "
        },
        {
            "from": 504.93,
            "to": 506.7,
            "location": 2,
            "content": " 他们这里写的是1*2*2 "
        },
        {
            "from": 506.7,
            "to": 508.07,
            "location": 2,
            "content": " 就是在这个时序上呢 "
        },
        {
            "from": 508.07,
            "to": 509.67,
            "location": 2,
            "content": " 他不做这个下采样 "
        },
        {
            "from": 510,
            "to": 511.33,
            "location": 2,
            "content": " 因为想尽可能的多的呢 "
        },
        {
            "from": 511.33,
            "to": 513.27,
            "location": 2,
            "content": " 再保留一下时序上的这个信息 "
        },
        {
            "from": 513.27,
            "to": 515.9,
            "location": 2,
            "content": " 那所以说呢这个时序上16呢还是16 "
        },
        {
            "from": 515.9,
            "to": 518.07,
            "location": 2,
            "content": " 但是这个空间上呢就降了一半 "
        },
        {
            "from": 518.07,
            "to": 519.9,
            "location": 2,
            "content": " 那就变成56*56了 "
        },
        {
            "from": 520.1,
            "to": 521.67,
            "location": 2,
            "content": " 然后再做一层conv pooling "
        },
        {
            "from": 521.9,
            "to": 523.87,
            "location": 2,
            "content": " 那接下来呢所有这个pooling操作呢 "
        },
        {
            "from": 523.87,
            "to": 525.13,
            "location": 2,
            "content": " 也都是2*2*2了 "
        },
        {
            "from": 525.13,
            "to": 527.9,
            "location": 2,
            "content": " 所以说呢不仅是时间上从16变成8 "
        },
        {
            "from": 527.9,
            "to": 530.93,
            "location": 2,
            "content": " 把空间上进一步降低变成28*28 "
        },
        {
            "from": 531.3,
            "to": 533.2,
            "location": 2,
            "content": " 然后再过了第三层这个conv之后呢 "
        },
        {
            "from": 533.2,
            "to": 534.97,
            "location": 2,
            "content": " 就变成4*14*14 "
        },
        {
            "from": 534.97,
            "to": 536.57,
            "location": 2,
            "content": " 然后过了第四层conv之后呢 "
        },
        {
            "from": 536.57,
            "to": 538.07,
            "location": 2,
            "content": " 就变成2*7*7 "
        },
        {
            "from": 538.2,
            "to": 540.47,
            "location": 2,
            "content": " 然后再过了第五层conv和pooling之后呢 "
        },
        {
            "from": 540.47,
            "to": 543,
            "location": 2,
            "content": " 最后在 fc 这一层这个特征维度呢 "
        },
        {
            "from": 543,
            "to": 544.87,
            "location": 2,
            "content": " 就变成一个1*4096 "
        },
        {
            "from": 544.97,
            "to": 546.97,
            "location": 2,
            "content": " 就变成一个一维的一个向量了 "
        },
        {
            "from": 546.97,
            "to": 549,
            "location": 2,
            "content": " 也就是我们最后抽取的这个特征 "
        },
        {
            "from": 549.3,
            "to": 552.07,
            "location": 2,
            "content": " 当然了 fc 7呢也是4096*4096 "
        },
        {
            "from": 552.07,
            "to": 555.4,
            "location": 2,
            "content": " 然后最后一层 fc 8分类层呢就是4096*101 "
        },
        {
            "from": 555.4,
            "to": 556.93,
            "location": 2,
            "content": " 还就是101类了 "
        },
        {
            "from": 557.6,
            "to": 559,
            "location": 2,
            "content": " 但是在这篇论文里呢 "
        },
        {
            "from": 559,
            "to": 561.8,
            "location": 2,
            "content": " 作者当时发现啊这个fine-tuned这个网络啊 "
        },
        {
            "from": 561.8,
            "to": 563.7,
            "location": 2,
            "content": " 其实最后的结果呢也不是很好 "
        },
        {
            "from": 563.7,
            "to": 565.2,
            "location": 2,
            "content": " 而且呢又费时费力 "
        },
        {
            "from": 565.7,
            "to": 568.07,
            "location": 2,
            "content": " 对其实作者呢每次都是抽取特征啊 "
        },
        {
            "from": 568.07,
            "to": 570.1,
            "location": 2,
            "content": " 他最后选择的就是从 fc 6这层 "
        },
        {
            "from": 570.1,
            "to": 572,
            "location": 2,
            "content": " 去抽取这个4096的特征 "
        },
        {
            "from": 572.13,
            "to": 572.7,
            "location": 2,
            "content": " 拿出来 "
        },
        {
            "from": 572.7,
            "to": 575.27,
            "location": 2,
            "content": " 然后再去训练一个 svm 的这个分类器 "
        },
        {
            "from": 575.3,
            "to": 576.7,
            "location": 2,
            "content": " 啊去做这个分类任务啊 "
        },
        {
            "from": 576.7,
            "to": 577.97,
            "location": 2,
            "content": " 又快效果又好 "
        },
        {
            "from": 578.33,
            "to": 580.6,
            "location": 2,
            "content": " 那其实这篇文章的名字 c 3 d 呢 "
        },
        {
            "from": 580.6,
            "to": 582.4,
            "location": 2,
            "content": " 其实更多时候指代的呢 "
        },
        {
            "from": 582.4,
            "to": 583.93,
            "location": 2,
            "content": " 就是这个 c 3 d 特征 "
        },
        {
            "from": 583.93,
            "to": 585.97,
            "location": 2,
            "content": " 也就是 fc 6抽出来的这个特征 "
        },
        {
            "from": 585.97,
            "to": 587.27,
            "location": 2,
            "content": " 叫 c 3 d 特征 "
        },
        {
            "from": 587.77,
            "to": 589.77,
            "location": 2,
            "content": " 那模型上呢其实就是这些啊 "
        },
        {
            "from": 589.77,
            "to": 591.07,
            "location": 2,
            "content": " 能讲的并不是很多 "
        },
        {
            "from": 591.07,
            "to": 593,
            "location": 2,
            "content": " 那接下来呢我们就直接看结果 "
        },
        {
            "from": 593.2,
            "to": 594.53,
            "location": 2,
            "content": " 首先在这个表2里呢 "
        },
        {
            "from": 594.53,
            "to": 595.8,
            "location": 2,
            "content": " 作者就表展示了一下 "
        },
        {
            "from": 595.8,
            "to": 597,
            "location": 2,
            "content": " 在这个 sports-1M "
        },
        {
            "from": 597.13,
            "to": 598.6,
            "location": 2,
            "content": " 这个数据集上的结果 "
        },
        {
            "from": 598.8,
            "to": 600.77,
            "location": 2,
            "content": " 那前两行呢这个就是 deep video 啊 "
        },
        {
            "from": 600.77,
            "to": 602.3,
            "location": 2,
            "content": " cvp 2014的那篇论文 "
        },
        {
            "from": 602.5,
            "to": 603.53,
            "location": 2,
            "content": " 也是第一次提出 "
        },
        {
            "from": 603.53,
            "to": 605.3,
            "location": 2,
            "content": " sports-1M 这个数据集的 "
        },
        {
            "from": 605.57,
            "to": 607.4,
            "location": 2,
            "content": " 我们可以看出来啊 c 3 d 这个工作 "
        },
        {
            "from": 607.4,
            "to": 608.97,
            "location": 2,
            "content": " 而如果也是在 sports-1M "
        },
        {
            "from": 608.97,
            "to": 611.1,
            "location": 2,
            "content": " 这个数据集上去重头训练的话呢 "
        },
        {
            "from": 611.2,
            "to": 612.13,
            "location": 2,
            "content": " 它的这个效果呢 "
        },
        {
            "from": 612.13,
            "to": 614.57,
            "location": 2,
            "content": " 大概是四十四 六十 八十四 "
        },
        {
            "from": 614.73,
            "to": 617.37,
            "location": 2,
            "content": " 所以比原来对应的这个版本这一行呢 "
        },
        {
            "from": 617.37,
            "to": 618.53,
            "location": 2,
            "content": " 还是要高一些的 "
        },
        {
            "from": 618.67,
            "to": 621.1,
            "location": 2,
            "content": " 所以说证明了 c 3 d 这个网络的有效性 "
        },
        {
            "from": 621.27,
            "to": 622.9,
            "location": 2,
            "content": " 然后如果把这个 c 3 d 网络 "
        },
        {
            "from": 622.9,
            "to": 624.97,
            "location": 2,
            "content": " 在更大的数据集上去做预训练 "
        },
        {
            "from": 624.97,
            "to": 627.27,
            "location": 2,
            "content": " 也就是他这里说这个 I380 k 啊 "
        },
        {
            "from": 627.27,
            "to": 628.2,
            "location": 2,
            "content": " 其实是 "
        },
        {
            "from": 628.2,
            "to": 628.73,
            "location": 2,
            "content": " facebook自己 "
        },
        {
            "from": 628.73,
            "to": 630.1,
            "location": 2,
            "content": " 一个从来没有 release 过的 "
        },
        {
            "from": 630.1,
            "to": 632.77,
            "location": 2,
            "content": " 一个 instagram 的视频数据集啊 "
        },
        {
            "from": 632.77,
            "to": 635,
            "location": 2,
            "content": " 在这个上面去做这个预训练之后呢 "
        },
        {
            "from": 635.17,
            "to": 637.3,
            "location": 2,
            "content": " 他发现这个效果呢就更好了 "
        },
        {
            "from": 637.7,
            "to": 638.4,
            "location": 2,
            "content": " 这就是这篇 "
        },
        {
            "from": 638.4,
            "to": 640.1,
            "location": 2,
            "content": " 作者在这个摘要里 "
        },
        {
            "from": 640.1,
            "to": 641.7,
            "location": 2,
            "content": " 还有在引言里反复强调了 "
        },
        {
            "from": 641.7,
            "to": 642.67,
            "location": 2,
            "content": " 就是他们认为啊 "
        },
        {
            "from": 642.67,
            "to": 645.37,
            "location": 2,
            "content": " 这种3 d 的直接学习时空特征的方法呢 "
        },
        {
            "from": 645.37,
            "to": 647.33,
            "location": 2,
            "content": " 是比使用2 d 网络要好的 "
        },
        {
            "from": 647.37,
            "to": 649.17,
            "location": 2,
            "content": " 因为这个 deep video这个方法呢 "
        },
        {
            "from": 649.17,
            "to": 651.57,
            "location": 2,
            "content": " 其实还是可以看作成是一个2 d 网络 "
        },
        {
            "from": 651.93,
            "to": 653.7,
            "location": 2,
            "content": " 它里面虽然有一些这个什么 "
        },
        {
            "from": 653.73,
            "to": 654.57,
            "location": 2,
            "content": " early fusion 呢 "
        },
        {
            "from": 654.57,
            "to": 656.33,
            "location": 2,
            "content": " 或者 slow fusion 呢啊 "
        },
        {
            "from": 656.33,
            "to": 657.27,
            "location": 2,
            "content": " 但是终归而言 "
        },
        {
            "from": 657.27,
            "to": 659.57,
            "location": 2,
            "content": " 他还是用这个2 d 网络去抽特征啊 "
        },
        {
            "from": 659.57,
            "to": 661.77,
            "location": 2,
            "content": " 只不过是在后面呢做了一下这个合并 "
        },
        {
            "from": 661.93,
            "to": 662.9,
            "location": 2,
            "content": " 那这个 c 3 d 呢 "
        },
        {
            "from": 662.9,
            "to": 665.5,
            "location": 2,
            "content": " 才是真真正正从头到尾都是一个3 d "
        },
        {
            "from": 665.5,
            "to": 666.37,
            "location": 2,
            "content": " 卷积神经网络 "
        },
        {
            "from": 666.37,
            "to": 668.73,
            "location": 2,
            "content": " 从头到尾都是在做这种时空学习 "
        },
        {
            "from": 669,
            "to": 670.17,
            "location": 2,
            "content": " 所以作者就得出了啊 "
        },
        {
            "from": 670.17,
            "to": 672.87,
            "location": 2,
            "content": " 说这个3 d 网络呢要比2 d 网络要更优 "
        },
        {
            "from": 672.97,
            "to": 675.37,
            "location": 2,
            "content": " 或者说更适合这个视频理解的任务 "
        },
        {
            "from": 676.5,
            "to": 678.67,
            "location": 2,
            "content": " 那接下来呢我们看一下这个表3啊 "
        },
        {
            "from": 678.67,
            "to": 680.93,
            "location": 2,
            "content": " 也就是在 ucf 101这个数据集上啊 "
        },
        {
            "from": 680.93,
            "to": 682.57,
            "location": 2,
            "content": " c 3 d 的表现到底如何 "
        },
        {
            "from": 683.3,
            "to": 684.33,
            "location": 2,
            "content": " 我们这里也可以看出来 "
        },
        {
            "from": 684.33,
            "to": 685.7,
            "location": 2,
            "content": " 就是 c 3 d 这个网络 "
        },
        {
            "from": 685.7,
            "to": 687.9,
            "location": 2,
            "content": " 其实你如果你只用一个网络的话呢 "
        },
        {
            "from": 687.9,
            "to": 689.97,
            "location": 2,
            "content": " 他的结果只有82.3啊 "
        },
        {
            "from": 689.97,
            "to": 691.53,
            "location": 2,
            "content": " 如果你训练了3个网络 "
        },
        {
            "from": 691.53,
            "to": 693.2,
            "location": 2,
            "content": " 把他们这个 ensemble 起来 "
        },
        {
            "from": 693.2,
            "to": 695.73,
            "location": 2,
            "content": " 他最后的这个结果才有85.2这么高 "
        },
        {
            "from": 696.07,
            "to": 696.67,
            "location": 2,
            "content": " 但其实呢 "
        },
        {
            "from": 696.67,
            "to": 697.9,
            "location": 2,
            "content": " 85.2这个效果呢 "
        },
        {
            "from": 697.9,
            "to": 699.93,
            "location": 2,
            "content": " 是远低于同期其他工作的啊 "
        },
        {
            "from": 699.93,
            "to": 700.73,
            "location": 2,
            "content": " 我们之前说过 "
        },
        {
            "from": 700.73,
            "to": 702.53,
            "location": 2,
            "content": " 这个之前最好的手工特征呢 "
        },
        {
            "from": 702.53,
            "to": 705.73,
            "location": 2,
            "content": " 都有88 双流网络呢也有88 "
        },
        {
            "from": 706.13,
            "to": 709.57,
            "location": 2,
            "content": " 然后用 lstm网络的呢也有84或者88这么高 "
        },
        {
            "from": 709.8,
            "to": 711.27,
            "location": 2,
            "content": " 而且其实比他更早啊 "
        },
        {
            "from": 711.27,
            "to": 713.27,
            "location": 2,
            "content": " 就是 cvpr 15发出来的一篇论文 "
        },
        {
            "from": 713.27,
            "to": 715.37,
            "location": 2,
            "content": " 就王黎明老师在 tdd 里面的论文 "
        },
        {
            "from": 715.37,
            "to": 716.7,
            "location": 2,
            "content": " 其实已经在 ucf 上呢 "
        },
        {
            "from": 716.7,
            "to": 718.6,
            "location": 2,
            "content": " 有91.5的这个结果了 "
        },
        {
            "from": 718.7,
            "to": 720.93,
            "location": 2,
            "content": " 这比他这里的90.4还要高的 "
        },
        {
            "from": 720.93,
            "to": 722.33,
            "location": 2,
            "content": " 所以说整体上来看呢 "
        },
        {
            "from": 722.33,
            "to": 724.97,
            "location": 2,
            "content": " 其实 c 3 d 的这个效果呢并不突出 "
        },
        {
            "from": 725.5,
            "to": 727.07,
            "location": 2,
            "content": " 那 c 3 d 为什么会这么火 "
        },
        {
            "from": 727.07,
            "to": 728.7,
            "location": 2,
            "content": " 他的接受度又这么高呢 "
        },
        {
            "from": 728.73,
            "to": 731.17,
            "location": 2,
            "content": " 其实我认为呢是作者抓住了一个机会 "
        },
        {
            "from": 731.27,
            "to": 732.9,
            "location": 2,
            "content": " 他没有把这篇文章的卖点呢 "
        },
        {
            "from": 732.9,
            "to": 734.37,
            "location": 2,
            "content": " 放在这个网络训练上 "
        },
        {
            "from": 734.47,
            "to": 735.93,
            "location": 2,
            "content": " 而是把这个文章的卖点呢 "
        },
        {
            "from": 735.93,
            "to": 737.47,
            "location": 2,
            "content": " 放在了这个抽特征上 "
        },
        {
            "from": 737.6,
            "to": 739.53,
            "location": 2,
            "content": " 而且他还给出了对应的这个python "
        },
        {
            "from": 739.53,
            "to": 740.73,
            "location": 2,
            "content": " 和 matlab 的实现 "
        },
        {
            "from": 740.77,
            "to": 742.4,
            "location": 2,
            "content": " 这个在当时15年的时候呢 "
        },
        {
            "from": 742.4,
            "to": 743.7,
            "location": 2,
            "content": " 是非常关键的 "
        },
        {
            "from": 744.13,
            "to": 744.77,
            "location": 2,
            "content": " 那这个时候呢 "
        },
        {
            "from": 744.77,
            "to": 746.6,
            "location": 2,
            "content": " c 3 d 的作者其实他也发现了 "
        },
        {
            "from": 746.6,
            "to": 748.33,
            "location": 2,
            "content": " 因为当时开会的时候跟他聊过 "
        },
        {
            "from": 748.33,
            "to": 749.87,
            "location": 2,
            "content": " 他训练这个 c 3 d 网络呢 "
        },
        {
            "from": 749.87,
            "to": 750.97,
            "location": 2,
            "content": " 当时花了一个月 "
        },
        {
            "from": 751.2,
            "to": 752.8,
            "location": 2,
            "content": " 也就以 facebook 这个算力呢 "
        },
        {
            "from": 752.8,
            "to": 754.17,
            "location": 2,
            "content": " 他训练这么一个视频模型 "
        },
        {
            "from": 754.17,
            "to": 755.6,
            "location": 2,
            "content": " 都要花一个月的时间 "
        },
        {
            "from": 755.73,
            "to": 757,
            "location": 2,
            "content": " 那对于大多数人来说呢 "
        },
        {
            "from": 757,
            "to": 758.47,
            "location": 2,
            "content": " 肯定是训练不动了 "
        },
        {
            "from": 758.67,
            "to": 759.4,
            "location": 2,
            "content": " 所以他知道的 "
        },
        {
            "from": 759.4,
            "to": 761.2,
            "location": 2,
            "content": " 如果大家想在这个视频理解 "
        },
        {
            "from": 761.2,
            "to": 762.73,
            "location": 2,
            "content": " 或者在对应的其他领域里 "
        },
        {
            "from": 762.73,
            "to": 764.1,
            "location": 2,
            "content": " 去用这种视频的特征 "
        },
        {
            "from": 764.1,
            "to": 765.47,
            "location": 2,
            "content": " 或者视频模型的话 "
        },
        {
            "from": 765.77,
            "to": 766.8,
            "location": 2,
            "content": " fine-tuned这个模型呢 "
        },
        {
            "from": 766.8,
            "to": 768.77,
            "location": 2,
            "content": " 在当时不是一个好的选择啊 "
        },
        {
            "from": 768.77,
            "to": 770.73,
            "location": 2,
            "content": " 抽特征才是最好的选择 "
        },
        {
            "from": 771.1,
            "to": 771.57,
            "location": 2,
            "content": " 所以说呢 "
        },
        {
            "from": 771.57,
            "to": 772.93,
            "location": 2,
            "content": " 作者就提供了一个 python "
        },
        {
            "from": 772.93,
            "to": 774.37,
            "location": 2,
            "content": " 还有一个 matlab 的接口 "
        },
        {
            "from": 774.5,
            "to": 775.13,
            "location": 2,
            "content": " 也就说呢 "
        },
        {
            "from": 775.13,
            "to": 776.87,
            "location": 2,
            "content": " 你只要给我一个视频输入啊 "
        },
        {
            "from": 776.87,
            "to": 778.67,
            "location": 2,
            "content": " 你也可以用 open cv 读进来 "
        },
        {
            "from": 778.93,
            "to": 780.13,
            "location": 2,
            "content": "  matlab python 都可以 "
        },
        {
            "from": 780.13,
            "to": 782.8,
            "location": 2,
            "content": " 然后我就返还给你一个1*4096的特征 "
        },
        {
            "from": 783.1,
            "to": 785.3,
            "location": 2,
            "content": " 中间的细节呢你通通都不用管啊 "
        },
        {
            "from": 785.3,
            "to": 786.13,
            "location": 2,
            "content": " 你就拿这个特征 "
        },
        {
            "from": 786.13,
            "to": 788.13,
            "location": 2,
            "content": " 去做你其他的下游任务就可以了 "
        },
        {
            "from": 788.5,
            "to": 789.27,
            "location": 2,
            "content": " 所以很快啊 "
        },
        {
            "from": 789.27,
            "to": 791.57,
            "location": 2,
            "content": " 其他任务纷纷都用起 c 3 d 这个特征 "
        },
        {
            "from": 791.57,
            "to": 792,
            "location": 2,
            "content": " 了啊 "
        },
        {
            "from": 792,
            "to": 794.9,
            "location": 2,
            "content": " 比如说 video detection 啊或者 video captioning 啊 "
        },
        {
            "from": 795.4,
            "to": 796.87,
            "location": 2,
            "content": " 都可以直接抽取一个特征 "
        },
        {
            "from": 796.87,
            "to": 798.37,
            "location": 2,
            "content": " 然后就去做他的下游任务 "
        },
        {
            "from": 798.7,
            "to": 800.87,
            "location": 2,
            "content": " 这个呢其实跟现在我们大家用transformer "
        },
        {
            "from": 800.87,
            "to": 802,
            "location": 2,
            "content": " 也是一个套路啊 "
        },
        {
            "from": 802,
            "to": 803.87,
            "location": 2,
            "content": " 因为transformer训起来太贵了啊 "
        },
        {
            "from": 803.87,
            "to": 805.2,
            "location": 2,
            "content": " 很多人也训练不动啊 "
        },
        {
            "from": 805.2,
            "to": 806.53,
            "location": 2,
            "content": " 飞条都训练不动 "
        },
        {
            "from": 806.73,
            "to": 808.4,
            "location": 2,
            "content": " 所以说大家在做多模态的时候呢 "
        },
        {
            "from": 808.4,
            "to": 810.8,
            "location": 2,
            "content": " 往往是把这个transformer呢去抽一个特征 "
        },
        {
            "from": 810.8,
            "to": 811.93,
            "location": 2,
            "content": " 然后抽完特征以后 "
        },
        {
            "from": 811.93,
            "to": 814.5,
            "location": 2,
            "content": " 在特征上再去做这种啊特征的融合 "
        },
        {
            "from": 814.5,
            "to": 816.17,
            "location": 2,
            "content": " 或者做这种多模态的学习 "
        },
        {
            "from": 816.3,
            "to": 818.67,
            "location": 2,
            "content": " 这个训练起来的代价呢就小很多了 "
        },
        {
            "from": 819.27,
            "to": 820.9,
            "location": 2,
            "content": " 所以说啊从这个角度上来看 "
        },
        {
            "from": 820.9,
            "to": 821.5,
            "location": 2,
            "content": " 做研究呢 "
        },
        {
            "from": 821.5,
            "to": 823.17,
            "location": 2,
            "content": " 也不光要成天去考虑这种 "
        },
        {
            "from": 823.17,
            "to": 824.5,
            "location": 2,
            "content": " 新意度的问题啊 "
        },
        {
            "from": 824.5,
            "to": 825.27,
            "location": 2,
            "content": " 更主要的呢 "
        },
        {
            "from": 825.27,
            "to": 825.9,
            "location": 2,
            "content": " 是要考虑一下 "
        },
        {
            "from": 825.9,
            "to": 827.6,
            "location": 2,
            "content": " 你这个东西到底有没有用 "
        },
        {
            "from": 828.13,
            "to": 829.53,
            "location": 2,
            "content": " 如果你做出来的这个东西 "
        },
        {
            "from": 829.53,
            "to": 831.7,
            "location": 2,
            "content": " 真的能够推动整个领域的进步 "
        },
        {
            "from": 831.87,
            "to": 833.37,
            "location": 2,
            "content": " 那其实才是真的好的 "
        },
        {
            "from": 833.37,
            "to": 835.07,
            "location": 2,
            "content": " 真的有用的研究工作 "
        },
        {
            "from": 835.47,
            "to": 837.07,
            "location": 2,
            "content": " 总之呢 c 3 d 这篇论文 "
        },
        {
            "from": 837.07,
            "to": 838.73,
            "location": 2,
            "content": " 他的意义还是非常巨大的 "
        },
        {
            "from": 838.97,
            "to": 841.13,
            "location": 2,
            "content": " 不光是通过这种抽特征的方式 "
        },
        {
            "from": 841.17,
            "to": 842.3,
            "location": 2,
            "content": " 让更多的研究者呢 "
        },
        {
            "from": 842.3,
            "to": 843.93,
            "location": 2,
            "content": " 能够把深度学习时代 "
        },
        {
            "from": 843.93,
            "to": 845.93,
            "location": 2,
            "content": " 更好的这个视频理解的特征 "
        },
        {
            "from": 845.93,
            "to": 847.47,
            "location": 2,
            "content": " 而用作其他的下游任务 "
        },
        {
            "from": 847.73,
            "to": 848.17,
            "location": 2,
            "content": " 同时呢 "
        },
        {
            "from": 848.17,
            "to": 850.3,
            "location": 2,
            "content": " 他还系统性的研究了这种3 d  "
        },
        {
            "from": 850.3,
            "to": 850.97,
            "location": 2,
            "content": " 卷积神经网络 "
        },
        {
            "from": 850.97,
            "to": 851.67,
            "location": 2,
            "content": " 以及如何 "
        },
        {
            "from": 851.67,
            "to": 853.6,
            "location": 2,
            "content": " 使用到这个视频理解的任务上来 "
        },
        {
            "from": 853.7,
            "to": 854.17,
            "location": 2,
            "content": " 从而为 "
        },
        {
            "from": 854.17,
            "to": 856.2,
            "location": 2,
            "content": " 后续的这一系列的这个3 d 工作呢 "
        },
        {
            "from": 856.2,
            "to": 857.2,
            "location": 2,
            "content": " 做了一个铺垫 "
        },
        {
            "from": 858.2,
            "to": 858.9,
            "location": 2,
            "content": " 那接下来呢 "
        },
        {
            "from": 858.9,
            "to": 860.97,
            "location": 2,
            "content": " 就不得不提一下 i 3 d 这篇论文 "
        },
        {
            "from": 861.27,
            "to": 862.33,
            "location": 2,
            "content": " 这篇论文的意义呢 "
        },
        {
            "from": 862.33,
            "to": 864.33,
            "location": 2,
            "content": " 就是降低了网络训练的难度 "
        },
        {
            "from": 864.53,
            "to": 866.53,
            "location": 2,
            "content": " 提出了一个很好很大的数据集 "
        },
        {
            "from": 866.73,
            "to": 867.87,
            "location": 2,
            "content": " 而且他在标准的 "
        },
        {
            "from": 867.87,
            "to": 869.6,
            "location": 2,
            "content": " 这些bench mark 上的结果呢 "
        },
        {
            "from": 869.77,
            "to": 872.3,
            "location": 2,
            "content": " 都比之前2 d 或者双流的方法要好 "
        },
        {
            "from": 872.4,
            "to": 874.53,
            "location": 2,
            "content": " 从而奠定了3 d 网络的这个地位 "
        },
        {
            "from": 874.93,
            "to": 875.87,
            "location": 2,
            "content": " 我们也可以看出来 "
        },
        {
            "from": 875.87,
            "to": 878.67,
            "location": 2,
            "content": " 这个 c 3 d 呢是发表在 iccv 15上的 "
        },
        {
            "from": 878.73,
            "to": 881.47,
            "location": 2,
            "content": " 而这个 i3d 呢是发表在 c v p r 17上的 "
        },
        {
            "from": 881.47,
            "to": 883.73,
            "location": 2,
            "content": " 这中间呢将近过了两年的时间 "
        },
        {
            "from": 883.87,
            "to": 884.5,
            "location": 2,
            "content": " 所以说明啊 "
        },
        {
            "from": 884.5,
            "to": 885.3,
            "location": 2,
            "content": " 这个3 d 网络 "
        },
        {
            "from": 885.3,
            "to": 887.13,
            "location": 2,
            "content": " 这个调试和这个模型的迭代 "
        },
        {
            "from": 887.13,
            "to": 888.3,
            "location": 2,
            "content": " 还是非常困难的 "
        },
        {
            "from": 888.5,
            "to": 889.97,
            "location": 2,
            "content": " 这就更进一步的体现出了 "
        },
        {
            "from": 889.97,
            "to": 891.57,
            "location": 2,
            "content": " i 3 d 这篇网络的意义 "
        },
        {
            "from": 891.73,
            "to": 894.47,
            "location": 2,
            "content": " 如何能通过这种Bootstrapping 的形式啊 "
        },
        {
            "from": 894.47,
            "to": 895.97,
            "location": 2,
            "content": " 降低网络训练的难度 "
        },
        {
            "from": 896.27,
            "to": 897,
            "location": 2,
            "content": " 那鉴于之前 "
        },
        {
            "from": 897,
            "to": 899.27,
            "location": 2,
            "content": " 我们已经精读过 i 3 d 这篇论文了 "
        },
        {
            "from": 899.37,
            "to": 901.33,
            "location": 2,
            "content": " 对这里呢我就快速的过一下 "
        },
        {
            "from": 901.77,
            "to": 904.2,
            "location": 2,
            "content": " 那其实 i 3 d 这篇论文最大的亮点呢 "
        },
        {
            "from": 904.2,
            "to": 906.1,
            "location": 2,
            "content": " 其实就是在这个字母 i 上啊 "
        },
        {
            "from": 906.1,
            "to": 907.53,
            "location": 2,
            "content": " 也就是这里这个 inflated "
        },
        {
            "from": 907.87,
            "to": 910.17,
            "location": 2,
            "content": " 扩充的膨胀的一个3 d 网络 "
        },
        {
            "from": 910.6,
            "to": 912.37,
            "location": 2,
            "content": " 那之所以作者想到这么做呢 "
        },
        {
            "from": 912.37,
            "to": 914.5,
            "location": 2,
            "content": " 其实主要是看到 c 3 d 这个网络 "
        },
        {
            "from": 914.6,
            "to": 915.8,
            "location": 2,
            "content": " 在这么大的数据集上 "
        },
        {
            "from": 915.8,
            "to": 917.37,
            "location": 2,
            "content": " 去做过预训练之后呢 "
        },
        {
            "from": 917.57,
            "to": 918.93,
            "location": 2,
            "content": " 他的效果不太行 "
        },
        {
            "from": 919,
            "to": 921.07,
            "location": 2,
            "content": " 所以 i 3 d 的作者呢就坚信 "
        },
        {
            "from": 921.07,
            "to": 922.8,
            "location": 2,
            "content": " 那就是我们这里一定要有一个 "
        },
        {
            "from": 922.8,
            "to": 923.33,
            "location": 2,
            "content": " 类似于 image "
        },
        {
            "from": 923.33,
            "to": 925.1,
            "location": 2,
            "content": " net 这样一个预训练的模型 "
        },
        {
            "from": 925.17,
            "to": 926.87,
            "location": 2,
            "content": " 我们要有一个好的初始化 "
        },
        {
            "from": 927.13,
            "to": 929.6,
            "location": 2,
            "content": " 从而呢接下来这个训练呢变得更简单 "
        },
        {
            "from": 929.8,
            "to": 931.67,
            "location": 2,
            "content": " 那之前image net预训练的模型啊 "
        },
        {
            "from": 931.67,
            "to": 932.73,
            "location": 2,
            "content": " 全都是2 d 的 "
        },
        {
            "from": 932.9,
            "to": 934.6,
            "location": 2,
            "content": " 那你现在如果是一个3 d 网络 "
        },
        {
            "from": 934.6,
            "to": 936.6,
            "location": 2,
            "content": " 那怎么把一个2 d 变成3 d 呢 "
        },
        {
            "from": 936.73,
            "to": 938.4,
            "location": 2,
            "content": " 也就是这里的膨胀的意思 "
        },
        {
            "from": 938.4,
            "to": 940.3,
            "location": 2,
            "content": " 他就是要把一个2 d 的网络啊 "
        },
        {
            "from": 940.3,
            "to": 941.13,
            "location": 2,
            "content": " 扩充成一个 "
        },
        {
            "from": 941.13,
            "to": 942,
            "location": 2,
            "content": " 3 d 的网络 "
        },
        {
            "from": 942.17,
            "to": 944.97,
            "location": 2,
            "content": " 而这个网络整体的结构呢是并不改变 "
        },
        {
            "from": 945.37,
            "to": 946,
            "location": 2,
            "content": " 那在这里呢 "
        },
        {
            "from": 946,
            "to": 947.8,
            "location": 2,
            "content": " 我们用这个图3做个例子啊 "
        },
        {
            "from": 947.8,
            "to": 948.8,
            "location": 2,
            "content": " 他这里也就是把一个 "
        },
        {
            "from": 948.8,
            "to": 950.7,
            "location": 2,
            "content": " 2 d 的一个 inception 网络啊 "
        },
        {
            "from": 950.7,
            "to": 953.3,
            "location": 2,
            "content": " 给扩充成了一个3 d 的i3d 网络 "
        },
        {
            "from": 953.87,
            "to": 955.3,
            "location": 2,
            "content": " 那对于一个2 d 的 inception "
        },
        {
            "from": 955.3,
            "to": 956.47,
            "location": 2,
            "content": " v1网络来说呢 "
        },
        {
            "from": 956.47,
            "to": 958.57,
            "location": 2,
            "content": " 其实这里也就是啊conv pooling "
        },
        {
            "from": 958.57,
            "to": 959.77,
            "location": 2,
            "content": " 然后conv conv pooling "
        },
        {
            "from": 959.77,
            "to": 961.73,
            "location": 2,
            "content": " 而接下来都是这种 inception module "
        },
        {
            "from": 962.1,
            "to": 962.97,
            "location": 2,
            "content": " 也就意味着说啊 "
        },
        {
            "from": 962.97,
            "to": 965.47,
            "location": 2,
            "content": " 这个2 d 的 inception 和这个3 d the inception "
        },
        {
            "from": 965.47,
            "to": 967.4,
            "location": 2,
            "content": " 他这个网络结构没有改变 "
        },
        {
            "from": 967.57,
            "to": 969.9,
            "location": 2,
            "content": " 那只是这里的这些卷积核呢从 "
        },
        {
            "from": 970.1,
            "to": 972.6,
            "location": 2,
            "content": " 3*3啊变成了3*3*3啊 "
        },
        {
            "from": 972.6,
            "to": 975.6,
            "location": 2,
            "content": " 或者刚开始这7*7变成7*7*7 啊 "
        },
        {
            "from": 975.6,
            "to": 976.9,
            "location": 2,
            "content": " 像这个pooling 层呢 "
        },
        {
            "from": 976.9,
            "to": 978.77,
            "location": 2,
            "content": " 那刚开始有1*3*3啊 "
        },
        {
            "from": 978.77,
            "to": 981.97,
            "location": 2,
            "content": " 后面呢有3*3*3然后最后呢还有2*2*2 "
        },
        {
            "from": 982.07,
            "to": 984,
            "location": 2,
            "content": " 就是都是由2 d 呢变成了3 d "
        },
        {
            "from": 984.57,
            "to": 985.6,
            "location": 2,
            "content": " 那这样一个好处呢 "
        },
        {
            "from": 985.6,
            "to": 987.93,
            "location": 2,
            "content": " 就是说因为你2 d 网络和3 d 网络 "
        },
        {
            "from": 987.93,
            "to": 990.37,
            "location": 2,
            "content": " 共享了一个同样的一个 meta 结构啊 "
        },
        {
            "from": 990.37,
            "to": 991.8,
            "location": 2,
            "content": " 就是总体架构一样 "
        },
        {
            "from": 991.9,
            "to": 992.67,
            "location": 2,
            "content": " 那这样呢 "
        },
        {
            "from": 992.67,
            "to": 994.6,
            "location": 2,
            "content": " 你就能想到一种比较简单的方式 "
        },
        {
            "from": 994.6,
            "to": 996.47,
            "location": 2,
            "content": " 能把2 d 已经训练好的参数呢 "
        },
        {
            "from": 996.47,
            "to": 998.27,
            "location": 2,
            "content": " 移植到3 d 的模型上来 "
        },
        {
            "from": 998.57,
            "to": 1001.47,
            "location": 2,
            "content": " 那这个呢对于 c 3 d 网络他就做不到啊 "
        },
        {
            "from": 1001.47,
            "to": 1002.27,
            "location": 2,
            "content": " c 3 d 网络 "
        },
        {
            "from": 1002.27,
            "to": 1004.97,
            "location": 2,
            "content": " 虽然我们之前说过他有点像 vgg 16啊 "
        },
        {
            "from": 1004.97,
            "to": 1006.27,
            "location": 2,
            "content": " 基本上就是按 vgg "
        },
        {
            "from": 1006.27,
            "to": 1008.57,
            "location": 2,
            "content": " 那个网络的这个设计理念来设计的 "
        },
        {
            "from": 1008.87,
            "to": 1010.67,
            "location": 2,
            "content": " 但是呢因为他每一个 block "
        },
        {
            "from": 1010.67,
            "to": 1012.37,
            "location": 2,
            "content": " 里面都少了一层卷积 "
        },
        {
            "from": 1012.57,
            "to": 1014.37,
            "location": 2,
            "content": " 所以导致他没法很简单的 "
        },
        {
            "from": 1014.37,
            "to": 1016.27,
            "location": 2,
            "content": " 把这个 vgg 的2 d 网络呢 "
        },
        {
            "from": 1016.27,
            "to": 1016.97,
            "location": 2,
            "content": " 参数啊 "
        },
        {
            "from": 1016.97,
            "to": 1019.53,
            "location": 2,
            "content": " 移植到这个他的3d c3d 网络中来 "
        },
        {
            "from": 1019.73,
            "to": 1021.5,
            "location": 2,
            "content": " 这些都导致了他们没法使用 "
        },
        {
            "from": 1021.5,
            "to": 1023.4,
            "location": 2,
            "content": " 这种image net的预训练的参数啊 "
        },
        {
            "from": 1023.4,
            "to": 1025.2,
            "location": 2,
            "content": " 从而导致了他们很难优化啊 "
        },
        {
            "from": 1025.2,
            "to": 1026.9,
            "location": 2,
            "content": " 很难得到一个更好的结果 "
        },
        {
            "from": 1027.2,
            "to": 1027.73,
            "location": 2,
            "content": " 所以说呢 "
        },
        {
            "from": 1027.73,
            "to": 1029.57,
            "location": 2,
            "content": " i3d 这篇论文最大的亮点呢 "
        },
        {
            "from": 1029.57,
            "to": 1030.7,
            "location": 2,
            "content": " 就是这个 inflation "
        },
        {
            "from": 1030.7,
            "to": 1033.4,
            "location": 2,
            "content": " 这个操作不仅不用设计一个网络啊 "
        },
        {
            "from": 1033.4,
            "to": 1036.17,
            "location": 2,
            "content": " 直接把一个2 d 网络扩充成3 d 就可以了 "
        },
        {
            "from": 1036.2,
            "to": 1037.8,
            "location": 2,
            "content": " 而且还能利用2 d 网络 "
        },
        {
            "from": 1037.8,
            "to": 1039.27,
            "location": 2,
            "content": " 预训练好的模型参数 "
        },
        {
            "from": 1039.3,
            "to": 1040.93,
            "location": 2,
            "content": " 从而简化这个训练过程 "
        },
        {
            "from": 1041.1,
            "to": 1043.17,
            "location": 2,
            "content": " 最后呢也能利用更少的训练时间 "
        },
        {
            "from": 1043.17,
            "to": 1044.37,
            "location": 2,
            "content": " 达到更好的效果 "
        },
        {
            "from": 1045.1,
            "to": 1046.73,
            "location": 2,
            "content": " 那如果我们快速看一下 "
        },
        {
            "from": 1046.77,
            "to": 1047.67,
            "location": 2,
            "content": " i 3 d 网络 "
        },
        {
            "from": 1047.67,
            "to": 1049.33,
            "location": 2,
            "content": " 在 ucf 101和 hmdb "
        },
        {
            "from": 1049.33,
            "to": 1051.2,
            "location": 2,
            "content": " 51这两个数据集上的结果呢 "
        },
        {
            "from": 1051.4,
            "to": 1053.3,
            "location": 2,
            "content": " 我们就可以发现他的这个结果啊 "
        },
        {
            "from": 1053.3,
            "to": 1055.77,
            "location": 2,
            "content": " 是远远比之前的方法都要高的 "
        },
        {
            "from": 1056,
            "to": 1058.47,
            "location": 2,
            "content": " 那如果我们就拿3 d 网络之间做对比呢 "
        },
        {
            "from": 1058.47,
            "to": 1059.3,
            "location": 2,
            "content": " 我们可以看到啊 "
        },
        {
            "from": 1059.3,
            "to": 1061.97,
            "location": 2,
            "content": " 这个 rgb i3d 的这个结果啊 "
        },
        {
            "from": 1061.97,
            "to": 1064.57,
            "location": 2,
            "content": " 就比对应的这个 c 3 d 用 rgb 的结果呢 "
        },
        {
            "from": 1064.57,
            "to": 1065.87,
            "location": 2,
            "content": " 高了大概是3个点 "
        },
        {
            "from": 1066,
            "to": 1068.33,
            "location": 2,
            "content": " 所以说这个提升啊是相当显著的 "
        },
        {
            "from": 1068.77,
            "to": 1070.13,
            "location": 2,
            "content": " 而且 i 3 d 这篇论文呢 "
        },
        {
            "from": 1070.13,
            "to": 1071.9,
            "location": 2,
            "content": " 还有另外几个意义所在啊 "
        },
        {
            "from": 1071.9,
            "to": 1072.57,
            "location": 2,
            "content": " 第一个意义呢 "
        },
        {
            "from": 1072.57,
            "to": 1075.8,
            "location": 2,
            "content": " 就是他还是做了这种 rgb i3d 和 flow i3d "
        },
        {
            "from": 1075.8,
            "to": 1077.67,
            "location": 2,
            "content": " 就是即使他是一个3 d 网络 "
        },
        {
            "from": 1077.67,
            "to": 1078.93,
            "location": 2,
            "content": " 他还是用了光流 "
        },
        {
            "from": 1079.17,
            "to": 1080.53,
            "location": 2,
            "content": " 这就我们之前说的啊 "
        },
        {
            "from": 1080.53,
            "to": 1081.8,
            "location": 2,
            "content": " 即使你是一个3 d 网络 "
        },
        {
            "from": 1081.8,
            "to": 1082.9,
            "location": 2,
            "content": " 你用了光流之后呢 "
        },
        {
            "from": 1082.9,
            "to": 1084.7,
            "location": 2,
            "content": " 你的这个效果还是会很好 "
        },
        {
            "from": 1084.77,
            "to": 1086.4,
            "location": 2,
            "content": " 所以光流不是没用啊 "
        },
        {
            "from": 1086.4,
            "to": 1088.3,
            "location": 2,
            "content": " 只是计算代价太高而已 "
        },
        {
            "from": 1088.6,
            "to": 1089.53,
            "location": 2,
            "content": " 那第二个意义呢 "
        },
        {
            "from": 1089.53,
            "to": 1090.67,
            "location": 2,
            "content": " 就是说 i 3 d 网络 "
        },
        {
            "from": 1090.67,
            "to": 1093.27,
            "location": 2,
            "content": " 通过简单的这种膨胀扩充的这个操作 "
        },
        {
            "from": 1093.27,
            "to": 1095.1,
            "location": 2,
            "content": " 能大幅提高这个实验结果 "
        },
        {
            "from": 1095.3,
            "to": 1096.7,
            "location": 2,
            "content": " 从而把这个 ucf 101和 "
        },
        {
            "from": 1096.7,
            "to": 1098.27,
            "location": 2,
            "content": " hmdb 51这两个数据集呢 "
        },
        {
            "from": 1098.27,
            "to": 1099.53,
            "location": 2,
            "content": " 基本上都刷爆了 "
        },
        {
            "from": 1099.6,
            "to": 1100.6,
            "location": 2,
            "content": " 所以在这之后呢 "
        },
        {
            "from": 1100.6,
            "to": 1102.5,
            "location": 2,
            "content": " 大家基本也就不用这两个数据集 "
        },
        {
            "from": 1102.5,
            "to": 1103.77,
            "location": 2,
            "content": " 转而去用他们提出的 "
        },
        {
            "from": 1103.77,
            "to": 1105.53,
            "location": 2,
            "content": " 新的这个 k 400数据集了 "
        },
        {
            "from": 1105.8,
            "to": 1107.67,
            "location": 2,
            "content": " 他相当于呢是一己之力 "
        },
        {
            "from": 1107.7,
            "to": 1109.47,
            "location": 2,
            "content": " 把整个这个视频理解领域呢 "
        },
        {
            "from": 1109.47,
            "to": 1111.67,
            "location": 2,
            "content": " 从双流变成了3 d 网络 "
        },
        {
            "from": 1111.7,
            "to": 1113.53,
            "location": 2,
            "content": " 而且把这个做测试的数据集呢 "
        },
        {
            "from": 1113.53,
            "to": 1116.13,
            "location": 2,
            "content": " 也从 ucf 101变成了 k 400数据集 "
        },
        {
            "from": 1116.9,
            "to": 1119.07,
            "location": 2,
            "content": " i3d 论文带来的第三个影响呢 "
        },
        {
            "from": 1119.07,
            "to": 1121.33,
            "location": 2,
            "content": " 就是说他证明了从这个2 d 网络 "
        },
        {
            "from": 1121.57,
            "to": 1123.7,
            "location": 2,
            "content": " 迁移到3 d 网络的这种有效性 "
        },
        {
            "from": 1123.9,
            "to": 1126.53,
            "location": 2,
            "content": " 所以在 i3d 网络把2 d 的inception net "
        },
        {
            "from": 1126.53,
            "to": 1128.67,
            "location": 2,
            "content": " 转成3 d 的 inception net之后呢 "
        },
        {
            "from": 1128.67,
            "to": 1131.13,
            "location": 2,
            "content": " 很快就有其他的工作就跟进了 "
        },
        {
            "from": 1131.5,
            "to": 1133.13,
            "location": 2,
            "content": " 那比如说在 cvp 18的时候呢 "
        },
        {
            "from": 1133.13,
            "to": 1134.57,
            "location": 2,
            "content": " 大家就把这个 Resnet "
        },
        {
            "from": 1134.57,
            "to": 1135.97,
            "location": 2,
            "content": " 就全都变成这个 Resnet "
        },
        {
            "from": 1135.97,
            "to": 1138.57,
            "location": 2,
            "content": " 3 d 了然后呢 eccv 18的时候呢 "
        },
        {
            "from": 1138.57,
            "to": 1141.1,
            "location": 2,
            "content": " 就一篇论文把 resnext 的思想应用过来 "
        },
        {
            "from": 1141.1,
            "to": 1142.87,
            "location": 2,
            "content": " 变成了叫 multifiber network "
        },
        {
            "from": 1142.87,
            "to": 1144.13,
            "location": 2,
            "content": " 也就是 mfnet "
        },
        {
            "from": 1144.53,
            "to": 1145.17,
            "location": 2,
            "content": " 然后后来呢 "
        },
        {
            "from": 1145.17,
            "to": 1146.37,
            "location": 2,
            "content": " 大家又把2 d 的这个 "
        },
        {
            "from": 1146.5,
            "to": 1147.8,
            "location": 2,
            "content": " senat 里这种 channel "
        },
        {
            "from": 1147.8,
            "to": 1149.7,
            "location": 2,
            "content": " attention的思想啊借鉴了过来 "
        },
        {
            "from": 1149.77,
            "to": 1152.77,
            "location": 2,
            "content": " 然后变成了 cpr 19的一篇 stcnet 的文章 "
        },
        {
            "from": 1153.37,
            "to": 1155.7,
            "location": 2,
            "content": " 所以说是非常里程碑式的一个工作 "
        },
        {
            "from": 1156.57,
            "to": 1158.47,
            "location": 2,
            "content": " 那说完了 c 3 d 和 i 3 d "
        },
        {
            "from": 1158.7,
            "to": 1161.1,
            "location": 2,
            "content": " 那基本上3 d 网络的这个基本结构呢 "
        },
        {
            "from": 1161.1,
            "to": 1161.93,
            "location": 2,
            "content": " 就定好了 "
        },
        {
            "from": 1162.07,
            "to": 1164.2,
            "location": 2,
            "content": " 接下来呢就是做各种各样的改进了 "
        },
        {
            "from": 1164.37,
            "to": 1165.73,
            "location": 2,
            "content": " 那对于视频问题来说 "
        },
        {
            "from": 1165.73,
            "to": 1166.77,
            "location": 2,
            "content": " 大家更关心的呢 "
        },
        {
            "from": 1166.77,
            "to": 1168.8,
            "location": 2,
            "content": " 肯定是时序上该怎么去建模 "
        },
        {
            "from": 1168.93,
            "to": 1170.6,
            "location": 2,
            "content": " 或者说我怎么能处理好更 "
        },
        {
            "from": 1170.6,
            "to": 1172.13,
            "location": 2,
            "content": " 长的这个时间序列呢 "
        },
        {
            "from": 1172.27,
            "to": 1174.07,
            "location": 2,
            "content": " 那对于之前的这个传统方法 "
        },
        {
            "from": 1174.07,
            "to": 1176.2,
            "location": 2,
            "content": " 或者对于2 d 网络双流方法来说呢 "
        },
        {
            "from": 1176.2,
            "to": 1178.67,
            "location": 2,
            "content": " 大家就是在后面加一个 lstm 就行了 "
        },
        {
            "from": 1178.73,
            "to": 1179.67,
            "location": 2,
            "content": " 那3 d 这边呢 "
        },
        {
            "from": 1179.67,
            "to": 1182.33,
            "location": 2,
            "content": " 当然也可以在后面加一个 lstm 没问题 "
        },
        {
            "from": 1182.7,
            "to": 1185.37,
            "location": 2,
            "content": " 但是呢在3 d 网络火起来的同时啊 "
        },
        {
            "from": 1185.37,
            "to": 1188.1,
            "location": 2,
            "content": " 在 nlp 领域呢发生了一件巨大的事情 "
        },
        {
            "from": 1188.17,
            "to": 1190.37,
            "location": 2,
            "content": " 那就是transformer这个模型出来了 "
        },
        {
            "from": 1190.4,
            "to": 1191.9,
            "location": 2,
            "content": " 也就是说 self attention啊 "
        },
        {
            "from": 1191.9,
            "to": 1193.97,
            "location": 2,
            "content": " 自注意力这个操作被提出来了 "
        },
        {
            "from": 1193.97,
            "to": 1195.6,
            "location": 2,
            "content": " 而且效果呢特别的好 "
        },
        {
            "from": 1195.93,
            "to": 1197.4,
            "location": 2,
            "content": " 那自注意力操作我们也知道 "
        },
        {
            "from": 1197.4,
            "to": 1197.57,
            "location": 2,
            "content": " 他 "
        },
        {
            "from": 1197.57,
            "to": 1200.27,
            "location": 2,
            "content": " 本身就是用来学习这种远距离信息的 "
        },
        {
            "from": 1200.5,
            "to": 1202.97,
            "location": 2,
            "content": " 正好跟这个 lstm 的作用呢不谋而合 "
        },
        {
            "from": 1203.07,
            "to": 1205.27,
            "location": 2,
            "content": " 所以说non local 的作者可能就想了一下 "
        },
        {
            "from": 1205.27,
            "to": 1207.13,
            "location": 2,
            "content": " 那我为什么不把这个 self attention "
        },
        {
            "from": 1207.13,
            "to": 1208.8,
            "location": 2,
            "content": " 拿来替代一下 lstm 呢 "
        },
        {
            "from": 1208.9,
            "to": 1210.5,
            "location": 2,
            "content": " 看看这个自注意力在视觉里 "
        },
        {
            "from": 1210.5,
            "to": 1211.97,
            "location": 2,
            "content": " 到底应用的好不好呢 "
        },
        {
            "from": 1212.33,
            "to": 1213.13,
            "location": 2,
            "content": " 结果证明呢 "
        },
        {
            "from": 1213.13,
            "to": 1215.07,
            "location": 2,
            "content": " 把自注意力啊用到视觉领域 "
        },
        {
            "from": 1215.07,
            "to": 1216.6,
            "location": 2,
            "content": " 效果还是非常不错的 "
        },
        {
            "from": 1216.77,
            "to": 1219.33,
            "location": 2,
            "content": " 所以说在 non local 这篇论文出来之后呢 "
        },
        {
            "from": 1219.37,
            "to": 1221.6,
            "location": 2,
            "content": " 很快啊视觉的别的一些下游任务 "
        },
        {
            "from": 1221.6,
            "to": 1223.37,
            "location": 2,
            "content": " 比如说检测和分割啊 "
        },
        {
            "from": 1223.37,
            "to": 1225.3,
            "location": 2,
            "content": " 全都是把non local 这个算子啊 "
        },
        {
            "from": 1225.3,
            "to": 1227.27,
            "location": 2,
            "content": " 应用到别的这个网络之中了啊 "
        },
        {
            "from": 1227.27,
            "to": 1228.77,
            "location": 2,
            "content": " 尤其是对于分割而言 "
        },
        {
            "from": 1228.77,
            "to": 1230.93,
            "location": 2,
            "content": " 2019年啊简直都卷疯了 "
        },
        {
            "from": 1231.2,
            "to": 1233.2,
            "location": 2,
            "content": " 不知道有多少论文把这个自注意力啊 "
        },
        {
            "from": 1233.2,
            "to": 1234.17,
            "location": 2,
            "content": " 尝试加到分割 "
        },
        {
            "from": 1234.17,
            "to": 1235.73,
            "location": 2,
            "content": " 各种不同的这个网络结构里 "
        },
        {
            "from": 1235.73,
            "to": 1237.5,
            "location": 2,
            "content": " 然后做各种不同的变体啊 "
        },
        {
            "from": 1237.5,
            "to": 1239.53,
            "location": 2,
            "content": " 或者说加速啊或者说提点啊 "
        },
        {
            "from": 1239.87,
            "to": 1241.2,
            "location": 2,
            "content": " 总之是五花八门 "
        },
        {
            "from": 1241.57,
            "to": 1243.53,
            "location": 2,
            "content": " 然后在后面呢就有了vision transformer "
        },
        {
            "from": 1243.57,
            "to": 1244.57,
            "location": 2,
            "content": " 然后又有了transformer "
        },
        {
            "from": 1244.57,
            "to": 1247,
            "location": 2,
            "content": " 现在在 cv 这个领域里呢大杀四方 "
        },
        {
            "from": 1247.17,
            "to": 1247.53,
            "location": 2,
            "content": " 总体 "
        },
        {
            "from": 1247.53,
            "to": 1250.1,
            "location": 2,
            "content": " 而言呢就是自注意力这个操作真的有效 "
        },
        {
            "from": 1250.67,
            "to": 1251.6,
            "location": 2,
            "content": " 那在摘要里呢 "
        },
        {
            "from": 1251.6,
            "to": 1254.17,
            "location": 2,
            "content": " 作者就说无论是这个卷积操作啊 "
        },
        {
            "from": 1254.17,
            "to": 1255.87,
            "location": 2,
            "content": " 还是递归的这种操作 "
        },
        {
            "from": 1255.97,
            "to": 1257.1,
            "location": 2,
            "content": " 他呢每次处理 "
        },
        {
            "from": 1257.1,
            "to": 1257.8,
            "location": 2,
            "content": " 都是在一个很 "
        },
        {
            "from": 1257.8,
            "to": 1259.7,
            "location": 2,
            "content": " 局部的区域里进行处理的 "
        },
        {
            "from": 1259.73,
            "to": 1261.27,
            "location": 2,
            "content": " 那如果我们能看到更长 "
        },
        {
            "from": 1261.27,
            "to": 1262.93,
            "location": 2,
            "content": " 或者更多的这个上下文呢 "
        },
        {
            "from": 1262.93,
            "to": 1265.17,
            "location": 2,
            "content": " 肯定是对各种任务都会有帮助的 "
        },
        {
            "from": 1265.27,
            "to": 1266.37,
            "location": 2,
            "content": " 所以在这篇论文里呢 "
        },
        {
            "from": 1266.37,
            "to": 1268.67,
            "location": 2,
            "content": " 作者就提出来了一个不是局部操作啊 "
        },
        {
            "from": 1268.67,
            "to": 1270.87,
            "location": 2,
            "content": " 也就是这里说到 non local 的一个算子 "
        },
        {
            "from": 1271,
            "to": 1272.4,
            "location": 2,
            "content": " 他呢是一个可以泛化的 "
        },
        {
            "from": 1272.4,
            "to": 1274.93,
            "location": 2,
            "content": " 而且可以即插即用的一个 building block 啊 "
        },
        {
            "from": 1274.93,
            "to": 1275.97,
            "location": 2,
            "content": " 就是一个模块 "
        },
        {
            "from": 1276.17,
            "to": 1277.33,
            "location": 2,
            "content": " 而这个模块的作用呢 "
        },
        {
            "from": 1277.33,
            "to": 1279.9,
            "location": 2,
            "content": " 就是用来建模这种长距离的信息的 "
        },
        {
            "from": 1280.27,
            "to": 1281.33,
            "location": 2,
            "content": " 然后作者接下来说呢 "
        },
        {
            "from": 1281.33,
            "to": 1283.3,
            "location": 2,
            "content": " 他们呢是受到这个 cv 里的 "
        },
        {
            "from": 1283.3,
            "to": 1284.17,
            "location": 2,
            "content": " 之前有一个方法 "
        },
        {
            "from": 1284.17,
            "to": 1286.1,
            "location": 2,
            "content": " 叫做 non local means 的方法 "
        },
        {
            "from": 1286.2,
            "to": 1288.73,
            "location": 2,
            "content": " 所以才想到用这个 non local 这个算子 "
        },
        {
            "from": 1288.77,
            "to": 1290.53,
            "location": 2,
            "content": " 去做这种长距离建模的 "
        },
        {
            "from": 1290.87,
            "to": 1292.1,
            "location": 2,
            "content": " 然后作者最后就说呢 "
        },
        {
            "from": 1292.1,
            "to": 1294.47,
            "location": 2,
            "content": " 因为这个模块是一个即插即用的模块 "
        },
        {
            "from": 1294.53,
            "to": 1297.07,
            "location": 2,
            "content": " 所以我可以把它运用到各种任务里去 "
        },
        {
            "from": 1297.33,
            "to": 1298.57,
            "location": 2,
            "content": " 首先我们在视频这边呢 "
        },
        {
            "from": 1298.57,
            "to": 1300.13,
            "location": 2,
            "content": " 就取得了不错的效果 "
        },
        {
            "from": 1300.5,
            "to": 1302.3,
            "location": 2,
            "content": " 其次呢我们还在这个检测啊 "
        },
        {
            "from": 1302.3,
            "to": 1304.3,
            "location": 2,
            "content": " 分割啊还有这个姿态检测啊 "
        },
        {
            "from": 1304.3,
            "to": 1305.97,
            "location": 2,
            "content": " 全都取得了很好的效果 "
        },
        {
            "from": 1306.1,
            "to": 1307.87,
            "location": 2,
            "content": " 这也可以说是凯明或者是菲尔 "
        },
        {
            "from": 1307.87,
            "to": 1308.4,
            "location": 2,
            "content": " 这个工作 "
        },
        {
            "from": 1308.4,
            "to": 1309.7,
            "location": 2,
            "content": " 一系列的这风格啊 "
        },
        {
            "from": 1309.77,
            "to": 1311.5,
            "location": 2,
            "content": " 就是实验非常的详尽 "
        },
        {
            "from": 1311.7,
            "to": 1313.87,
            "location": 2,
            "content": " 那每次基本上就是把能做的任务呢 "
        },
        {
            "from": 1313.87,
            "to": 1315,
            "location": 2,
            "content": " 全都给你做了个遍 "
        },
        {
            "from": 1315.3,
            "to": 1316.97,
            "location": 2,
            "content": " 让审稿人呢无话可说 "
        },
        {
            "from": 1317.67,
            "to": 1320.5,
            "location": 2,
            "content": " 那具体这篇论文提出的这个 non local block "
        },
        {
            "from": 1320.5,
            "to": 1321.57,
            "location": 2,
            "content": " 到底长什么样呢 "
        },
        {
            "from": 1321.57,
            "to": 1323.57,
            "location": 2,
            "content": " 啊其实他就画在这个图2里 "
        },
        {
            "from": 1323.67,
            "to": 1324.9,
            "location": 2,
            "content": " 而且他这个图2里呢 "
        },
        {
            "from": 1324.9,
            "to": 1327.53,
            "location": 2,
            "content": " 画的是一个 spacetime 的 non local block 这 "
        },
        {
            "from": 1327.53,
            "to": 1328.9,
            "location": 2,
            "content": " 是一个时空的算子 "
        },
        {
            "from": 1329.17,
            "to": 1331.07,
            "location": 2,
            "content": " 也就是用来做视频理解的 "
        },
        {
            "from": 1331.5,
            "to": 1331.9,
            "location": 2,
            "content": " 但是呢 "
        },
        {
            "from": 1331.9,
            "to": 1334.2,
            "location": 2,
            "content": " 我们先不管他是做3 d 的还是做2 d 的 "
        },
        {
            "from": 1334.2,
            "to": 1335.97,
            "location": 2,
            "content": " 如果我们只看这个结构呢 "
        },
        {
            "from": 1336.07,
            "to": 1337.27,
            "location": 2,
            "content": " 其实我们一眼就发现 "
        },
        {
            "from": 1337.27,
            "to": 1339.4,
            "location": 2,
            "content": " 他就是一个自注意力操作啊 "
        },
        {
            "from": 1339.4,
            "to": 1340.73,
            "location": 2,
            "content": " 先是一个特征进来 "
        },
        {
            "from": 1340.73,
            "to": 1343.47,
            "location": 2,
            "content": " 然后呢通过这个 kqv 对吧  "
        },
        {
            "from": 1343.47,
            "to": 1346.17,
            "location": 2,
            "content": " key query 和 value network 啊得到三个特征 "
        },
        {
            "from": 1346.33,
            "to": 1348.73,
            "location": 2,
            "content": " 那这三个特征呢全都是由自己变来的 "
        },
        {
            "from": 1349.13,
            "to": 1349.77,
            "location": 2,
            "content": " 然后呢 "
        },
        {
            "from": 1349.77,
            "to": 1352.2,
            "location": 2,
            "content": " key 和 query 呢去做一下这个attention操作啊 "
        },
        {
            "from": 1352.2,
            "to": 1353.57,
            "location": 2,
            "content": " 就得到了一个自注意力 "
        },
        {
            "from": 1353.7,
            "to": 1355.07,
            "location": 2,
            "content": " 然后再拿这个自注意力呢 "
        },
        {
            "from": 1355.07,
            "to": 1357.27,
            "location": 2,
            "content": " 去和这个 value 到做这个加权平均 "
        },
        {
            "from": 1357.53,
            "to": 1358.77,
            "location": 2,
            "content": " 然后得到最后的这个值 "
        },
        {
            "from": 1358.77,
            "to": 1361.07,
            "location": 2,
            "content": " 之后呢再有一个这个残差连接啊 "
        },
        {
            "from": 1361.07,
            "to": 1362.6,
            "location": 2,
            "content": " 最后得到最后的输出 "
        },
        {
            "from": 1362.97,
            "to": 1363.53,
            "location": 2,
            "content": " 所以说呢 "
        },
        {
            "from": 1363.53,
            "to": 1366.17,
            "location": 2,
            "content": " 完全就是一个标准的自注意力的模块 "
        },
        {
            "from": 1366.33,
            "to": 1366.8,
            "location": 2,
            "content": " 这里呢 "
        },
        {
            "from": 1366.8,
            "to": 1368.73,
            "location": 2,
            "content": " 只不过是为了适配这个视频理解 "
        },
        {
            "from": 1368.73,
            "to": 1371.27,
            "location": 2,
            "content": " 所以把这个2 d 的操作呢全都变成了3 d "
        },
        {
            "from": 1371.73,
            "to": 1373.6,
            "location": 2,
            "content": " 那鉴于我们这个论文精读系列 "
        },
        {
            "from": 1373.6,
            "to": 1375.17,
            "location": 2,
            "content": " 之前已经讲过transformer "
        },
        {
            "from": 1375.17,
            "to": 1376.73,
            "location": 2,
            "content": " 而且讲过vision transformer "
        },
        {
            "from": 1376.73,
            "to": 1378.93,
            "location": 2,
            "content": " 所以对于自注意力呢大家应该都不陌生 "
        },
        {
            "from": 1378.97,
            "to": 1381,
            "location": 2,
            "content": " 那这里我就不再过多复述了 "
        },
        {
            "from": 1381.67,
            "to": 1383.47,
            "location": 2,
            "content": " 那我们先来看一些消融实验啊 "
        },
        {
            "from": 1383.47,
            "to": 1385.1,
            "location": 2,
            "content": " 其实这个消融实验很重要 "
        },
        {
            "from": 1385.17,
            "to": 1386.53,
            "location": 2,
            "content": " 因为这也体现了作者 "
        },
        {
            "from": 1386.53,
            "to": 1387.77,
            "location": 2,
            "content": " 而是怎么一步一步 "
        },
        {
            "from": 1387.77,
            "to": 1389.57,
            "location": 2,
            "content": " 设计出来这个网络结构的 "
        },
        {
            "from": 1390.07,
            "to": 1391.13,
            "location": 2,
            "content": " 比如首先第一步 "
        },
        {
            "from": 1391.13,
            "to": 1393,
            "location": 2,
            "content": " 就是这个自注意力该怎么算呢 "
        },
        {
            "from": 1393.1,
            "to": 1394.93,
            "location": 2,
            "content": " 那作者就在这个表 a 里呢 "
        },
        {
            "from": 1395.1,
            "to": 1396.57,
            "location": 2,
            "content": " 就列出了几种方式啊 "
        },
        {
            "from": 1396.57,
            "to": 1398.9,
            "location": 2,
            "content": " 比如说到底是用gaussian啊还是用 dot product "
        },
        {
            "from": 1398.9,
            "to": 1400.33,
            "location": 2,
            "content": " 还是直接 concat 一下呀 "
        },
        {
            "from": 1400.47,
            "to": 1401.07,
            "location": 2,
            "content": " 那最后呢 "
        },
        {
            "from": 1401.07,
            "to": 1403.87,
            "location": 2,
            "content": " 发现用 dot product 这个效果是最好的 "
        },
        {
            "from": 1403.97,
            "to": 1404.7,
            "location": 2,
            "content": " 但其实呢 "
        },
        {
            "from": 1404.7,
            "to": 1407.07,
            "location": 2,
            "content": " transformer 默认的呢也就是 dot product "
        },
        {
            "from": 1407.57,
            "to": 1409.3,
            "location": 2,
            "content": " 接下来确认使用 dot product "
        },
        {
            "from": 1409.3,
            "to": 1411.1,
            "location": 2,
            "content": " 来做这个自注意力之后呢 "
        },
        {
            "from": 1411.3,
            "to": 1412.3,
            "location": 2,
            "content": " 那接下一个问题 "
        },
        {
            "from": 1412.3,
            "to": 1414.37,
            "location": 2,
            "content": " 就是说我们怎么把这个 non local block "
        },
        {
            "from": 1414.37,
            "to": 1414.6,
            "location": 2,
            "content": " 插 "
        },
        {
            "from": 1414.6,
            "to": 1416.93,
            "location": 2,
            "content": " 入到这个已有的这个网络结构之中呢 "
        },
        {
            "from": 1417.1,
            "to": 1419.2,
            "location": 2,
            "content": " 那像之前作者在摘要里已经说了 "
        },
        {
            "from": 1419.2,
            "to": 1420.87,
            "location": 2,
            "content": " 因为这是一个 plug and play 的啊 "
        },
        {
            "from": 1420.87,
            "to": 1422.77,
            "location": 2,
            "content": " 就是即插即用的一个网络结构 "
        },
        {
            "from": 1422.8,
            "to": 1424.4,
            "location": 2,
            "content": " 所以你插在哪都可以 "
        },
        {
            "from": 1424.8,
            "to": 1426.9,
            "location": 2,
            "content": " 那作者这里呢先做了简单的尝试 "
        },
        {
            "from": 1426.9,
            "to": 1429.3,
            "location": 2,
            "content": " 就是我先加一层这个non logal block "
        },
        {
            "from": 1429.33,
            "to": 1430.4,
            "location": 2,
            "content": " 我先试一试啊 "
        },
        {
            "from": 1430.4,
            "to": 1431.77,
            "location": 2,
            "content": " 把它加到哪最好 "
        },
        {
            "from": 1431.97,
            "to": 1433.07,
            "location": 2,
            "content": " 它呢就在每一个 "
        },
        {
            "from": 1433.07,
            "to": 1434.77,
            "location": 2,
            "content": " 这个 res 就 block 后面啊 "
        },
        {
            "from": 1434.77,
            "to": 1435.67,
            "location": 2,
            "content": " 因为对于一个 resnet "
        },
        {
            "from": 1435.67,
            "to": 1437.3,
            "location": 2,
            "content": " 来说他有4个 block 吗 "
        },
        {
            "from": 1437.3,
            "to": 1439.17,
            "location": 2,
            "content": " res 2345 4个 block "
        },
        {
            "from": 1439.6,
            "to": 1441.77,
            "location": 2,
            "content": " 他呢就尝试要么在这个2后面加一个 "
        },
        {
            "from": 1441.77,
            "to": 1443,
            "location": 2,
            "content": " 要么就在3后面加一个 "
        },
        {
            "from": 1443,
            "to": 1444.8,
            "location": 2,
            "content": " 看看到底加在哪一个 block 上 "
        },
        {
            "from": 1444.8,
            "to": 1445.93,
            "location": 2,
            "content": " 这个效果最好 "
        },
        {
            "from": 1446.07,
            "to": 1447.07,
            "location": 2,
            "content": " 然后作者就发现 "
        },
        {
            "from": 1447.07,
            "to": 1449.1,
            "location": 2,
            "content": " 加在这个234上这个效果呢 "
        },
        {
            "from": 1449.1,
            "to": 1452.37,
            "location": 2,
            "content": " 不错啊加在5上这个效果不太行啊 "
        },
        {
            "from": 1452.37,
            "to": 1453.07,
            "location": 2,
            "content": " 作者觉得呢 "
        },
        {
            "from": 1453.07,
            "to": 1454.7,
            "location": 2,
            "content": " 这个加在5上不行的原因呢 "
        },
        {
            "from": 1454.7,
            "to": 1456.87,
            "location": 2,
            "content": " 是因为5的这个特征图啊太小了 "
        },
        {
            "from": 1456.9,
            "to": 1458.5,
            "location": 2,
            "content": " 他已经没有多少这个空间信息 "
        },
        {
            "from": 1458.5,
            "to": 1459.3,
            "location": 2,
            "content": " 在里面了 "
        },
        {
            "from": 1459.47,
            "to": 1461.8,
            "location": 2,
            "content": " 这也没有什么远距离的特征你可以学 "
        },
        {
            "from": 1461.97,
            "to": 1463.47,
            "location": 2,
            "content": " 那这个 non local 的这个操作呢 "
        },
        {
            "from": 1463.47,
            "to": 1465.1,
            "location": 2,
            "content": " 就起不到他应有的作用 "
        },
        {
            "from": 1465.2,
            "to": 1465.73,
            "location": 2,
            "content": " 然后呢 "
        },
        {
            "from": 1465.73,
            "to": 1467.8,
            "location": 2,
            "content": " 又因为刚才说的这个自注意力操作呢 "
        },
        {
            "from": 1467.8,
            "to": 1468.6,
            "location": 2,
            "content": " 比较贵啊 "
        },
        {
            "from": 1468.6,
            "to": 1470.33,
            "location": 2,
            "content": " 所以作者也不想在这个 res 2 "
        },
        {
            "from": 1470.33,
            "to": 1472.2,
            "location": 2,
            "content": " 就是特别早的腾出来的时候呢 "
        },
        {
            "from": 1472.2,
            "to": 1473.93,
            "location": 2,
            "content": " 去做这个 non local 操作 "
        },
        {
            "from": 1474.33,
            "to": 1475.8,
            "location": 2,
            "content": " 所以作者最后就决定啊 "
        },
        {
            "from": 1475.8,
            "to": 1477.9,
            "location": 2,
            "content": " 就在这个 res 3和 res 4上啊 "
        },
        {
            "from": 1477.9,
            "to": 1479.5,
            "location": 2,
            "content": " 去做这种non local 的操作 "
        },
        {
            "from": 1479.77,
            "to": 1481.67,
            "location": 2,
            "content": " 那接下来呢又有新的问题了 "
        },
        {
            "from": 1481.67,
            "to": 1483.73,
            "location": 2,
            "content": " 那之前呢你是给整个网络里 "
        },
        {
            "from": 1483.73,
            "to": 1485.3,
            "location": 2,
            "content": " 就加了一个non local block "
        },
        {
            "from": 1485.53,
            "to": 1486.6,
            "location": 2,
            "content": " 那这个non local block "
        },
        {
            "from": 1486.6,
            "to": 1488.2,
            "location": 2,
            "content": " 肯定是加的越多越好嘛 "
        },
        {
            "from": 1488.3,
            "to": 1489.9,
            "location": 2,
            "content": " 因为就相当于你在每一层 "
        },
        {
            "from": 1489.9,
            "to": 1491.73,
            "location": 2,
            "content": " 你都去做这种远距离的建模 "
        },
        {
            "from": 1492.07,
            "to": 1493.33,
            "location": 2,
            "content": " 所以作者这里的问题就说 "
        },
        {
            "from": 1493.33,
            "to": 1494.93,
            "location": 2,
            "content": " 我到底加多少好呢 "
        },
        {
            "from": 1495,
            "to": 1497.07,
            "location": 2,
            "content": " 所以他就试了一下啊加1个 block "
        },
        {
            "from": 1497.07,
            "to": 1498.93,
            "location": 2,
            "content": " 加5个 block 和加10个 block "
        },
        {
            "from": 1499.67,
            "to": 1501.2,
            "location": 2,
            "content": " 那这里10个 block 的意思呢 "
        },
        {
            "from": 1501.2,
            "to": 1502.93,
            "location": 2,
            "content": " 其实比如说在 res 3和 res 4 "
        },
        {
            "from": 1502.97,
            "to": 1504.57,
            "location": 2,
            "content": " 这两个阶段之中呢 "
        },
        {
            "from": 1504.57,
            "to": 1505.87,
            "location": 2,
            "content": " 所有的这个卷积后面呢 "
        },
        {
            "from": 1505.87,
            "to": 1507.53,
            "location": 2,
            "content": " 都加了一个 non local block "
        },
        {
            "from": 1507.93,
            "to": 1510.1,
            "location": 2,
            "content": " 因为我们也知道这个 res 50这个网络呢 "
        },
        {
            "from": 1510.1,
            "to": 1512.87,
            "location": 2,
            "content": " 他的这个层数分别是3463 "
        },
        {
            "from": 1512.93,
            "to": 1515.33,
            "location": 2,
            "content": " 所以中间这个 res 3和 res 4对应的呢 "
        },
        {
            "from": 1515.33,
            "to": 1518.1,
            "location": 2,
            "content": " 是4和6 所以他一共就有10个卷积层 "
        },
        {
            "from": 1518.3,
            "to": 1518.9,
            "location": 2,
            "content": " 所以就是说 "
        },
        {
            "from": 1518.9,
            "to": 1520.57,
            "location": 2,
            "content": " 对应的这10个卷积层后面呢 "
        },
        {
            "from": 1520.57,
            "to": 1521.7,
            "location": 2,
            "content": " 都有一个non local "
        },
        {
            "from": 1521.7,
            "to": 1523.6,
            "location": 2,
            "content": " 那最后就是有10个non local block "
        },
        {
            "from": 1523.73,
            "to": 1525.27,
            "location": 2,
            "content": " 那这个5个non local block "
        },
        {
            "from": 1525.33,
            "to": 1527.13,
            "location": 2,
            "content": " 那就是隔一个来一个隔一个来一个 "
        },
        {
            "from": 1527.13,
            "to": 1528.67,
            "location": 2,
            "content": " 所以说就刚好是5个 "
        },
        {
            "from": 1529.07,
            "to": 1530.5,
            "location": 2,
            "content": " 那对于 res 101来说呢 "
        },
        {
            "from": 1530.5,
            "to": 1532.9,
            "location": 2,
            "content": " 虽然他后面两层的这个层数更多啊 "
        },
        {
            "from": 1532.9,
            "to": 1534.37,
            "location": 2,
            "content": " 但他就是隔得多一点 "
        },
        {
            "from": 1534.37,
            "to": 1536.4,
            "location": 2,
            "content": " 那他还是5个 block 和10个 block "
        },
        {
            "from": 1536.8,
            "to": 1537.93,
            "location": 2,
            "content": " 那作者就发现呢 "
        },
        {
            "from": 1537.93,
            "to": 1539.9,
            "location": 2,
            "content": " 确实是更多的这个non local block "
        },
        {
            "from": 1539.9,
            "to": 1541.47,
            "location": 2,
            "content": " 带来的效果提升更多 "
        },
        {
            "from": 1541.57,
            "to": 1543.47,
            "location": 2,
            "content": " 也就意味着说自注意力这个操作呢 "
        },
        {
            "from": 1543.47,
            "to": 1544.4,
            "location": 2,
            "content": " 真的是有用 "
        },
        {
            "from": 1544.47,
            "to": 1545.9,
            "location": 2,
            "content": " 尤其是在这个视频里面 "
        },
        {
            "from": 1545.9,
            "to": 1548.3,
            "location": 2,
            "content": " 这个长距离的建模呢是更有帮助的 "
        },
        {
            "from": 1548.73,
            "to": 1550.07,
            "location": 2,
            "content": " 那接下来这个消融实验呢 "
        },
        {
            "from": 1550.07,
            "to": 1551.4,
            "location": 2,
            "content": " 主要是为了证明啊 "
        },
        {
            "from": 1551.4,
            "to": 1553.9,
            "location": 2,
            "content": " 作者新提出的这个 space time non local "
        },
        {
            "from": 1553.9,
            "to": 1554.87,
            "location": 2,
            "content": " 到底有没有用 "
        },
        {
            "from": 1554.93,
            "to": 1556.47,
            "location": 2,
            "content": " 因为有的人可能会质疑啊 "
        },
        {
            "from": 1556.47,
            "to": 1558.13,
            "location": 2,
            "content": " 这个self-attention 本来提出呢 "
        },
        {
            "from": 1558.13,
            "to": 1559.67,
            "location": 2,
            "content": " 就是在这个特征图上去做 "
        },
        {
            "from": 1559.67,
            "to": 1561.13,
            "location": 2,
            "content": " 的啊有可能只在 "
        },
        {
            "from": 1561.13,
            "to": 1563.27,
            "location": 2,
            "content": " spatial 上做这个 self attention 就可以了 "
        },
        {
            "from": 1563.27,
            "to": 1565.1,
            "location": 2,
            "content": " 啊你没有必要做这种 spacetime "
        },
        {
            "from": 1565.1,
            "to": 1566.3,
            "location": 2,
            "content": " 上的这个 self attention "
        },
        {
            "from": 1566.73,
            "to": 1569,
            "location": 2,
            "content": " 那所以作者这里呢就把它拆分开来了 "
        },
        {
            "from": 1569,
            "to": 1571.3,
            "location": 2,
            "content": " 就如果我在光在空间上去做 "
        },
        {
            "from": 1571.3,
            "to": 1572.37,
            "location": 2,
            "content": " 自注意力会怎么样 "
        },
        {
            "from": 1572.37,
            "to": 1574.8,
            "location": 2,
            "content": " 如果光在时间上去做自注意力怎么样 "
        },
        {
            "from": 1574.9,
            "to": 1576.73,
            "location": 2,
            "content": " 那或者我在这个时空上去做 "
        },
        {
            "from": 1576.73,
            "to": 1578.13,
            "location": 2,
            "content": " 自注意力又会怎么样 "
        },
        {
            "from": 1578.47,
            "to": 1579.57,
            "location": 2,
            "content": " 然后作者就会发现呢 "
        },
        {
            "from": 1579.57,
            "to": 1581.7,
            "location": 2,
            "content": " 时间和空间上做这个自注意力呢 "
        },
        {
            "from": 1581.7,
            "to": 1582.57,
            "location": 2,
            "content": " 一样重要 "
        },
        {
            "from": 1582.67,
            "to": 1583.33,
            "location": 2,
            "content": " 有的时候呢 "
        },
        {
            "from": 1583.33,
            "to": 1585.33,
            "location": 2,
            "content": " 甚至在时间上做这种自注意力呢 "
        },
        {
            "from": 1585.33,
            "to": 1587.27,
            "location": 2,
            "content": " 比在空间上做更有效 "
        },
        {
            "from": 1587.37,
            "to": 1588.87,
            "location": 2,
            "content": " 如果你在两个上面都做 "
        },
        {
            "from": 1588.87,
            "to": 1590.5,
            "location": 2,
            "content": " 就是这个 space time 都做呢 "
        },
        {
            "from": 1590.5,
            "to": 1591.8,
            "location": 2,
            "content": " 他的结果是最好的 "
        },
        {
            "from": 1591.8,
            "to": 1592.77,
            "location": 2,
            "content": " 所以就证明了 "
        },
        {
            "from": 1592.77,
            "to": 1595.1,
            "location": 2,
            "content": " 这篇论文提出的这个时空自注意力 "
        },
        {
            "from": 1595.1,
            "to": 1597.17,
            "location": 2,
            "content": " 才是对视频理解更有效的方法 "
        },
        {
            "from": 1597.47,
            "to": 1599.33,
            "location": 2,
            "content": " 那最后我想大概提一下的表格呢 "
        },
        {
            "from": 1599.33,
            "to": 1601,
            "location": 2,
            "content": " 其实也就是这里的表格 g 了 "
        },
        {
            "from": 1601,
            "to": 1601.97,
            "location": 2,
            "content": " 也就是利用更 "
        },
        {
            "from": 1601.97,
            "to": 1603.87,
            "location": 2,
            "content": " 长的这个视频输入会怎么样 "
        },
        {
            "from": 1603.93,
            "to": 1606.5,
            "location": 2,
            "content": " 因为他这篇论文从头到尾讲的就是说 "
        },
        {
            "from": 1606.6,
            "to": 1608.7,
            "location": 2,
            "content": " 如果我能有更长的上下文啊 "
        },
        {
            "from": 1608.7,
            "to": 1609.9,
            "location": 2,
            "content": " 效果会不会更好 "
        },
        {
            "from": 1609.97,
            "to": 1611.7,
            "location": 2,
            "content": " 那如果你这个non local 的目的 "
        },
        {
            "from": 1611.7,
            "to": 1612.33,
            "location": 2,
            "content": " 就是为了 "
        },
        {
            "from": 1612.33,
            "to": 1614.57,
            "location": 2,
            "content": " 抓住更长的上下文之间的信息 "
        },
        {
            "from": 1614.9,
            "to": 1617.37,
            "location": 2,
            "content": " 那如果你的输入只有16帧或者32帧 "
        },
        {
            "from": 1617.37,
            "to": 1619.3,
            "location": 2,
            "content": " 那也就是1秒的话其实也不长 "
        },
        {
            "from": 1619.3,
            "to": 1621.67,
            "location": 2,
            "content": " 你也没什么长距离的信息可以抓住的 "
        },
        {
            "from": 1621.87,
            "to": 1622.97,
            "location": 2,
            "content": " 所以作者这里就说 "
        },
        {
            "from": 1622.97,
            "to": 1624.87,
            "location": 2,
            "content": " 我一定得找一个更长的这个 "
        },
        {
            "from": 1624.87,
            "to": 1625.77,
            "location": 2,
            "content": " 时间序列输入 "
        },
        {
            "from": 1625.77,
            "to": 1628.07,
            "location": 2,
            "content": " 来证明一下non local 到底有没有用 "
        },
        {
            "from": 1628.33,
            "to": 1629.2,
            "location": 2,
            "content": " 而事实上呢 "
        },
        {
            "from": 1629.27,
            "to": 1631.17,
            "location": 2,
            "content": " 对于这个128帧的一个输入 "
        },
        {
            "from": 1631.17,
            "to": 1632.53,
            "location": 2,
            "content": " 也就大概4秒多 "
        },
        {
            "from": 1632.67,
            "to": 1633.93,
            "location": 2,
            "content": " 那non local这个方法呢 "
        },
        {
            "from": 1633.93,
            "to": 1636.8,
            "location": 2,
            "content": " 还是能够持续的提高这个波形的性能 "
        },
        {
            "from": 1637.17,
            "to": 1639.13,
            "location": 2,
            "content": " 而且提升呢还是非常显著的 "
        },
        {
            "from": 1639.2,
            "to": 1640.8,
            "location": 2,
            "content": " 也从侧面说明了啊non "
        },
        {
            "from": 1640.8,
            "to": 1641.4,
            "location": 2,
            "content": " local "
        },
        {
            "from": 1641.4,
            "to": 1643.67,
            "location": 2,
            "content": " 是对这种长距离的这种时序建模呢 "
        },
        {
            "from": 1643.67,
            "to": 1644.7,
            "location": 2,
            "content": " 更有好处的 "
        },
        {
            "from": 1645.2,
            "to": 1646.53,
            "location": 2,
            "content": " 那说完了消融实验啊 "
        },
        {
            "from": 1646.53,
            "to": 1648.13,
            "location": 2,
            "content": " 最后我们就来看一下结果 "
        },
        {
            "from": 1648.33,
            "to": 1650.7,
            "location": 2,
            "content": " 那因为这个时候呢已经是 i 3 d 之后了 "
        },
        {
            "from": 1650.7,
            "to": 1652.1,
            "location": 2,
            "content": " 所以说大家主要的结果呢 "
        },
        {
            "from": 1652.1,
            "to": 1654.47,
            "location": 2,
            "content": " 都是在 k 400这个数据集上去做比较 "
        },
        {
            "from": 1654.73,
            "to": 1656.57,
            "location": 2,
            "content": " 那我们可以看到这里这个表3啊 "
        },
        {
            "from": 1656.57,
            "to": 1657.67,
            "location": 2,
            "content": " 其实非常的小 "
        },
        {
            "from": 1657.8,
            "to": 1660,
            "location": 2,
            "content": " 总共对比的方法呢也就只有 i 3 d "
        },
        {
            "from": 1660,
            "to": 1662.9,
            "location": 2,
            "content": " 就是7还有之前的另外一篇论文啊3 "
        },
        {
            "from": 1663.27,
            "to": 1664,
            "location": 2,
            "content": " 为什么呢 "
        },
        {
            "from": 1664,
            "to": 1666.4,
            "location": 2,
            "content": " 因为之前讲过的那么多方法2 d 的啊 "
        },
        {
            "from": 1666.4,
            "to": 1667.9,
            "location": 2,
            "content": " 或者说双流网络的方法啊 "
        },
        {
            "from": 1667.9,
            "to": 1670.7,
            "location": 2,
            "content": " 他们的结果全都是在 ucf 101和 hmdb "
        },
        {
            "from": 1670.7,
            "to": 1671.73,
            "location": 2,
            "content": " 51上做的 "
        },
        {
            "from": 1671.73,
            "to": 1673.77,
            "location": 2,
            "content": " 他们都没有 k 400上的这个分 "
        },
        {
            "from": 1673.77,
            "to": 1675.3,
            "location": 2,
            "content": " 所以作者呢也没法比 "
        },
        {
            "from": 1675.5,
            "to": 1677.47,
            "location": 2,
            "content": " 总不能把之前所有的方法全都复现 "
        },
        {
            "from": 1677.47,
            "to": 1678,
            "location": 2,
            "content": " 一遍吧 "
        },
        {
            "from": 1678,
            "to": 1679.27,
            "location": 2,
            "content": " 所以说这里能比的呢 "
        },
        {
            "from": 1679.27,
            "to": 1680.9,
            "location": 2,
            "content": " 也就只有这两种方法了 "
        },
        {
            "from": 1681.17,
            "to": 1682.3,
            "location": 2,
            "content": " 那我们这里可以看到啊 "
        },
        {
            "from": 1682.3,
            "to": 1683.3,
            "location": 2,
            "content": " 如果拿这个 "
        },
        {
            "from": 1683.33,
            "to": 1684.5,
            "location": 2,
            "content": " non local 的 i 3 d "
        },
        {
            "from": 1684.5,
            "to": 1686.67,
            "location": 2,
            "content": " 去跟这个 i 3 d 去做对比的话呢 "
        },
        {
            "from": 1686.67,
            "to": 1687.8,
            "location": 2,
            "content": " 它有两个区别 "
        },
        {
            "from": 1688.1,
            "to": 1690.2,
            "location": 2,
            "content": " 一个呢就是他把这个 backbone 给换了 "
        },
        {
            "from": 1690.3,
            "to": 1692.77,
            "location": 2,
            "content": " 是把 inception net 呢换成了这个 resnet "
        },
        {
            "from": 1692.93,
            "to": 1695.37,
            "location": 2,
            "content": " 这个改变呢大概带来了一个点的提升 "
        },
        {
            "from": 1695.37,
            "to": 1696.9,
            "location": 2,
            "content": " 然后加上non local 之后呢 "
        },
        {
            "from": 1696.9,
            "to": 1698.73,
            "location": 2,
            "content": " 又带来了两三个点的提升 "
        },
        {
            "from": 1698.87,
            "to": 1699.57,
            "location": 2,
            "content": " 所以最后呢 "
        },
        {
            "from": 1699.57,
            "to": 1703,
            "location": 2,
            "content": " 从72.1到76.5大概就有4个多点的提升啊 "
        },
        {
            "from": 1703,
            "to": 1704.6,
            "location": 2,
            "content": " 提升也是非常显著的 "
        },
        {
            "from": 1704.8,
            "to": 1705.9,
            "location": 2,
            "content": " 而且我们可以看到呢 "
        },
        {
            "from": 1705.9,
            "to": 1707.53,
            "location": 2,
            "content": " 用上non local 之后啊 "
        },
        {
            "from": 1707.53,
            "to": 1708.5,
            "location": 2,
            "content": " 他的这个结果呢 "
        },
        {
            "from": 1708.5,
            "to": 1710.47,
            "location": 2,
            "content": " 甚至比之前这个双流 "
        },
        {
            "from": 1710.47,
            "to": 1712.27,
            "location": 2,
            "content": " i3d的结果还要好一点 "
        },
        {
            "from": 1712.57,
            "to": 1715.13,
            "location": 2,
            "content": " 这其实也就给做3 d 网络的人信心啊 "
        },
        {
            "from": 1715.13,
            "to": 1717.6,
            "location": 2,
            "content": " 就说我不用光流我照样效果能很好 "
        },
        {
            "from": 1717.8,
            "to": 1720.73,
            "location": 2,
            "content": " 然后呢non local network 如果换成了 res 101啊 "
        },
        {
            "from": 1720.73,
            "to": 1722.47,
            "location": 2,
            "content": " 当这个backbone它的最后结果呢 "
        },
        {
            "from": 1722.47,
            "to": 1724.07,
            "location": 2,
            "content": " 就有77.7这么高啊 "
        },
        {
            "from": 1724.07,
            "to": 1725.57,
            "location": 2,
            "content": " 已经是非常的高了 "
        },
        {
            "from": 1725.7,
            "to": 1726.4,
            "location": 2,
            "content": " 我们可以看到 "
        },
        {
            "from": 1726.4,
            "to": 1728.53,
            "location": 2,
            "content": " 比之前这个3里面的方法啊 "
        },
        {
            "from": 1728.53,
            "to": 1729.7,
            "location": 2,
            "content": " 它不仅用了 inception "
        },
        {
            "from": 1729.7,
            "to": 1732.5,
            "location": 2,
            "content": " resnet v 2就一个更好更强的结构 "
        },
        {
            "from": 1732.7,
            "to": 1734.33,
            "location": 2,
            "content": " 而且还用了三个模态啊 "
        },
        {
            "from": 1734.33,
            "to": 1735.5,
            "location": 2,
            "content": " 就是说 rgb 图像 "
        },
        {
            "from": 1735.5,
            "to": 1737.77,
            "location": 2,
            "content": " flow 图像和这个音频信息 "
        },
        {
            "from": 1737.93,
            "to": 1740.77,
            "location": 2,
            "content": " 那全都用了的情况下也就是77.7 "
        },
        {
            "from": 1740.93,
            "to": 1741.6,
            "location": 2,
            "content": " 所以说明啊 "
        },
        {
            "from": 1741.6,
            "to": 1743.77,
            "location": 2,
            "content": " non local 这个操作真的非常有效 "
        },
        {
            "from": 1744.67,
            "to": 1745.9,
            "location": 2,
            "content": " 那这篇论文的贡献呢 "
        },
        {
            "from": 1745.9,
            "to": 1747.3,
            "location": 2,
            "content": " 就是把这个自注意力操作 "
        },
        {
            "from": 1747.3,
            "to": 1748.73,
            "location": 2,
            "content": " 引入到了视觉领域 "
        },
        {
            "from": 1748.87,
            "to": 1750.93,
            "location": 2,
            "content": " 而且针对这个视频理解的任务呢 "
        },
        {
            "from": 1750.93,
            "to": 1752.13,
            "location": 2,
            "content": " 他还把这个 space "
        },
        {
            "from": 1752.13,
            "to": 1754,
            "location": 2,
            "content": " 自注意力操作变成了 space time "
        },
        {
            "from": 1754,
            "to": 1756.07,
            "location": 2,
            "content": " 就时空上的这个自注意力操作 "
        },
        {
            "from": 1756.17,
            "to": 1758.2,
            "location": 2,
            "content": " 而把这个视频理解上几个任务的分啊 "
        },
        {
            "from": 1758.2,
            "to": 1759.1,
            "location": 2,
            "content": " 都刷的很高 "
        },
        {
            "from": 1759.1,
            "to": 1760.87,
            "location": 2,
            "content": " 而也证明了他的有效性 "
        },
        {
            "from": 1761.27,
            "to": 1762.53,
            "location": 2,
            "content": " 那在这篇论文之后呢 "
        },
        {
            "from": 1762.53,
            "to": 1765.07,
            "location": 2,
            "content": " 就更少有人去使用 lstm 了 "
        },
        {
            "from": 1765.1,
            "to": 1766.33,
            "location": 2,
            "content": " 因为在 nlp 那边呢 "
        },
        {
            "from": 1766.33,
            "to": 1769.1,
            "location": 2,
            "content": " 大家也是使用transformer而不是使用 lstm "
        },
        {
            "from": 1769.3,
            "to": 1770.5,
            "location": 2,
            "content": " 那在 cv 这边呢 "
        },
        {
            "from": 1770.5,
            "to": 1772.07,
            "location": 2,
            "content": " 自从有了non local 算子 "
        },
        {
            "from": 1772.07,
            "to": 1773.7,
            "location": 2,
            "content": " 大家也不用 lstm 了 "
        },
        {
            "from": 1773.9,
            "to": 1775.7,
            "location": 2,
            "content": " 那作者的愿望呢其实也实现了 "
        },
        {
            "from": 1775.73,
            "to": 1776.53,
            "location": 2,
            "content": " 作者最后说啊 "
        },
        {
            "from": 1776.53,
            "to": 1778.6,
            "location": 2,
            "content": " 他们希望这个non local 这个层啊 "
        },
        {
            "from": 1778.7,
            "to": 1779.97,
            "location": 2,
            "content": " 能够成为一个重要的 "
        },
        {
            "from": 1779.97,
            "to": 1781.87,
            "location": 2,
            "content": " 这个神经网络的组成部分啊 "
        },
        {
            "from": 1781.87,
            "to": 1784.37,
            "location": 2,
            "content": " 之后的这个网络结构呢都能用到他 "
        },
        {
            "from": 1784.67,
            "to": 1785.17,
            "location": 2,
            "content": " 那确实 "
        },
        {
            "from": 1785.17,
            "to": 1787,
            "location": 2,
            "content": " 不管是在之后的这个网络设计上 "
        },
        {
            "from": 1787,
            "to": 1788.37,
            "location": 2,
            "content": " 还是在这个下游任务上 "
        },
        {
            "from": 1788.37,
            "to": 1789.67,
            "location": 2,
            "content": " 那non local 这个算子呢 "
        },
        {
            "from": 1789.67,
            "to": 1791.07,
            "location": 2,
            "content": " 是有巨大的影响力的 "
        },
        {
            "from": 1791.77,
            "to": 1793.6,
            "location": 2,
            "content": " 那说完了non local 这篇论文 "
        },
        {
            "from": 1793.8,
            "to": 1795.87,
            "location": 2,
            "content": " 那接下来我们讲一篇同期的啊 "
        },
        {
            "from": 1795.87,
            "to": 1798,
            "location": 2,
            "content": " 也是 cvpr 18的另外一篇论文啊 "
        },
        {
            "from": 1798,
            "to": 1799.17,
            "location": 2,
            "content": " 就是 r （2+1） d "
        },
        {
            "from": 1799.7,
            "to": 1800.53,
            "location": 2,
            "content": " 论文的题目呢 "
        },
        {
            "from": 1800.53,
            "to": 1802.73,
            "location": 2,
            "content": " 就是说对于这个动作识别来说 "
        },
        {
            "from": 1802.8,
            "to": 1804.4,
            "location": 2,
            "content": " 他们做了一个详尽的调查 "
        },
        {
            "from": 1804.4,
            "to": 1805.6,
            "location": 2,
            "content": " 那调查的是什么呢 "
        },
        {
            "from": 1805.6,
            "to": 1808.53,
            "location": 2,
            "content": " 就是这种时空的卷积到底该怎么做好 "
        },
        {
            "from": 1808.67,
            "to": 1810.6,
            "location": 2,
            "content": " 啊到底用2 d 还是用3 d "
        },
        {
            "from": 1810.67,
            "to": 1812.07,
            "location": 2,
            "content": " 还是2 d 加3 d 啊 "
        },
        {
            "from": 1812.07,
            "to": 1814.2,
            "location": 2,
            "content": " 还是怎么串联一下或者并联一下 "
        },
        {
            "from": 1814.53,
            "to": 1816.8,
            "location": 2,
            "content": " 总之呢是一篇非常实验性的论文 "
        },
        {
            "from": 1817.1,
            "to": 1818.3,
            "location": 2,
            "content": " 那作者在摘要里呢 "
        },
        {
            "from": 1818.3,
            "to": 1818.97,
            "location": 2,
            "content": " 其实也说了 "
        },
        {
            "from": 1818.97,
            "to": 1821.1,
            "location": 2,
            "content": " 他们这篇论文的研究动机是什么 "
        },
        {
            "from": 1821.53,
            "to": 1822.8,
            "location": 2,
            "content": " 就说啊他们发现啊 "
        },
        {
            "from": 1822.8,
            "to": 1824.9,
            "location": 2,
            "content": " 如果就用这种2 d 的这个网络 "
        },
        {
            "from": 1825.07,
            "to": 1827.5,
            "location": 2,
            "content": " 然后在视频上这个一帧一帧去出特征 "
        },
        {
            "from": 1827.5,
            "to": 1829.1,
            "location": 2,
            "content": " 或者说一帧一帧这么做 "
        },
        {
            "from": 1829.2,
            "to": 1830.6,
            "location": 2,
            "content": " 结果呢也很好啊 "
        },
        {
            "from": 1830.6,
            "to": 1830.93,
            "location": 2,
            "content": " 至少 "
        },
        {
            "from": 1830.93,
            "to": 1833.1,
            "location": 2,
            "content": " 是在这个视频动作识别领域里来说啊 "
        },
        {
            "from": 1833.1,
            "to": 1834.13,
            "location": 2,
            "content": " 他们的这个结果呢 "
        },
        {
            "from": 1834.13,
            "to": 1835.93,
            "location": 2,
            "content": " 还是表现的相当不错的啊 "
        },
        {
            "from": 1835.93,
            "to": 1837.93,
            "location": 2,
            "content": " 并没有比3 d 网络低多少 "
        },
        {
            "from": 1838.2,
            "to": 1839.73,
            "location": 2,
            "content": " 那这篇论文的作者就想 "
        },
        {
            "from": 1839.73,
            "to": 1841.77,
            "location": 2,
            "content": " 那既然2 d 网络表现也这么好 "
        },
        {
            "from": 1841.93,
            "to": 1843.3,
            "location": 2,
            "content": " 那如果能用一下2 d "
        },
        {
            "from": 1843.3,
            "to": 1845.4,
            "location": 2,
            "content": " 或者部分用一下这个2 d 卷积呢 "
        },
        {
            "from": 1845.4,
            "to": 1846.53,
            "location": 2,
            "content": " 其实也是不错的啊 "
        },
        {
            "from": 1846.53,
            "to": 1849.57,
            "location": 2,
            "content": " 毕竟2 d 卷积比3 d 卷积呢便宜太多了 "
        },
        {
            "from": 1849.8,
            "to": 1850.67,
            "location": 2,
            "content": " 在这篇文章呢 "
        },
        {
            "from": 1850.67,
            "to": 1853.17,
            "location": 2,
            "content": " 整个就是在测试各种各样的结构啊 "
        },
        {
            "from": 1853.17,
            "to": 1855.07,
            "location": 2,
            "content": " 一会我们在这个图里也可以看到 "
        },
        {
            "from": 1855.07,
            "to": 1857.9,
            "location": 2,
            "content": " 到底是先2 d 再3 d 还是先3 d 再2 d "
        },
        {
            "from": 1857.9,
            "to": 1859.2,
            "location": 2,
            "content": " 还是说把这个3 d 呢 "
        },
        {
            "from": 1859.2,
            "to": 1861.2,
            "location": 2,
            "content": " 拆分成1 d 加2 d 的结构 "
        },
        {
            "from": 1861.6,
            "to": 1862.77,
            "location": 2,
            "content": " 那最后作者发现呢 "
        },
        {
            "from": 1862.77,
            "to": 1866.13,
            "location": 2,
            "content": " 把这个3 d 卷积拆分成这个空间上的2 d "
        },
        {
            "from": 1866.2,
            "to": 1867.9,
            "location": 2,
            "content": " 和这个时间上的1 d 呢 "
        },
        {
            "from": 1867.97,
            "to": 1869.67,
            "location": 2,
            "content": " 最后能得到更好的效果 "
        },
        {
            "from": 1869.67,
            "to": 1871.87,
            "location": 2,
            "content": " 而且这个训练呢也简单了很多 "
        },
        {
            "from": 1872.27,
            "to": 1874.47,
            "location": 2,
            "content": " 然后在得到了一个更优的结构之后呢 "
        },
        {
            "from": 1874.47,
            "to": 1874.8,
            "location": 2,
            "content": " 他们在 "
        },
        {
            "from": 1874.8,
            "to": 1877.2,
            "location": 2,
            "content": " 很多数据集上都取得了很好的结果啊 "
        },
        {
            "from": 1877.2,
            "to": 1877.93,
            "location": 2,
            "content": " 那包括 "
        },
        {
            "from": 1877.93,
            "to": 1880.27,
            "location": 2,
            "content": " 比较大的这个 sports-1M 和 k 400 "
        },
        {
            "from": 1880.37,
            "to": 1883.73,
            "location": 2,
            "content": " 以及之前的小一些的这个 ucf 101和 hmdb 51 "
        },
        {
            "from": 1884.47,
            "to": 1885.37,
            "location": 2,
            "content": " 那具体来说呢 "
        },
        {
            "from": 1885.37,
            "to": 1887.4,
            "location": 2,
            "content": " 作者就是在这几个方式上啊 "
        },
        {
            "from": 1887.4,
            "to": 1888.87,
            "location": 2,
            "content": " 去做了这个消融实验啊 "
        },
        {
            "from": 1888.87,
            "to": 1890.8,
            "location": 2,
            "content": " 看看到底哪种组合最好 "
        },
        {
            "from": 1890.8,
            "to": 1893.97,
            "location": 2,
            "content": " 那首先第一种呢就是纯2 d 的网络啊 r2d "
        },
        {
            "from": 1894.4,
            "to": 1896.5,
            "location": 2,
            "content": " 那他的意思呢就是视频中的每一帧啊 "
        },
        {
            "from": 1896.5,
            "to": 1898.8,
            "location": 2,
            "content": " 一帧一帧这么过去抽特征或者做训练 "
        },
        {
            "from": 1898.8,
            "to": 1900.47,
            "location": 2,
            "content": " 那完全是一个2 d 网络 "
        },
        {
            "from": 1900.9,
            "to": 1903.57,
            "location": 2,
            "content": " 那对于第二种这个 mcx 方法来说呢 "
        },
        {
            "from": 1903.73,
            "to": 1905.53,
            "location": 2,
            "content": " 这个头重脚轻的方法 "
        },
        {
            "from": 1905.53,
            "to": 1907.73,
            "location": 2,
            "content": " 就是说我先有一个视频clip进来 "
        },
        {
            "from": 1907.73,
            "to": 1910.47,
            "location": 2,
            "content": " 然后我通过这个3 d 卷机去做啊 "
        },
        {
            "from": 1910.47,
            "to": 1913.2,
            "location": 2,
            "content": " 先在这个底层上学一学这个时空特征 "
        },
        {
            "from": 1913.33,
            "to": 1915.67,
            "location": 2,
            "content": " 然后到上层呢我换成这个2 d 的 "
        },
        {
            "from": 1915.67,
            "to": 1917.53,
            "location": 2,
            "content": " 然后把这个计算复杂度降一下 "
        },
        {
            "from": 1917.53,
            "to": 1919,
            "location": 2,
            "content": " 但因为2 d 比较便宜吗 "
        },
        {
            "from": 1919,
            "to": 1920.73,
            "location": 2,
            "content": " 所以我说他是头重脚轻 "
        },
        {
            "from": 1921.17,
            "to": 1921.87,
            "location": 2,
            "content": " 那很显然 "
        },
        {
            "from": 1921.87,
            "to": 1924.27,
            "location": 2,
            "content": " 那第三种结构这个 rmcx 来说呢 "
        },
        {
            "from": 1924.27,
            "to": 1926.1,
            "location": 2,
            "content": " 那就肯定就是说头轻脚重了 "
        },
        {
            "from": 1926.1,
            "to": 1927.9,
            "location": 2,
            "content": " 那就是说我先刚开始的时候呢 "
        },
        {
            "from": 1927.9,
            "to": 1930.07,
            "location": 2,
            "content": " 把一个视频 clip 拆分成每一帧 "
        },
        {
            "from": 1930.17,
            "to": 1932.4,
            "location": 2,
            "content": " 然后我一帧一帧输入这个2 d conv "
        },
        {
            "from": 1932.6,
            "to": 1933.77,
            "location": 2,
            "content": " 然后在得到这些2 d "
        },
        {
            "from": 1933.77,
            "to": 1935.17,
            "location": 2,
            "content": " conv出来的特征之后呢 "
        },
        {
            "from": 1935.17,
            "to": 1937.73,
            "location": 2,
            "content": " 我再用这个3 d conv去做一些这个融合 "
        },
        {
            "from": 1937.8,
            "to": 1939.07,
            "location": 2,
            "content": " 最后出这个结果 "
        },
        {
            "from": 1939.3,
            "to": 1940.07,
            "location": 2,
            "content": " 那第四种呢 "
        },
        {
            "from": 1940.07,
            "to": 1942.7,
            "location": 2,
            "content": " 当然就是说全部都是都使用3 d 网络了 "
        },
        {
            "from": 1942.73,
            "to": 1944,
            "location": 2,
            "content": " 那这也就是 c 3 d 啊 "
        },
        {
            "from": 1944,
            "to": 1946.17,
            "location": 2,
            "content": " i 3 d 啊这一系列的网络做法啊 "
        },
        {
            "from": 1946.17,
            "to": 1947.4,
            "location": 2,
            "content": " 包括 cvpr18的时候 "
        },
        {
            "from": 1947.4,
            "to": 1949.17,
            "location": 2,
            "content": " 还有一篇叫 r 3 d 的网络 "
        },
        {
            "from": 1949.17,
            "to": 1950.13,
            "location": 2,
            "content": " 就是纯粹使用 "
        },
        {
            "from": 1950.13,
            "to": 1951.93,
            "location": 2,
            "content": " resnet 的一个3 d 版本 "
        },
        {
            "from": 1952.4,
            "to": 1953.5,
            "location": 2,
            "content": " 那最后这个 e 啊 "
        },
        {
            "from": 1953.5,
            "to": 1954.8,
            "location": 2,
            "content": " 这个 r （2+1） d 结构呢 "
        },
        {
            "from": 1954.8,
            "to": 1956.53,
            "location": 2,
            "content": " 就是这篇论文提出的结构 "
        },
        {
            "from": 1956.73,
            "to": 1957.33,
            "location": 2,
            "content": " 也就说啊 "
        },
        {
            "from": 1957.33,
            "to": 1960.67,
            "location": 2,
            "content": " 他把这个3 d 卷积拆分成了两个卷积啊 "
        },
        {
            "from": 1960.67,
            "to": 1963.37,
            "location": 2,
            "content": " 就是先做一个2 d 上的 spatial 上的卷积 "
        },
        {
            "from": 1963.37,
            "to": 1964.53,
            "location": 2,
            "content": " 然后再做一个 1 d "
        },
        {
            "from": 1964.53,
            "to": 1966.37,
            "location": 2,
            "content": " 的这个时间上的这个卷积 "
        },
        {
            "from": 1966.73,
            "to": 1967.57,
            "location": 2,
            "content": " 那作者发现啊 "
        },
        {
            "from": 1967.57,
            "to": 1969.73,
            "location": 2,
            "content": " 其实他们的这种效果呢是最好的 "
        },
        {
            "from": 1970.1,
            "to": 1970.67,
            "location": 2,
            "content": " 那接下来呢 "
        },
        {
            "from": 1970.67,
            "to": 1972.47,
            "location": 2,
            "content": " 我们就具体来看一下这个结果 "
        },
        {
            "from": 1972.47,
            "to": 1974.7,
            "location": 2,
            "content": " 看看到底哪一个设置会更好 "
        },
        {
            "from": 1974.93,
            "to": 1977.07,
            "location": 2,
            "content": " 那首先我们看一下这个参数量啊 "
        },
        {
            "from": 1977.1,
            "to": 1978.47,
            "location": 2,
            "content": " 从参数量上来看呢 "
        },
        {
            "from": 1978.47,
            "to": 1980.27,
            "location": 2,
            "content": " 那如果纯用2 d 的这个网络呢 "
        },
        {
            "from": 1980.27,
            "to": 1981.6,
            "location": 2,
            "content": " 肯定是更便宜的啊 "
        },
        {
            "from": 1981.6,
            "to": 1983.33,
            "location": 2,
            "content": " 所以我们可以看到他的这个参数量呢 "
        },
        {
            "from": 1983.33,
            "to": 1984.6,
            "location": 2,
            "content": " 都明显小很多 "
        },
        {
            "from": 1985.07,
            "to": 1986.7,
            "location": 2,
            "content": " 但是其他用了3 d 网络的呢 "
        },
        {
            "from": 1986.7,
            "to": 1988.6,
            "location": 2,
            "content": " 明显这个参数量呢就上去了 "
        },
        {
            "from": 1988.77,
            "to": 1989.3,
            "location": 2,
            "content": " 第二个呢 "
        },
        {
            "from": 1989.3,
            "to": 1991.27,
            "location": 2,
            "content": " 就是我们从这个实验结果上来看 "
        },
        {
            "from": 1991.33,
            "to": 1992.27,
            "location": 2,
            "content": " 那实验结果上呢 "
        },
        {
            "from": 1992.27,
            "to": 1994.5,
            "location": 2,
            "content": " 明显如果只用2 d 网络的这个结果呢 "
        },
        {
            "from": 1994.5,
            "to": 1995.37,
            "location": 2,
            "content": " 是最差的 "
        },
        {
            "from": 1995.93,
            "to": 1998.2,
            "location": 2,
            "content": " 纯用3 d 网络的结果呢也不咋样 "
        },
        {
            "from": 1998.5,
            "to": 2001.4,
            "location": 2,
            "content": " 反而是这种2 d 3 d 混合用的结果还不错 "
        },
        {
            "from": 2001.57,
            "to": 2003.8,
            "location": 2,
            "content": " 啊如果是头重脚轻呢就50多 "
        },
        {
            "from": 2003.8,
            "to": 2006.5,
            "location": 2,
            "content": " 那头轻脚重呢也有将近50的效果 "
        },
        {
            "from": 2006.73,
            "to": 2009.3,
            "location": 2,
            "content": " 都比前面单纯使用2 d 或者3 d 的效果呢 "
        },
        {
            "from": 2009.3,
            "to": 2010.13,
            "location": 2,
            "content": " 要好一些 "
        },
        {
            "from": 2010.2,
            "to": 2010.87,
            "location": 2,
            "content": " 那最后呢 "
        },
        {
            "from": 2010.87,
            "to": 2012.93,
            "location": 2,
            "content": " 就是这篇论文提出的 r （2+1） d 啊 "
        },
        {
            "from": 2012.93,
            "to": 2014.7,
            "location": 2,
            "content": " 就是这种拆分结构的形式 "
        },
        {
            "from": 2014.9,
            "to": 2015.77,
            "location": 2,
            "content": " 它的参数量呢 "
        },
        {
            "from": 2015.77,
            "to": 2017.97,
            "location": 2,
            "content": " 是目的是为了和之前的这个3 d 网络呢 "
        },
        {
            "from": 2017.97,
            "to": 2018.8,
            "location": 2,
            "content": " 保持一致 "
        },
        {
            "from": 2018.97,
            "to": 2020.8,
            "location": 2,
            "content": " 但是效果呢好了非常多 "
        },
        {
            "from": 2021.07,
            "to": 2022.53,
            "location": 2,
            "content": " 无论是在短一点的视频上 "
        },
        {
            "from": 2022.53,
            "to": 2023.97,
            "location": 2,
            "content": " 还是长一点的视频上 "
        },
        {
            "from": 2024,
            "to": 2025.27,
            "location": 2,
            "content": " 它的效果呢都比所有的 "
        },
        {
            "from": 2025.27,
            "to": 2026.87,
            "location": 2,
            "content": " 之前这些设计呢都要好 "
        },
        {
            "from": 2027.07,
            "to": 2029.17,
            "location": 2,
            "content": " 那其实对于网络结构的这种设计的探 "
        },
        {
            "from": 2029.17,
            "to": 2029.47,
            "location": 2,
            "content": " 索呢 "
        },
        {
            "from": 2029.47,
            "to": 2032.37,
            "location": 2,
            "content": " 其实也不光是 r （2+1） d 这一篇论文在做 "
        },
        {
            "from": 2032.47,
            "to": 2034.9,
            "location": 2,
            "content": " 那之前呢也有 p 3 d 这篇论文在做 "
        },
        {
            "from": 2034.93,
            "to": 2035.73,
            "location": 2,
            "content": " 然后他之后呢 "
        },
        {
            "from": 2035.73,
            "to": 2037.9,
            "location": 2,
            "content": " 也有 s 3 d 和 eco 这两篇论文 "
        },
        {
            "from": 2037.9,
            "to": 2039.77,
            "location": 2,
            "content": " 也都是用类似的方法在做的 "
        },
        {
            "from": 2039.93,
            "to": 2041.73,
            "location": 2,
            "content": " 尤其是 s 3 d 和 eco啊 "
        },
        {
            "from": 2041.73,
            "to": 2043.17,
            "location": 2,
            "content": " 他们都提出了这种啊 "
        },
        {
            "from": 2043.17,
            "to": 2043.9,
            "location": 2,
            "content": " 头重脚轻 "
        },
        {
            "from": 2043.9,
            "to": 2046.13,
            "location": 2,
            "content": " 或者头轻脚重的这种设计方式 "
        },
        {
            "from": 2046.17,
            "to": 2047.7,
            "location": 2,
            "content": " 然后去做这种相融实验 "
        },
        {
            "from": 2047.87,
            "to": 2048.37,
            "location": 2,
            "content": " 所以说啊 "
        },
        {
            "from": 2048.37,
            "to": 2050.5,
            "location": 2,
            "content": " 大家的想法其实也都是差不多的 "
        },
        {
            "from": 2051.07,
            "to": 2052,
            "location": 2,
            "content": " 那可能读到这呢 "
        },
        {
            "from": 2052,
            "to": 2054.53,
            "location": 2,
            "content": " 很多同学还是不知道什么是 r （2+1） d 啊 "
        },
        {
            "from": 2054.53,
            "to": 2056.53,
            "location": 2,
            "content": " 到底什么叫拆分啊 "
        },
        {
            "from": 2056.53,
            "to": 2058.17,
            "location": 2,
            "content": " 那作者这里其实在图二里呢 "
        },
        {
            "from": 2058.17,
            "to": 2060.07,
            "location": 2,
            "content": " 就大概画了一个简单的示意图 "
        },
        {
            "from": 2060.37,
            "to": 2061.27,
            "location": 2,
            "content": " 那意思就说呢 "
        },
        {
            "from": 2061.27,
            "to": 2064.17,
            "location": 2,
            "content": " 你用了一个 t * d * d 的一个卷积核啊 "
        },
        {
            "from": 2064.17,
            "to": 2066,
            "location": 2,
            "content": " 当然你可以是3*3*3了 "
        },
        {
            "from": 2066.13,
            "to": 2068.1,
            "location": 2,
            "content": " 但是呢你这个时间长和空间上呢 "
        },
        {
            "from": 2068.1,
            "to": 2069.17,
            "location": 2,
            "content": " 可以是不一样的 "
        },
        {
            "from": 2069.57,
            "to": 2071.2,
            "location": 2,
            "content": " 然后 r （2+1） d 的方式呢 "
        },
        {
            "from": 2071.2,
            "to": 2073.17,
            "location": 2,
            "content": " 就是说把这个3 d 呢给拆分了 "
        },
        {
            "from": 2073.2,
            "to": 2075.7,
            "location": 2,
            "content": " 我先在空间上呢做这种2 d 卷积 "
        },
        {
            "from": 2075.7,
            "to": 2077.73,
            "location": 2,
            "content": " 就是在时间这个维度上呢是1啊 "
        },
        {
            "from": 2077.73,
            "to": 2078.97,
            "location": 2,
            "content": " 就什么操作都不做 "
        },
        {
            "from": 2079.13,
            "to": 2080.2,
            "location": 2,
            "content": " 然后在空间上呢 "
        },
        {
            "from": 2080.2,
            "to": 2082.13,
            "location": 2,
            "content": " 去做这个 d * d 的这个卷积 "
        },
        {
            "from": 2082.53,
            "to": 2085.07,
            "location": 2,
            "content": " 然后中间呢做一层这个特征投射啊 "
        },
        {
            "from": 2085.07,
            "to": 2086.93,
            "location": 2,
            "content": " 就是把这个维度呢变化一下 "
        },
        {
            "from": 2087.13,
            "to": 2088.9,
            "location": 2,
            "content": " 那这里之所以变化这个维度呢 "
        },
        {
            "from": 2088.9,
            "to": 2090.27,
            "location": 2,
            "content": " 是想让这个 r （2+1）d "
        },
        {
            "from": 2090.27,
            "to": 2091.77,
            "location": 2,
            "content": " 最后的一个网络参数呢 "
        },
        {
            "from": 2091.87,
            "to": 2093,
            "location": 2,
            "content": " 和这个 r 3 d "
        },
        {
            "from": 2093,
            "to": 2095.57,
            "location": 2,
            "content": " 这个纯3 d 网络的网络参数保持一致 "
        },
        {
            "from": 2095.7,
            "to": 2096.3,
            "location": 2,
            "content": " 这样子呢 "
        },
        {
            "from": 2096.3,
            "to": 2098.37,
            "location": 2,
            "content": " 更能够做这种公平的对比啊来 "
        },
        {
            "from": 2098.37,
            "to": 2100.73,
            "location": 2,
            "content": " 显示这个 r （2+1） d 网络这个优越性 "
        },
        {
            "from": 2101.13,
            "to": 2103.4,
            "location": 2,
            "content": " 那至于这里这个维度 mi 怎么算的呢 "
        },
        {
            "from": 2103.4,
            "to": 2104.87,
            "location": 2,
            "content": " 其实他在论文里呢 "
        },
        {
            "from": 2104.87,
            "to": 2106.4,
            "location": 2,
            "content": " 也在这里展现出来了啊 "
        },
        {
            "from": 2106.4,
            "to": 2107.87,
            "location": 2,
            "content": " 用这个公式去算的啊 "
        },
        {
            "from": 2107.87,
            "to": 2109.2,
            "location": 2,
            "content": " 能够尽可能的逼近 "
        },
        {
            "from": 2109.2,
            "to": 2111.17,
            "location": 2,
            "content": " 那这个 r 3 d 的这个网络参数 "
        },
        {
            "from": 2111.5,
            "to": 2113.57,
            "location": 2,
            "content": " 那一旦做完这个特征投射之后呢 "
        },
        {
            "from": 2113.57,
            "to": 2114.9,
            "location": 2,
            "content": " 他接下就做了一个  "
        },
        {
            "from": 2114.9,
            "to": 2117.5,
            "location": 2,
            "content": " t*1*1的一个时序上的一个卷积 "
        },
        {
            "from": 2117.97,
            "to": 2120.47,
            "location": 2,
            "content": " 那这里呢只在时间上做了一次卷积 "
        },
        {
            "from": 2120.5,
            "to": 2121.67,
            "location": 2,
            "content": " 那后面是空间上啊 "
        },
        {
            "from": 2121.67,
            "to": 2123.73,
            "location": 2,
            "content": " 就是1*1还没有做什么操作的 "
        },
        {
            "from": 2123.8,
            "to": 2125.5,
            "location": 2,
            "content": " 这就是通过这种方式啊 "
        },
        {
            "from": 2125.5,
            "to": 2126.8,
            "location": 2,
            "content": " 把一个3 d 的卷积呢 "
        },
        {
            "from": 2126.8,
            "to": 2128.47,
            "location": 2,
            "content": " 拆分成了一个顺序的啊 "
        },
        {
            "from": 2128.47,
            "to": 2130.77,
            "location": 2,
            "content": " 先做空间再做时间的卷积形式 "
        },
        {
            "from": 2130.8,
            "to": 2132.87,
            "location": 2,
            "content": " 那作者这里呢也说了两点啊 "
        },
        {
            "from": 2132.87,
            "to": 2134.4,
            "location": 2,
            "content": " 就说这种拆分的形式 "
        },
        {
            "from": 2134.4,
            "to": 2137.3,
            "location": 2,
            "content": " 为什么比原来这个纯使用3 d 网络好的 "
        },
        {
            "from": 2137.3,
            "to": 2138.1,
            "location": 2,
            "content": " 原因 "
        },
        {
            "from": 2138.47,
            "to": 2140.93,
            "location": 2,
            "content": " 一个呢就是增强了网络这个非线性 "
        },
        {
            "from": 2141.07,
            "to": 2142.8,
            "location": 2,
            "content": " 因为你原来如果只有一个3 d "
        },
        {
            "from": 2142.8,
            "to": 2143.5,
            "location": 2,
            "content": " conv的话呢 "
        },
        {
            "from": 2143.5,
            "to": 2145.57,
            "location": 2,
            "content": " 你后面就只接了一个 relu激活层 "
        },
        {
            "from": 2145.57,
            "to": 2147.73,
            "location": 2,
            "content": " 所以你只做了一次飞线性操作 "
        },
        {
            "from": 2148.1,
            "to": 2150.1,
            "location": 2,
            "content": " 但是你现在呢做了两次卷积 "
        },
        {
            "from": 2150.1,
            "to": 2152.27,
            "location": 2,
            "content": " 那你每个卷积后面呢都有一个relu "
        },
        {
            "from": 2152.27,
            "to": 2155.37,
            "location": 2,
            "content": " 激活层那你就有两次非线性的变换 "
        },
        {
            "from": 2155.47,
            "to": 2158.1,
            "location": 2,
            "content": " 你这个模型的非线性能力呢就加强了 "
        },
        {
            "from": 2158.17,
            "to": 2160.57,
            "location": 2,
            "content": " 那他的学习能力呢也就增加了 "
        },
        {
            "from": 2160.8,
            "to": 2161.97,
            "location": 2,
            "content": " 那第二个好处呢 "
        },
        {
            "from": 2161.97,
            "to": 2163.87,
            "location": 2,
            "content": " 也就是从优化的角度来看啊 "
        },
        {
            "from": 2163.87,
            "to": 2166.13,
            "location": 2,
            "content": " 如果你直接去学一个3 d 卷积的话 "
        },
        {
            "from": 2166.13,
            "to": 2167.27,
            "location": 2,
            "content": " 那是不好学的 "
        },
        {
            "from": 2167.5,
            "to": 2169.27,
            "location": 2,
            "content": " 那如果你把它拆分成一个2 d "
        },
        {
            "from": 2169.27,
            "to": 2170.1,
            "location": 2,
            "content": " 和1 d 来说呢 "
        },
        {
            "from": 2170.1,
            "to": 2171.87,
            "location": 2,
            "content": " 他就相对容易优化一些 "
        },
        {
            "from": 2172.3,
            "to": 2174.13,
            "location": 2,
            "content": " 那作者在右边的这个图三里呢 "
        },
        {
            "from": 2174.13,
            "to": 2176.87,
            "location": 2,
            "content": " 也展示一下训练和测试的这个错误呢 "
        },
        {
            "from": 2177.2,
            "to": 2177.9,
            "location": 2,
            "content": " 就是拿（2+1）d "
        },
        {
            "from": 2177.9,
            "to": 2180.5,
            "location": 2,
            "content": " 和这个r3d 呢做了一个对比 "
        },
        {
            "from": 2180.73,
            "to": 2181.6,
            "location": 2,
            "content": " 我们可以看到啊 "
        },
        {
            "from": 2181.6,
            "to": 2183.13,
            "location": 2,
            "content": " 不论是对浅一点的网络 "
        },
        {
            "from": 2183.13,
            "to": 2186.67,
            "location": 2,
            "content": " 就是 r 3 d 18或者 r （2+1）d 18就是只有18层 "
        },
        {
            "from": 2186.87,
            "to": 2188.7,
            "location": 2,
            "content": " 而是说对于一个深一些的网络啊 "
        },
        {
            "from": 2188.7,
            "to": 2191.9,
            "location": 2,
            "content": " 就 r 3 d 34和 r （2+1）d 34来说啊 "
        },
        {
            "from": 2191.9,
            "to": 2193.73,
            "location": 2,
            "content": " 他的这个结论呢都是统一的 "
        },
        {
            "from": 2193.93,
            "to": 2194.9,
            "location": 2,
            "content": " 就是你用上  "
        },
        {
            "from": 2194.9,
            "to": 2197.3,
            "location": 2,
            "content": " r（2+1） d 这种拆分式的结构之后呢 "
        },
        {
            "from": 2197.47,
            "to": 2199,
            "location": 2,
            "content": " 你不论是训练的这个误差 "
        },
        {
            "from": 2199,
            "to": 2200.6,
            "location": 2,
            "content": " 还是测试的这个误差啊 "
        },
        {
            "from": 2200.6,
            "to": 2203.13,
            "location": 2,
            "content": " 都比原来这个 r 3 d 呢是要低一些的 "
        },
        {
            "from": 2203.13,
            "to": 2205.13,
            "location": 2,
            "content": " 这也就证明了这既不是过你和 "
        },
        {
            "from": 2205.13,
            "to": 2206.2,
            "location": 2,
            "content": " 也不是欠拟合 "
        },
        {
            "from": 2206.3,
            "to": 2207.5,
            "location": 2,
            "content": " 这就简单的证明了 "
        },
        {
            "from": 2207.5,
            "to": 2208.93,
            "location": 2,
            "content": " 模型呢是更容易训练 "
        },
        {
            "from": 2209.8,
            "to": 2211.07,
            "location": 2,
            "content": " 那说完了 r （2+1）d "
        },
        {
            "from": 2211.07,
            "to": 2212.57,
            "location": 2,
            "content": " 到底是怎么做拆分的啊 "
        },
        {
            "from": 2212.57,
            "to": 2214.1,
            "location": 2,
            "content": " 也做完了这个消融实验 "
        },
        {
            "from": 2214.33,
            "to": 2216.07,
            "location": 2,
            "content": " 那最后呢就是看一下结果 "
        },
        {
            "from": 2216.1,
            "to": 2217.6,
            "location": 2,
            "content": " 我们首先来看一下这个  "
        },
        {
            "from": 2217.6,
            "to": 2219.07,
            "location": 2,
            "content": " k400上的这个结果对比 "
        },
        {
            "from": 2219.37,
            "to": 2219.97,
            "location": 2,
            "content": " 那同样的 "
        },
        {
            "from": 2219.97,
            "to": 2222.8,
            "location": 2,
            "content": " 因为 r （2+1）d 篇论文呢也是 cvpr18啊 "
        },
        {
            "from": 2222.8,
            "to": 2223.93,
            "location": 2,
            "content": " 所以说在他之前呢 "
        },
        {
            "from": 2223.93,
            "to": 2226.47,
            "location": 2,
            "content": " 其实只有 i 3 d 这一篇工作在 k 400上 "
        },
        {
            "from": 2226.47,
            "to": 2227.87,
            "location": 2,
            "content": " 数据集有这个分数 "
        },
        {
            "from": 2228,
            "to": 2230.17,
            "location": 2,
            "content": " 所以说他就只能跟 i 3 d 去比 "
        },
        {
            "from": 2230.6,
            "to": 2231.3,
            "location": 2,
            "content": " 那这里面呢 "
        },
        {
            "from": 2231.3,
            "to": 2233.27,
            "location": 2,
            "content": " 其实还是有一个比较有意思的现象 "
        },
        {
            "from": 2233.57,
            "to": 2234.93,
            "location": 2,
            "content": " 就说 r （2+1） d 呢 "
        },
        {
            "from": 2234.93,
            "to": 2237.5,
            "location": 2,
            "content": " 不论是在 rgb 上还是在 flow 上呢 "
        },
        {
            "from": 2237.57,
            "to": 2240.3,
            "location": 2,
            "content": " 他的这个结果都比对应的这个 i3d 呢 "
        },
        {
            "from": 2240.3,
            "to": 2241.57,
            "location": 2,
            "content": " 是要高一些的 "
        },
        {
            "from": 2241.77,
            "to": 2243.97,
            "location": 2,
            "content": " 但是呢当你最后做这个 late fusion "
        },
        {
            "from": 2244,
            "to": 2245.67,
            "location": 2,
            "content": " 就是当你把这两个结果加权 "
        },
        {
            "from": 2245.67,
            "to": 2246.7,
            "location": 2,
            "content": " 平均之后呢 "
        },
        {
            "from": 2246.8,
            "to": 2247.73,
            "location": 2,
            "content": " 你会发现哎 "
        },
        {
            "from": 2247.73,
            "to": 2250,
            "location": 2,
            "content": " 这个 i 3 d 的提升呢非常明显 "
        },
        {
            "from": 2250.1,
            "to": 2251,
            "location": 2,
            "content": " 反而是这个 r （2+1）d "
        },
        {
            "from": 2251,
            "to": 2252.53,
            "location": 2,
            "content": " 呢没什么提升 "
        },
        {
            "from": 2252.73,
            "to": 2253.47,
            "location": 2,
            "content": " 所以导致呢 "
        },
        {
            "from": 2253.47,
            "to": 2254.17,
            "location": 2,
            "content": " 这个双流 "
        },
        {
            "from": 2254.17,
            "to": 2257.1,
            "location": 2,
            "content": " r （2+1） d 的结果还不如双流 i 3 d 的结果 "
        },
        {
            "from": 2257.2,
            "to": 2259.37,
            "location": 2,
            "content": " 不过这个呢作者也没有给出解释 "
        },
        {
            "from": 2259.87,
            "to": 2260.27,
            "location": 2,
            "content": " 另外呢 "
        },
        {
            "from": 2260.27,
            "to": 2262.93,
            "location": 2,
            "content": " 我们可以看一下这个在 ucf 101和 hmdb "
        },
        {
            "from": 2262.93,
            "to": 2264.27,
            "location": 2,
            "content": " 51上的这个结果 "
        },
        {
            "from": 2264.4,
            "to": 2265.53,
            "location": 2,
            "content": " 同样我们可以看出 "
        },
        {
            "from": 2265.53,
            "to": 2267.77,
            "location": 2,
            "content": " r （2+1）d 啊表现还是不错的啊 "
        },
        {
            "from": 2267.77,
            "to": 2269.33,
            "location": 2,
            "content": " 但是如果跟 i 3 d 去比呢 "
        },
        {
            "from": 2269.33,
            "to": 2270.7,
            "location": 2,
            "content": " 还是比较怪的现象 "
        },
        {
            "from": 2270.7,
            "to": 2272.27,
            "location": 2,
            "content": " 就是他虽然在 rgb 上呢 "
        },
        {
            "from": 2272.27,
            "to": 2274.17,
            "location": 2,
            "content": " 比这个 i 3 d 的 rgb 要高 "
        },
        {
            "from": 2274.4,
            "to": 2275.5,
            "location": 2,
            "content": " 但是呢他在 flow "
        },
        {
            "from": 2275.5,
            "to": 2277.97,
            "location": 2,
            "content": " 上就已经比 i 3 d 的 flow 要低了 "
        },
        {
            "from": 2278.2,
            "to": 2279.8,
            "location": 2,
            "content": " 然后再把这两个加起来之后呢 "
        },
        {
            "from": 2279.8,
            "to": 2281.4,
            "location": 2,
            "content": " 他的这个结果就更低了 "
        },
        {
            "from": 2281.67,
            "to": 2283.73,
            "location": 2,
            "content": " 那作者这里可能觉得哎呀这不行啊 "
        },
        {
            "from": 2283.73,
            "to": 2286.2,
            "location": 2,
            "content": " 那在 k 400上已经比i3d 低了 "
        },
        {
            "from": 2286.2,
            "to": 2288.9,
            "location": 2,
            "content": " 那如果在 ucf 101和 hmdb 上再低 "
        },
        {
            "from": 2288.9,
            "to": 2290.87,
            "location": 2,
            "content": " 这就不好给审稿人交代了 "
        },
        {
            "from": 2291.27,
            "to": 2291.93,
            "location": 2,
            "content": " 所以他这里呢 "
        },
        {
            "from": 2291.93,
            "to": 2293.87,
            "location": 2,
            "content": " 还在题目里稍微解释了一下 "
        },
        {
            "from": 2293.93,
            "to": 2295.3,
            "location": 2,
            "content": " 他说我们的这个模型啊 "
        },
        {
            "from": 2295.3,
            "to": 2297.6,
            "location": 2,
            "content": " 是光在 k 400上去做预训练的 "
        },
        {
            "from": 2297.67,
            "to": 2298.9,
            "location": 2,
            "content": " 但是上面这个 i3d "
        },
        {
            "from": 2298.9,
            "to": 2300.1,
            "location": 2,
            "content": " 模型啊是在image net "
        },
        {
            "from": 2300.1,
            "to": 2302.17,
            "location": 2,
            "content": " 在加 k 400上去做这个预训练的 "
        },
        {
            "from": 2302.17,
            "to": 2303.77,
            "location": 2,
            "content": " 那他们比我多用了image net "
        },
        {
            "from": 2303.77,
            "to": 2304.73,
            "location": 2,
            "content": " 的这个预训练 "
        },
        {
            "from": 2304.73,
            "to": 2307.53,
            "location": 2,
            "content": " 所以说他们比我高啊这是理所当然的 "
        },
        {
            "from": 2307.9,
            "to": 2310.57,
            "location": 2,
            "content": " 但是事实上呢这句话可能不太成立啊 "
        },
        {
            "from": 2310.57,
            "to": 2312.27,
            "location": 2,
            "content": " 因为我们之前如果精读过  "
        },
        {
            "from": 2312.27,
            "to": 2313.2,
            "location": 2,
            "content": " i3d 一篇论文呢 "
        },
        {
            "from": 2313.2,
            "to": 2314.2,
            "location": 2,
            "content": " 我们就会知道 "
        },
        {
            "from": 2314.4,
            "to": 2315.73,
            "location": 2,
            "content": " i 3 d 那篇论文里呢 "
        },
        {
            "from": 2315.73,
            "to": 2317.47,
            "location": 2,
            "content": " 也做了就是单独用  "
        },
        {
            "from": 2317.47,
            "to": 2319.33,
            "location": 2,
            "content": " k400去预训练模型的结果 "
        },
        {
            "from": 2319.6,
            "to": 2320.47,
            "location": 2,
            "content": " 而且事实上呢 "
        },
        {
            "from": 2320.47,
            "to": 2322.77,
            "location": 2,
            "content": " 最后这里的结果应该是97.8啊 "
        },
        {
            "from": 2322.77,
            "to": 2324.4,
            "location": 2,
            "content": " 这里呢应该是80.9 "
        },
        {
            "from": 2324.5,
            "to": 2325.57,
            "location": 2,
            "content": " 所以是丝毫不 "
        },
        {
            "from": 2325.57,
            "to": 2327.97,
            "location": 2,
            "content": " 比这个用了image net要差的 "
        },
        {
            "from": 2328.13,
            "to": 2330.9,
            "location": 2,
            "content": " 反而有可能在 hmdb 上呢是更好的 "
        },
        {
            "from": 2331.07,
            "to": 2332.1,
            "location": 2,
            "content": " 所以这也就意味着 "
        },
        {
            "from": 2332.1,
            "to": 2334.27,
            "location": 2,
            "content": " 其实 r 2加1 d 这个模型啊 "
        },
        {
            "from": 2334.27,
            "to": 2337.73,
            "location": 2,
            "content": " 至少在  ucf 101和 hmdb 51这两个数据集上 "
        },
        {
            "from": 2337.8,
            "to": 2339.5,
            "location": 2,
            "content": " 效果是不如 i 3 d 的 "
        },
        {
            "from": 2340.07,
            "to": 2342.57,
            "location": 2,
            "content": " 当然这个呢我觉得其实是情有可原的 "
        },
        {
            "from": 2342.57,
            "to": 2344,
            "location": 2,
            "content": " 因为毕竟 r （2+1） d 呢 "
        },
        {
            "from": 2344,
            "to": 2346.53,
            "location": 2,
            "content": " 他用的这个输入呢是112*112 "
        },
        {
            "from": 2346.77,
            "to": 2350.27,
            "location": 2,
            "content": " 他是比原来这个 i 3 d 的224*224要小一倍的 "
        },
        {
            "from": 2350.37,
            "to": 2352.73,
            "location": 2,
            "content": " 所以效果低这么一点呢也没什么关系 "
        },
        {
            "from": 2352.93,
            "to": 2355.2,
            "location": 2,
            "content": " 而且 r （2+1） d 这种拆分的模式呢 "
        },
        {
            "from": 2355.2,
            "to": 2357.67,
            "location": 2,
            "content": " 确实有助于这个模型的训练啊 "
        },
        {
            "from": 2357.67,
            "to": 2359.8,
            "location": 2,
            "content": " 确实有助于降低这种过拟合 "
        },
        {
            "from": 2360.17,
            "to": 2361.6,
            "location": 2,
            "content": " 而且他不需要借助于 "
        },
        {
            "from": 2361.6,
            "to": 2363.5,
            "location": 2,
            "content": " image net的这个预训练模型啊 "
        },
        {
            "from": 2363.5,
            "to": 2365.87,
            "location": 2,
            "content": " 他是可以重头自己开始训练的 "
        },
        {
            "from": 2366.13,
            "to": 2368.77,
            "location": 2,
            "content": " 而不是像 i 3 d 一样啊借助了2 d 模型 "
        },
        {
            "from": 2368.77,
            "to": 2371.17,
            "location": 2,
            "content": " 也借助了2 d 模型的这个预训练参数啊 "
        },
        {
            "from": 2371.17,
            "to": 2372.8,
            "location": 2,
            "content": " 才导致这个比较好优化 "
        },
        {
            "from": 2373.27,
            "to": 2374.67,
            "location": 2,
            "content": " 所以说 r （2+1） d 啊 "
        },
        {
            "from": 2374.67,
            "to": 2376,
            "location": 2,
            "content": " 这个网络本身的结构呢 "
        },
        {
            "from": 2376,
            "to": 2377.53,
            "location": 2,
            "content": " 也是非常值得学习的 "
        },
        {
            "from": 2377.93,
            "to": 2379.67,
            "location": 2,
            "content": " 那在前两年对比学习啊 "
        },
        {
            "from": 2379.67,
            "to": 2381.3,
            "location": 2,
            "content": " 或者说自监督学习在视频 "
        },
        {
            "from": 2381.3,
            "to": 2382.87,
            "location": 2,
            "content": " 领域里也比较火的时候呢 "
        },
        {
            "from": 2383.07,
            "to": 2385.1,
            "location": 2,
            "content": " 很多人都是采用 r （2+1） d 啊 "
        },
        {
            "from": 2385.1,
            "to": 2386.57,
            "location": 2,
            "content": " 当做这个网络的backbone "
        },
        {
            "from": 2386.67,
            "to": 2388.77,
            "location": 2,
            "content": " 去做这种视频的自监督训练呢 "
        },
        {
            "from": 2389.07,
            "to": 2390.2,
            "location": 2,
            "content": " 一个很重要的原因呢 "
        },
        {
            "from": 2390.2,
            "to": 2391.73,
            "location": 2,
            "content": " 也是因为他比较好优化 "
        },
        {
            "from": 2391.73,
            "to": 2394.27,
            "location": 2,
            "content": " 而且呢他的一个输入是112*112啊 "
        },
        {
            "from": 2394.27,
            "to": 2395.1,
            "location": 2,
            "content": " 也比较小 "
        },
        {
            "from": 2395.1,
            "to": 2396.93,
            "location": 2,
            "content": " 对gpu 内存呢比较友好 "
        },
        {
            "from": 2397.37,
            "to": 2397.9,
            "location": 2,
            "content": " 然后呢 "
        },
        {
            "from": 2397.9,
            "to": 2400.47,
            "location": 2,
            "content": " 接下来我们还会讲到times formerr 这篇论文 "
        },
        {
            "from": 2400.57,
            "to": 2402.8,
            "location": 2,
            "content": " 其实也是r 2+1 d 这篇论文里有些作者 "
        },
        {
            "from": 2402.8,
            "to": 2405.07,
            "location": 2,
            "content": " 写的想法上也非常类似 "
        },
        {
            "from": 2405.57,
            "to": 2408.2,
            "location": 2,
            "content": " 就是把一个 spatial temporal 的一个transformer呢 "
        },
        {
            "from": 2408.3,
            "to": 2410.33,
            "location": 2,
            "content": " 拆分成了在空间上和时间上 "
        },
        {
            "from": 2410.33,
            "to": 2412.27,
            "location": 2,
            "content": " 分别去做这个自注意力操作 "
        },
        {
            "from": 2412.6,
            "to": 2414.97,
            "location": 2,
            "content": " 这样子呢就大大简化了对显存的要求 "
        },
        {
            "from": 2415.07,
            "to": 2416.27,
            "location": 2,
            "content": " 从而呢在视频上呢 "
        },
        {
            "from": 2416.27,
            "to": 2418.17,
            "location": 2,
            "content": " 也能训练起一个vision transformer "
        },
        {
            "from": 2418.5,
            "to": 2419.7,
            "location": 2,
            "content": " 总之呢 r 2+1 d "
        },
        {
            "from": 2419.7,
            "to": 2420.4,
            "location": 2,
            "content": " 这篇论文呢 "
        },
        {
            "from": 2420.4,
            "to": 2421.3,
            "location": 2,
            "content": " 当你读完以后 "
        },
        {
            "from": 2421.3,
            "to": 2423.93,
            "location": 2,
            "content": " 你就会发现它是一个纯实验性的论文 "
        },
        {
            "from": 2424.1,
            "to": 2425.1,
            "location": 2,
            "content": " 它主要的贡献呢 "
        },
        {
            "from": 2425.1,
            "to": 2426.8,
            "location": 2,
            "content": " 就在于它的这个消融实验 "
        },
        {
            "from": 2426.93,
            "to": 2429.57,
            "location": 2,
            "content": " 以及它带给你的各种这种观察和见解 "
        },
        {
            "from": 2429.87,
            "to": 2431.3,
            "location": 2,
            "content": " 从而能够帮助你理解啊 "
        },
        {
            "from": 2431.3,
            "to": 2432,
            "location": 2,
            "content": " 视频领域里 "
        },
        {
            "from": 2432,
            "to": 2434.4,
            "location": 2,
            "content": " 不同架构之间的这个区别和联系啊 "
        },
        {
            "from": 2434.4,
            "to": 2436.57,
            "location": 2,
            "content": " 以及到底应该怎么去构建一个 "
        },
        {
            "from": 2436.57,
            "to": 2438.9,
            "location": 2,
            "content": " 适合于视频理解的这个模型框架 "
        },
        {
            "from": 2440,
            "to": 2441.33,
            "location": 2,
            "content": " 那3 d 网络的最后呢 "
        },
        {
            "from": 2441.33,
            "to": 2443.47,
            "location": 2,
            "content": " 我们来看一下slowfast这篇论文 "
        },
        {
            "from": 2443.6,
            "to": 2445.7,
            "location": 2,
            "content": " 那作者呢又是我们熟悉的一帮人 "
        },
        {
            "from": 2445.8,
            "to": 2448,
            "location": 2,
            "content": " 这篇论文呢其实是3 d 网络里啊 "
        },
        {
            "from": 2448,
            "to": 2449.1,
            "location": 2,
            "content": " 结合这个精度 "
        },
        {
            "from": 2449.1,
            "to": 2450.07,
            "location": 2,
            "content": " 而且这个效率 "
        },
        {
            "from": 2450.07,
            "to": 2451.7,
            "location": 2,
            "content": " 结合的比较好的一个工作 "
        },
        {
            "from": 2451.97,
            "to": 2454.53,
            "location": 2,
            "content": " 他的想法呢很简单也非常有意思 "
        },
        {
            "from": 2455.27,
            "to": 2457.57,
            "location": 2,
            "content": " 其实有点借鉴了双流网络的思想啊 "
        },
        {
            "from": 2457.57,
            "to": 2457.9,
            "location": 2,
            "content": " 但是 "
        },
        {
            "from": 2457.9,
            "to": 2460.07,
            "location": 2,
            "content": " 并没有用光流作为这个模型的输入 "
        },
        {
            "from": 2460.07,
            "to": 2462.1,
            "location": 2,
            "content": " 啊他还是一个单纯的3 d 网络 "
        },
        {
            "from": 2462.53,
            "to": 2463.53,
            "location": 2,
            "content": " 作者在文章中啊 "
        },
        {
            "from": 2463.53,
            "to": 2465.57,
            "location": 2,
            "content": " 其实说他们的这个研究动机 "
        },
        {
            "from": 2465.57,
            "to": 2467.73,
            "location": 2,
            "content": " 来源于说人的这个视觉系统啊 "
        },
        {
            "from": 2467.73,
            "to": 2468.9,
            "location": 2,
            "content": " 有两种细胞 "
        },
        {
            "from": 2469.07,
            "to": 2470.3,
            "location": 2,
            "content": " 一个呢叫 p 细胞 "
        },
        {
            "from": 2470.3,
            "to": 2471.7,
            "location": 2,
            "content": " 一个叫呢叫 m 细胞 "
        },
        {
            "from": 2472.1,
            "to": 2473.7,
            "location": 2,
            "content": " p细胞呢数量比较多啊 "
        },
        {
            "from": 2473.7,
            "to": 2475.9,
            "location": 2,
            "content": " 占到这个视觉细胞的80%啊 "
        },
        {
            "from": 2475.9,
            "to": 2476.27,
            "location": 2,
            "content": " 他呢 "
        },
        {
            "from": 2476.27,
            "to": 2478.7,
            "location": 2,
            "content": " 主要是负责处理这个静态图像的啊 "
        },
        {
            "from": 2478.7,
            "to": 2480.4,
            "location": 2,
            "content": " 就是说现在当前这个图像里呢 "
        },
        {
            "from": 2480.4,
            "to": 2482.3,
            "location": 2,
            "content": " 这个场景是什么信息啊 "
        },
        {
            "from": 2482.3,
            "to": 2483.93,
            "location": 2,
            "content": " 他要描绘的非常具体啊 "
        },
        {
            "from": 2483.93,
            "to": 2484.9,
            "location": 2,
            "content": " p细胞是干这个的 "
        },
        {
            "from": 2484.9,
            "to": 2488.07,
            "location": 2,
            "content": " m 细胞呢是处理这个运动信息的 "
        },
        {
            "from": 2488.07,
            "to": 2490.67,
            "location": 2,
            "content": " 他能处理这种高频率的这个运动信息 "
        },
        {
            "from": 2490.87,
            "to": 2491.27,
            "location": 2,
            "content": " 他呢 "
        },
        {
            "from": 2491.27,
            "to": 2493.87,
            "location": 2,
            "content": " 只占这个视觉细胞呢大概20%的数量 "
        },
        {
            "from": 2494.3,
            "to": 2495.4,
            "location": 2,
            "content": " 所以作者想了想呢 "
        },
        {
            "from": 2495.4,
            "to": 2496.27,
            "location": 2,
            "content": " 他觉得这个哎 "
        },
        {
            "from": 2496.27,
            "to": 2498.33,
            "location": 2,
            "content": " 跟这个双流系统呢也有点像啊 "
        },
        {
            "from": 2498.33,
            "to": 2500.73,
            "location": 2,
            "content": " 就是有一支呢是处理这个动态信息 "
        },
        {
            "from": 2500.73,
            "to": 2502.73,
            "location": 2,
            "content": " 一支呢是处理这个静态信息 "
        },
        {
            "from": 2502.8,
            "to": 2503.8,
            "location": 2,
            "content": " 那3 d 这边呢 "
        },
        {
            "from": 2503.8,
            "to": 2505.53,
            "location": 2,
            "content": " 其实我也可以这么设计一下 "
        },
        {
            "from": 2505.53,
            "to": 2507.77,
            "location": 2,
            "content": " 所以就有了 slow fast 这个网络 "
        },
        {
            "from": 2508.13,
            "to": 2508.93,
            "location": 2,
            "content": " slow fast 呢 "
        },
        {
            "from": 2508.93,
            "to": 2511.73,
            "location": 2,
            "content": " 顾名思义就是有一支网络呢是 slow 的 "
        },
        {
            "from": 2511.73,
            "to": 2513.33,
            "location": 2,
            "content": " 有一支网络的是 fast "
        },
        {
            "from": 2513.87,
            "to": 2515.97,
            "location": 2,
            "content": " 具体怎么个 slow 和 fast 法呢 "
        },
        {
            "from": 2516.27,
            "to": 2518.5,
            "location": 2,
            "content": " 那假设说呢我们现在有一个视频 "
        },
        {
            "from": 2518.57,
            "to": 2520.2,
            "location": 2,
            "content": " 那这个视频呢有64帧 "
        },
        {
            "from": 2520.2,
            "to": 2521.73,
            "location": 2,
            "content": " 那就说到2秒多 "
        },
        {
            "from": 2522.13,
            "to": 2523.1,
            "location": 2,
            "content": " 那如果我们现在呢 "
        },
        {
            "from": 2523.1,
            "to": 2524.53,
            "location": 2,
            "content": " 先用很低的这个帧率 "
        },
        {
            "from": 2524.53,
            "to": 2526.77,
            "location": 2,
            "content": " 就比如说每隔16帧取一帧啊 "
        },
        {
            "from": 2526.77,
            "to": 2528.27,
            "location": 2,
            "content": " 取出来4帧的话呢 "
        },
        {
            "from": 2528.37,
            "to": 2530.07,
            "location": 2,
            "content": " 这一支呢就叫慢分支 "
        },
        {
            "from": 2530.3,
            "to": 2531.9,
            "location": 2,
            "content": " 他呢就像那个p细胞一样 "
        },
        {
            "from": 2531.9,
            "to": 2533.9,
            "location": 2,
            "content": " 主要是学习这个静态图像啊 "
        },
        {
            "from": 2533.9,
            "to": 2535.97,
            "location": 2,
            "content": " 主要是学习这个场景信息的 "
        },
        {
            "from": 2536.1,
            "to": 2537.13,
            "location": 2,
            "content": " 那因为p细胞 "
        },
        {
            "from": 2537.13,
            "to": 2539.37,
            "location": 2,
            "content": " 他占了整个视觉细胞的30%吧 "
        },
        {
            "from": 2539.47,
            "to": 2540.27,
            "location": 2,
            "content": " 所以这里面呢 "
        },
        {
            "from": 2540.27,
            "to": 2542.2,
            "location": 2,
            "content": " 作者觉得这个静态图像的这描绘呢 "
        },
        {
            "from": 2542.2,
            "to": 2542.93,
            "location": 2,
            "content": " 也比较难 "
        },
        {
            "from": 2542.93,
            "to": 2543.93,
            "location": 2,
            "content": " 所以说他也想把 "
        },
        {
            "from": 2543.93,
            "to": 2545.53,
            "location": 2,
            "content": " 大部分的这个模型参数呢 "
        },
        {
            "from": 2545.53,
            "to": 2547,
            "location": 2,
            "content": " 给这个慢分支 "
        },
        {
            "from": 2547.47,
            "to": 2547.9,
            "location": 2,
            "content": " 所以说啊 "
        },
        {
            "from": 2547.9,
            "to": 2549.4,
            "location": 2,
            "content": " 这个慢分支的这个网络结构 "
        },
        {
            "from": 2549.4,
            "to": 2550.73,
            "location": 2,
            "content": " 其实是比较大的 "
        },
        {
            "from": 2550.8,
            "to": 2553.47,
            "location": 2,
            "content": " 简单来说呢其实他就是一个 i 3 d 网络 "
        },
        {
            "from": 2553.9,
            "to": 2554.67,
            "location": 2,
            "content": " 但是因为呢 "
        },
        {
            "from": 2554.67,
            "to": 2556.5,
            "location": 2,
            "content": " 给这个大 i 3 d 网络的输入呢 "
        },
        {
            "from": 2556.5,
            "to": 2557.37,
            "location": 2,
            "content": " 只有4帧 "
        },
        {
            "from": 2557.37,
            "to": 2558.5,
            "location": 2,
            "content": " 所以说相对而言呢 "
        },
        {
            "from": 2558.5,
            "to": 2560.4,
            "location": 2,
            "content": " 他这个计算复杂度不是太高 "
        },
        {
            "from": 2560.8,
            "to": 2562.67,
            "location": 2,
            "content": " 然后呢就到了底下这个快分支 "
        },
        {
            "from": 2562.9,
            "to": 2565.2,
            "location": 2,
            "content": " 那快分支呢就是假如说你有64帧 "
        },
        {
            "from": 2565.2,
            "to": 2567.27,
            "location": 2,
            "content": " 那我现在每隔4帧取一帧 "
        },
        {
            "from": 2567.27,
            "to": 2568.87,
            "location": 2,
            "content": " 就我用这个很快的帧率 "
        },
        {
            "from": 2568.87,
            "to": 2570.1,
            "location": 2,
            "content": " 现在去取样啊 "
        },
        {
            "from": 2570.1,
            "to": 2571.97,
            "location": 2,
            "content": " 最后呢我就取得到16帧 "
        },
        {
            "from": 2572.1,
            "to": 2574.77,
            "location": 2,
            "content": " 然后把这个16帧呢输入给这个快分支 "
        },
        {
            "from": 2575.13,
            "to": 2577.3,
            "location": 2,
            "content": " 那现在呢因为你这个输入变多了吗 "
        },
        {
            "from": 2577.47,
            "to": 2579.7,
            "location": 2,
            "content": " 我为了维持整个这个模型的计算 "
        },
        {
            "from": 2579.7,
            "to": 2581.07,
            "location": 2,
            "content": " 开销呢还是比较小 "
        },
        {
            "from": 2581.13,
            "to": 2583.27,
            "location": 2,
            "content": " 所以我就要让这个快分支的网络呢 "
        },
        {
            "from": 2583.27,
            "to": 2584.53,
            "location": 2,
            "content": " 尽可能的小 "
        },
        {
            "from": 2584.9,
            "to": 2586.4,
            "location": 2,
            "content": " 这样呢就模拟了这个视觉里 "
        },
        {
            "from": 2586.4,
            "to": 2587.47,
            "location": 2,
            "content": " 这个 m 细胞 "
        },
        {
            "from": 2587.5,
            "to": 2589.47,
            "location": 2,
            "content": " 它呢只占整体的20% "
        },
        {
            "from": 2589.5,
            "to": 2591.27,
            "location": 2,
            "content": " 主要就是描述运动信息 "
        },
        {
            "from": 2591.33,
            "to": 2592.93,
            "location": 2,
            "content": " 那因为你描述运动信息吗 "
        },
        {
            "from": 2592.93,
            "to": 2594.53,
            "location": 2,
            "content": " 所以你需要更多的这个帧 "
        },
        {
            "from": 2594.53,
            "to": 2595.13,
            "location": 2,
            "content": " 然后这样 "
        },
        {
            "from": 2595.13,
            "to": 2597.1,
            "location": 2,
            "content": " 能快速的看出来他们之间的改变 "
        },
        {
            "from": 2597.1,
            "to": 2599.07,
            "location": 2,
            "content": " 所以说听起来是非常合理的 "
        },
        {
            "from": 2599.3,
            "to": 2600.47,
            "location": 2,
            "content": " 所以整体上来看呢 "
        },
        {
            "from": 2600.47,
            "to": 2602.9,
            "location": 2,
            "content": " slow fast 的也是一个两分支的结构啊 "
        },
        {
            "from": 2602.9,
            "to": 2604.1,
            "location": 2,
            "content": " 跟双流网络一样 "
        },
        {
            "from": 2604.1,
            "to": 2605.93,
            "location": 2,
            "content": " 然后上面呢是这个慢分支 "
        },
        {
            "from": 2605.93,
            "to": 2607.5,
            "location": 2,
            "content": " 下面呢是这个快分支 "
        },
        {
            "from": 2607.73,
            "to": 2610.4,
            "location": 2,
            "content": " 慢分支呢用小输入但是大网络 "
        },
        {
            "from": 2610.47,
            "to": 2612.87,
            "location": 2,
            "content": " 快分支呢用大输入和小网络 "
        },
        {
            "from": 2613.27,
            "to": 2614.67,
            "location": 2,
            "content": " 然后这两个分支之间呢 "
        },
        {
            "from": 2614.67,
            "to": 2616.13,
            "location": 2,
            "content": " 还用这种 later connection "
        },
        {
            "from": 2616.13,
            "to": 2617.33,
            "location": 2,
            "content": " 把他们都结合了起来 "
        },
        {
            "from": 2617.33,
            "to": 2618.6,
            "location": 2,
            "content": " 所以他们之间的这信息啊 "
        },
        {
            "from": 2618.6,
            "to": 2619.97,
            "location": 2,
            "content": " 是可以互相交互的 "
        },
        {
            "from": 2619.97,
            "to": 2622.47,
            "location": 2,
            "content": " 从而能够更好的学习到这个时空特征 "
        },
        {
            "from": 2622.6,
            "to": 2623.1,
            "location": 2,
            "content": " 最后呢 "
        },
        {
            "from": 2623.1,
            "to": 2624.77,
            "location": 2,
            "content": " 达到了一个比较好的这个精度 "
        },
        {
            "from": 2624.77,
            "to": 2626.13,
            "location": 2,
            "content": " 和速度的这个结合 "
        },
        {
            "from": 2626.6,
            "to": 2627.73,
            "location": 2,
            "content": " 那看完图1之后呢 "
        },
        {
            "from": 2627.73,
            "to": 2629.27,
            "location": 2,
            "content": " 其实大家基本上已经知道 "
        },
        {
            "from": 2629.27,
            "to": 2630.37,
            "location": 2,
            "content": " slowfast的这个网络 "
        },
        {
            "from": 2630.37,
            "to": 2631.6,
            "location": 2,
            "content": " 到底是什么结构了 "
        },
        {
            "from": 2631.6,
            "to": 2632.27,
            "location": 2,
            "content": " 那接下来呢 "
        },
        {
            "from": 2632.27,
            "to": 2634.73,
            "location": 2,
            "content": " 我们就具体来看一下这个表1 啊 "
        },
        {
            "from": 2634.73,
            "to": 2636.6,
            "location": 2,
            "content": " 从头到尾走一遍这个前向过程 "
        },
        {
            "from": 2636.6,
            "to": 2638.5,
            "location": 2,
            "content": " 看一看这个输入输出的大小 "
        },
        {
            "from": 2638.53,
            "to": 2640.4,
            "location": 2,
            "content": " 就能更形象的了解这个网络 "
        },
        {
            "from": 2640.8,
            "to": 2642.57,
            "location": 2,
            "content": " 首先呢这个是慢分支啊 "
        },
        {
            "from": 2642.57,
            "to": 2643.5,
            "location": 2,
            "content": " 这个是快分支 "
        },
        {
            "from": 2643.5,
            "to": 2645.67,
            "location": 2,
            "content": " 然而这个呢是他们这个输出的大小 "
        },
        {
            "from": 2646.17,
            "to": 2647.8,
            "location": 2,
            "content": " 首先我们来看一下网络啊 "
        },
        {
            "from": 2647.8,
            "to": 2649.27,
            "location": 2,
            "content": " 网络的话我们刚才也说了这 "
        },
        {
            "from": 2649.27,
            "to": 2649.97,
            "location": 2,
            "content": " 个慢分支呢 "
        },
        {
            "from": 2649.97,
            "to": 2652.47,
            "location": 2,
            "content": " 其实就是一个标准的 i 3 d 网络啊 "
        },
        {
            "from": 2652.47,
            "to": 2654.07,
            "location": 2,
            "content": " 这里呢也就是一个 resnet "
        },
        {
            "from": 2654.07,
            "to": 2656.8,
            "location": 2,
            "content": " 我们也可以看到有 res 2345有4个 stage "
        },
        {
            "from": 2656.97,
            "to": 2658.73,
            "location": 2,
            "content": " 然后这里面就是呢 res 50 "
        },
        {
            "from": 2658.73,
            "to": 2661.67,
            "location": 2,
            "content": " 所以呢有3463这么多这个 residual block "
        },
        {
            "from": 2662,
            "to": 2664.2,
            "location": 2,
            "content": " 所以说这个慢分支呢本身就是个 i 3 d "
        },
        {
            "from": 2664.2,
            "to": 2665.47,
            "location": 2,
            "content": " 是非常标准的啊 "
        },
        {
            "from": 2665.47,
            "to": 2667.17,
            "location": 2,
            "content": " 作者这里也没有过多的强调 "
        },
        {
            "from": 2667.67,
            "to": 2669.1,
            "location": 2,
            "content": " 然后对于这个快分支呢 "
        },
        {
            "from": 2669.1,
            "to": 2670.8,
            "location": 2,
            "content": " 作者其实就把这几个数字啊 "
        },
        {
            "from": 2670.8,
            "to": 2672.1,
            "location": 2,
            "content": " 变成这个黄色了 "
        },
        {
            "from": 2672.17,
            "to": 2673.93,
            "location": 2,
            "content": " 那他之所以变成黄色呢 "
        },
        {
            "from": 2673.93,
            "to": 2675,
            "location": 2,
            "content": " 他就是想让你看一下 "
        },
        {
            "from": 2675,
            "to": 2676.87,
            "location": 2,
            "content": " 这个慢分支和快分支的这个 "
        },
        {
            "from": 2676.87,
            "to": 2677.97,
            "location": 2,
            "content": " 通道数的对比 "
        },
        {
            "from": 2678.13,
            "to": 2680.37,
            "location": 2,
            "content": " 我们可以看到这个快分支的通道数呢 "
        },
        {
            "from": 2680.37,
            "to": 2680.87,
            "location": 2,
            "content": " 是远 "
        },
        {
            "from": 2680.87,
            "to": 2683.27,
            "location": 2,
            "content": " 远小于这个慢分支的这个通道数的 "
        },
        {
            "from": 2683.27,
            "to": 2686.07,
            "location": 2,
            "content": " 也就意味着这个快分支呢是非常轻量 "
        },
        {
            "from": 2686.57,
            "to": 2687.57,
            "location": 2,
            "content": " 但是整体结构呢 "
        },
        {
            "from": 2687.57,
            "to": 2689.67,
            "location": 2,
            "content": " 这个快分支跟慢分支也是一样的啊 "
        },
        {
            "from": 2689.67,
            "to": 2690.97,
            "location": 2,
            "content": " 也是一个残差网络啊 "
        },
        {
            "from": 2690.97,
            "to": 2693.4,
            "location": 2,
            "content": " 也是3463这么多residual block "
        },
        {
            "from": 2693.9,
            "to": 2695.33,
            "location": 2,
            "content": " 那看完网络结构之后呢 "
        },
        {
            "from": 2695.33,
            "to": 2697.13,
            "location": 2,
            "content": " 我们就来过一下这个前向过程 "
        },
        {
            "from": 2697.2,
            "to": 2699.5,
            "location": 2,
            "content": " 那首先呢这个输入呢是64帧 "
        },
        {
            "from": 2699.5,
            "to": 2701.73,
            "location": 2,
            "content": " 那这个帧呢是224*224这么大 "
        },
        {
            "from": 2701.97,
            "to": 2703.13,
            "location": 2,
            "content": " 那对于慢分支来说呢 "
        },
        {
            "from": 2703.13,
            "to": 2704.1,
            "location": 2,
            "content": " 就像我们刚才说这样 "
        },
        {
            "from": 2704.1,
            "to": 2705.5,
            "location": 2,
            "content": " 每隔16帧取一帧 "
        },
        {
            "from": 2705.5,
            "to": 2707.8,
            "location": 2,
            "content": " 所以说这个慢分支的输入呢只有4帧 "
        },
        {
            "from": 2707.9,
            "to": 2709.2,
            "location": 2,
            "content": " 但是快分支呢啊 "
        },
        {
            "from": 2709.2,
            "to": 2711.37,
            "location": 2,
            "content": " 他这里其实是每隔一帧就取了一帧 "
        },
        {
            "from": 2711.37,
            "to": 2713.5,
            "location": 2,
            "content": " 所以说呢一个还取了32帧 "
        },
        {
            "from": 2713.5,
            "to": 2715.53,
            "location": 2,
            "content": " 比我刚才说的16帧还要多一倍 "
        },
        {
            "from": 2715.9,
            "to": 2716.3,
            "location": 2,
            "content": " 所以说啊 "
        },
        {
            "from": 2716.3,
            "to": 2718.3,
            "location": 2,
            "content": " 这个快分支的输入呢是相当大的 "
        },
        {
            "from": 2718.3,
            "to": 2719,
            "location": 2,
            "content": " 这也就是为什么 "
        },
        {
            "from": 2719,
            "to": 2719.33,
            "location": 2,
            "content": " 作者 "
        },
        {
            "from": 2719.33,
            "to": 2721.8,
            "location": 2,
            "content": " 一定把这里的通道数要减小的原因 "
        },
        {
            "from": 2721.9,
            "to": 2724.33,
            "location": 2,
            "content": " 啊否则这个计算开销实在是受不了 "
        },
        {
            "from": 2724.73,
            "to": 2725.77,
            "location": 2,
            "content": " 然后我们可以看到 "
        },
        {
            "from": 2725.77,
            "to": 2727.07,
            "location": 2,
            "content": " 这个slowfast跟之前 "
        },
        {
            "from": 2727.07,
            "to": 2728.17,
            "location": 2,
            "content": " 这个 i 3 d 网络啊 "
        },
        {
            "from": 2728.17,
            "to": 2730.1,
            "location": 2,
            "content": " 或者 r （2+1）d 网络啊都一样 "
        },
        {
            "from": 2730.2,
            "to": 2732.1,
            "location": 2,
            "content": " 他们呢在这个时序上 "
        },
        {
            "from": 2732.1,
            "to": 2734.3,
            "location": 2,
            "content": " 其实都是没有进行下采样的 "
        },
        {
            "from": 2734.6,
            "to": 2735.93,
            "location": 2,
            "content": " 你的输入呢是4帧 "
        },
        {
            "from": 2735.93,
            "to": 2737.67,
            "location": 2,
            "content": " 那接下都是4帧4帧4帧 "
        },
        {
            "from": 2737.67,
            "to": 2739.1,
            "location": 2,
            "content": " 一直到最后也是4帧 "
        },
        {
            "from": 2739.33,
            "to": 2741.37,
            "location": 2,
            "content": " 你的这个快分支输入是32 "
        },
        {
            "from": 2741.37,
            "to": 2742.97,
            "location": 2,
            "content": " 你到最后呢还是32 "
        },
        {
            "from": 2743.2,
            "to": 2745,
            "location": 2,
            "content": " 所以他在这个时间的维度上呢 "
        },
        {
            "from": 2745,
            "to": 2746.4,
            "location": 2,
            "content": " 始终不做下采样 "
        },
        {
            "from": 2746.47,
            "to": 2748.7,
            "location": 2,
            "content": " 因为他想尽可能的保持这么多帧啊 "
        },
        {
            "from": 2748.7,
            "to": 2750.47,
            "location": 2,
            "content": " 去学习更好的这个时序信息 "
        },
        {
            "from": 2750.47,
            "to": 2751.8,
            "location": 2,
            "content": " 因为本身就不多 "
        },
        {
            "from": 2751.93,
            "to": 2752.87,
            "location": 2,
            "content": " 他这个下采样呢 "
        },
        {
            "from": 2752.87,
            "to": 2754.9,
            "location": 2,
            "content": " 全都是在这个空间维度上做的啊 "
        },
        {
            "from": 2754.9,
            "to": 2757.6,
            "location": 2,
            "content": " 从刚开始的224然后降到112 56 "
        },
        {
            "from": 2757.6,
            "to": 2758.8,
            "location": 2,
            "content": " 然后24 14 "
        },
        {
            "from": 2758.8,
            "to": 2760.07,
            "location": 2,
            "content": " 然后到最后的7 "
        },
        {
            "from": 2760.33,
            "to": 2762.57,
            "location": 2,
            "content": " 那最后呢再接一个这个全局平均池化 "
        },
        {
            "from": 2762.57,
            "to": 2764,
            "location": 2,
            "content": " 然后再接一层这个 fc "
        },
        {
            "from": 2764.1,
            "to": 2765.6,
            "location": 2,
            "content": " 就可以直接做输出了 "
        },
        {
            "from": 2765.93,
            "to": 2766.8,
            "location": 2,
            "content": " 值得一提的呢 "
        },
        {
            "from": 2766.8,
            "to": 2768.77,
            "location": 2,
            "content": " 就是这每一个 residual block 后面呢 "
        },
        {
            "from": 2768.77,
            "to": 2770.53,
            "location": 2,
            "content": " 都有一个这个 lateral connection "
        },
        {
            "from": 2770.97,
            "to": 2772.6,
            "location": 2,
            "content": " 其实呢就是一个简单的连接 "
        },
        {
            "from": 2772.6,
            "to": 2773.93,
            "location": 2,
            "content": " 能让这两个分支之间呢 "
        },
        {
            "from": 2773.93,
            "to": 2775.4,
            "location": 2,
            "content": " 进行简单的信息交互 "
        },
        {
            "from": 2775.57,
            "to": 2777.7,
            "location": 2,
            "content": " 从而更好的学习时空上的特征 "
        },
        {
            "from": 2778.57,
            "to": 2780.5,
            "location": 2,
            "content": " 因为 slow fast 这篇论文的想法呢 "
        },
        {
            "from": 2780.5,
            "to": 2781.77,
            "location": 2,
            "content": " 确实比较直接了当 "
        },
        {
            "from": 2782.07,
            "to": 2784.3,
            "location": 2,
            "content": " 所以我们这里呢就直接看结果了啊 "
        },
        {
            "from": 2784.3,
            "to": 2786.87,
            "location": 2,
            "content": " 当然 slow fast 他还做了这个视频分类啊 "
        },
        {
            "from": 2786.87,
            "to": 2787.73,
            "location": 2,
            "content": " 视频检测 "
        },
        {
            "from": 2787.93,
            "to": 2789.87,
            "location": 2,
            "content": " 他做了好几个数据集啊 "
        },
        {
            "from": 2789.9,
            "to": 2791.37,
            "location": 2,
            "content": " 他的结果都是非常好的 "
        },
        {
            "from": 2791.37,
            "to": 2792.13,
            "location": 2,
            "content": " 那我们这里呢 "
        },
        {
            "from": 2792.13,
            "to": 2794.57,
            "location": 2,
            "content": " 就简单看一下 k 400上的效果就可以了 "
        },
        {
            "from": 2794.93,
            "to": 2796.57,
            "location": 2,
            "content": " 我们直接来看这个表2啊 "
        },
        {
            "from": 2796.8,
            "to": 2798.8,
            "location": 2,
            "content": " 那到 iccv 19的时候呢 "
        },
        {
            "from": 2799,
            "to": 2801,
            "location": 2,
            "content": " 啊其实 k 400已经提出有两年了 "
        },
        {
            "from": 2801,
            "to": 2802.57,
            "location": 2,
            "content": " 所以说我们可以看到这里面啊 "
        },
        {
            "from": 2802.57,
            "to": 2803.93,
            "location": 2,
            "content": " 之前的工作也有很多 "
        },
        {
            "from": 2803.93,
            "to": 2805.27,
            "location": 2,
            "content": " 在 k 400上这个汇报了 "
        },
        {
            "from": 2805.27,
            "to": 2807.13,
            "location": 2,
            "content": " 分数我们首先可以看到 "
        },
        {
            "from": 2807.13,
            "to": 2809.53,
            "location": 2,
            "content": " 作者把上了这个区域呢给灰色化了 "
        },
        {
            "from": 2809.9,
            "to": 2810.77,
            "location": 2,
            "content": " 因为作者觉得呢 "
        },
        {
            "from": 2810.77,
            "to": 2811.7,
            "location": 2,
            "content": " 这里这些模型啊 "
        },
        {
            "from": 2811.7,
            "to": 2812.87,
            "location": 2,
            "content": " 全都是利用了这个image net "
        },
        {
            "from": 2812.87,
            "to": 2814.17,
            "location": 2,
            "content": " 预训练模型 "
        },
        {
            "from": 2814.33,
            "to": 2815.9,
            "location": 2,
            "content": " 他没办法重头训练 "
        },
        {
            "from": 2816.17,
            "to": 2818.07,
            "location": 2,
            "content": " 但是呢对于接下来的这些模型啊 "
        },
        {
            "from": 2818.07,
            "to": 2819.93,
            "location": 2,
            "content": " 比如我们刚才讲过的 r （2+1）d 啊 "
        },
        {
            "from": 2819.93,
            "to": 2821.2,
            "location": 2,
            "content": " 还有新的这个slowfast "
        },
        {
            "from": 2821.2,
            "to": 2823.07,
            "location": 2,
            "content": " 他都是可以重头训练啊 "
        },
        {
            "from": 2823.07,
            "to": 2825.17,
            "location": 2,
            "content": " 不需要任何的这个预训练模型的 "
        },
        {
            "from": 2825.37,
            "to": 2825.73,
            "location": 2,
            "content": " 当然了 "
        },
        {
            "from": 2825.73,
            "to": 2827.93,
            "location": 2,
            "content": " 他训练的这epoch数量会非常多啊 "
        },
        {
            "from": 2827.93,
            "to": 2829.5,
            "location": 2,
            "content": " 需要196个epoch "
        },
        {
            "from": 2829.7,
            "to": 2831.47,
            "location": 2,
            "content": " 训练时长呢也非常长啊 "
        },
        {
            "from": 2831.47,
            "to": 2833.47,
            "location": 2,
            "content": " 8卡的机器呢也要训练十几天 "
        },
        {
            "from": 2833.9,
            "to": 2834.47,
            "location": 2,
            "content": " 所以说呢 "
        },
        {
            "from": 2834.47,
            "to": 2836.3,
            "location": 2,
            "content": " 不用这个image net 预训练参数啊 "
        },
        {
            "from": 2836.3,
            "to": 2837.57,
            "location": 2,
            "content": " 也不见得是个好事 "
        },
        {
            "from": 2837.7,
            "to": 2839.53,
            "location": 2,
            "content": " 那接下来呢我们看一下结果 "
        },
        {
            "from": 2839.57,
            "to": 2841.07,
            "location": 2,
            "content": " 那slowfast这篇文章呢 "
        },
        {
            "from": 2841.07,
            "to": 2842.47,
            "location": 2,
            "content": " 不光是卖这个精度 "
        },
        {
            "from": 2842.47,
            "to": 2844.73,
            "location": 2,
            "content": " 他更主要的呢是想说他们这个模型呢 "
        },
        {
            "from": 2844.73,
            "to": 2845.93,
            "location": 2,
            "content": " 非常的有高效 "
        },
        {
            "from": 2846.2,
            "to": 2847,
            "location": 2,
            "content": " 所以我们可以看到 "
        },
        {
            "from": 2847,
            "to": 2848.5,
            "location": 2,
            "content": " 他们这里呢还加了一列 "
        },
        {
            "from": 2848.5,
            "to": 2850.27,
            "location": 2,
            "content": " 那就是专门做 gflops "
        },
        {
            "from": 2850.6,
            "to": 2852.13,
            "location": 2,
            "content": " 那像他最小的这个slowfast "
        },
        {
            "from": 2852.13,
            "to": 2854.17,
            "location": 2,
            "content": " 4*16 res 50这个模型呢 "
        },
        {
            "from": 2854.17,
            "to": 2856.93,
            "location": 2,
            "content": " 他的这个 g flops 就只有36.1啊 "
        },
        {
            "from": 2856.93,
            "to": 2859.17,
            "location": 2,
            "content": " 如果我们跟上面这些3 d 模型去比的话 "
        },
        {
            "from": 2859.17,
            "to": 2860.8,
            "location": 2,
            "content": " 发现它是非常小的 "
        },
        {
            "from": 2861.3,
            "to": 2862.4,
            "location": 2,
            "content": " 而且呢slowfast "
        },
        {
            "from": 2862.4,
            "to": 2864.97,
            "location": 2,
            "content": " 随着使用的这个帧数越来越多 "
        },
        {
            "from": 2865,
            "to": 2866.73,
            "location": 2,
            "content": " 而且用的这个模型越来越大 "
        },
        {
            "from": 2866.73,
            "to": 2869.2,
            "location": 2,
            "content": " 或者说也用了这个non local block 之后呢 "
        },
        {
            "from": 2869.27,
            "to": 2871,
            "location": 2,
            "content": " 他这个性能啊一直会增长 "
        },
        {
            "from": 2871,
            "to": 2872.9,
            "location": 2,
            "content": " 一直到最后的这个79.8 "
        },
        {
            "from": 2873.07,
            "to": 2874.97,
            "location": 2,
            "content": " 这个呢也是比之前的这些方法呢 "
        },
        {
            "from": 2874.97,
            "to": 2876.2,
            "location": 2,
            "content": " 通通都要高的 "
        },
        {
            "from": 2876.37,
            "to": 2877.07,
            "location": 2,
            "content": " 而且这个呢 "
        },
        {
            "from": 2877.07,
            "to": 2878.7,
            "location": 2,
            "content": " 基本也算是3 d 网络 "
        },
        {
            "from": 2878.7,
            "to": 2880.2,
            "location": 2,
            "content": " 在 k 400这个数据集上 "
        },
        {
            "from": 2880.2,
            "to": 2881.4,
            "location": 2,
            "content": " 最好的表现了 "
        },
        {
            "from": 2881.67,
            "to": 2884.4,
            "location": 2,
            "content": " 那3 d 网络这部分呢我们就算过完了 "
        },
        {
            "from": 2884.5,
            "to": 2884.97,
            "location": 2,
            "content": " 当然了 "
        },
        {
            "from": 2884.97,
            "to": 2887.33,
            "location": 2,
            "content": " 还有很多很多优秀的3 d 网络的工作 "
        },
        {
            "from": 2887.33,
            "to": 2888.9,
            "location": 2,
            "content": " 我没有时间去设计 "
        },
        {
            "from": 2889.2,
            "to": 2891,
            "location": 2,
            "content": " 而且呢还有一些有趣的工作 "
        },
        {
            "from": 2891,
            "to": 2893.53,
            "location": 2,
            "content": " 他既不用光流他也不用3 d 网络 "
        },
        {
            "from": 2893.73,
            "to": 2894.8,
            "location": 2,
            "content": " 也能比较好的 "
        },
        {
            "from": 2894.8,
            "to": 2896.77,
            "location": 2,
            "content": " 高效的把这个视频理解做了 "
        },
        {
            "from": 2897.2,
            "to": 2898.7,
            "location": 2,
            "content": " 比如我之前就有一篇论文 "
        },
        {
            "from": 2898.7,
            "to": 2900.2,
            "location": 2,
            "content": " 叫hidden two-stream network "
        },
        {
            "from": 2900.27,
            "to": 2901.77,
            "location": 2,
            "content": " 就是把这个光流的学习啊 "
        },
        {
            "from": 2901.77,
            "to": 2903.3,
            "location": 2,
            "content": " 融入到网络之中了 "
        },
        {
            "from": 2903.5,
            "to": 2904.8,
            "location": 2,
            "content": " 这样不论是在训练的时候 "
        },
        {
            "from": 2904.8,
            "to": 2905.97,
            "location": 2,
            "content": " 还是在推理的时候呢 "
        },
        {
            "from": 2905.97,
            "to": 2908,
            "location": 2,
            "content": " 我们都不需要去抽取这个光流 "
        },
        {
            "from": 2908.2,
            "to": 2910.6,
            "location": 2,
            "content": " 抽光流这个步骤呢就在网络之中了 "
        },
        {
            "from": 2910.7,
            "to": 2912.07,
            "location": 2,
            "content": " 所以是比较高效的 "
        },
        {
            "from": 2912.3,
            "to": 2913.4,
            "location": 2,
            "content": " 然后还有另外一篇论文 "
        },
        {
            "from": 2913.4,
            "to": 2917.07,
            "location": 2,
            "content": " tsm temporal shift module iccv 19的一篇论文 "
        },
        {
            "from": 2917.2,
            "to": 2919,
            "location": 2,
            "content": " 他呢是把 shift 这个操作啊 "
        },
        {
            "from": 2919,
            "to": 2920.53,
            "location": 2,
            "content": " 用到了这个视频理解里 "
        },
        {
            "from": 2920.67,
            "to": 2921.93,
            "location": 2,
            "content": " 能让一个2 d 网络 "
        },
        {
            "from": 2921.93,
            "to": 2923.8,
            "location": 2,
            "content": " 就能媲美一个大的3 d 网络 "
        },
        {
            "from": 2924.07,
            "to": 2926.57,
            "location": 2,
            "content": " 而且在很多任务上效果都非常的好 "
        },
        {
            "from": 2926.77,
            "to": 2928.13,
            "location": 2,
            "content": " 而且因为是2 d 网络 "
        },
        {
            "from": 2928.13,
            "to": 2929.6,
            "location": 2,
            "content": " 所以比较方便去部署 "
        },
        {
            "from": 2930.07,
            "to": 2931.17,
            "location": 2,
            "content": " 作者在官方代码呢 "
        },
        {
            "from": 2931.17,
            "to": 2932.97,
            "location": 2,
            "content": " 还提供了一些首饰检测的 demo "
        },
        {
            "from": 2933.5,
            "to": 2934.6,
            "location": 2,
            "content": " 非常有意思啊 "
        },
        {
            "from": 2934.6,
            "to": 2936.5,
            "location": 2,
            "content": " 感兴趣的同学也可以去试一下 "
        },
        {
            "from": 2937.1,
            "to": 2940.17,
            "location": 2,
            "content": " 总之呢 3 d 网络从17年 i 3 d 火了之后呢 "
        },
        {
            "from": 2940.17,
            "to": 2942.1,
            "location": 2,
            "content": " 就一直霸占这个视频理解领域 "
        },
        {
            "from": 2942.1,
            "to": 2943.53,
            "location": 2,
            "content": " 一直到2020年 "
        },
        {
            "from": 2944.07,
            "to": 2945.73,
            "location": 2,
            "content": " 然后自从有了vision transformer啊 "
        },
        {
            "from": 2945.73,
            "to": 2946.7,
            "location": 2,
            "content": " 大家这个注意力呢 "
        },
        {
            "from": 2946.7,
            "to": 2948.37,
            "location": 2,
            "content": " 又全都转移到这上面了 "
        },
        {
            "from": 2948.5,
            "to": 2948.9,
            "location": 2,
            "content": " 所以说 "
        },
        {
            "from": 2948.9,
            "to": 2950.73,
            "location": 2,
            "content": " 就到了我们今天要讲的第四个部分 "
        },
        {
            "from": 2950.73,
            "to": 2952.1,
            "location": 2,
            "content": " 啊就是 video transformer "
        },
        {
            "from": 2952.37,
            "to": 2954.07,
            "location": 2,
            "content": " 咱们把在图像上用的比较好的 "
        },
        {
            "from": 2954.07,
            "to": 2955.3,
            "location": 2,
            "content": " 这个vision transformer啊 "
        },
        {
            "from": 2955.3,
            "to": 2956.93,
            "location": 2,
            "content": " 能移植到视频领域里来 "
        },
        {
            "from": 2956.93,
            "to": 2958.97,
            "location": 2,
            "content": " 做一个视频的vision transformer "
        },
        {
            "from": 2960,
            "to": 2961.37,
            "location": 2,
            "content": " 那video transformer这篇呢 "
        },
        {
            "from": 2961.37,
            "to": 2963.77,
            "location": 2,
            "content": " 我们就准备讲一篇啊这个 times former 啊 "
        },
        {
            "from": 2963.77,
            "to": 2965.7,
            "location": 2,
            "content": " 也是最早的一篇把vision transformer "
        },
        {
            "from": 2965.7,
            "to": 2967.57,
            "location": 2,
            "content": " 用到视频理解领域的一篇论文 "
        },
        {
            "from": 2967.8,
            "to": 2970.33,
            "location": 2,
            "content": " 他这个题目呢也是让人一看就懂啊 "
        },
        {
            "from": 2970.33,
            "to": 2971.47,
            "location": 2,
            "content": " 时空注意力啊 "
        },
        {
            "from": 2971.47,
            "to": 2973.07,
            "location": 2,
            "content": " 是不是 all you need 啊 "
        },
        {
            "from": 2973.07,
            "to": 2973.5,
            "location": 2,
            "content": " 这个呢 "
        },
        {
            "from": 2973.5,
            "to": 2976.3,
            "location": 2,
            "content": " 就跟2017年transformer的原文是一样的 "
        },
        {
            "from": 2976.3,
            "to": 2976.93,
            "location": 2,
            "content": " 自注意力啊 "
        },
        {
            "from": 2976.93,
            "to": 2977.97,
            "location": 2,
            "content": " 是不是 all you need "
        },
        {
            "from": 2978.57,
            "to": 2979.37,
            "location": 2,
            "content": " 那这篇论文呢 "
        },
        {
            "from": 2979.37,
            "to": 2981.87,
            "location": 2,
            "content": " 我们之前在讲 r （2+1） d 的时候也说过 "
        },
        {
            "from": 2982,
            "to": 2984.57,
            "location": 2,
            "content": " 是跟 r （2+1） d 的作者团队呢差不多的 "
        },
        {
            "from": 2984.73,
            "to": 2985.6,
            "location": 2,
            "content": " 那这篇论文呢 "
        },
        {
            "from": 2985.6,
            "to": 2987.73,
            "location": 2,
            "content": " 也是一间比较实验性的论文 "
        },
        {
            "from": 2987.97,
            "to": 2989.07,
            "location": 2,
            "content": " 就是探索了一下 "
        },
        {
            "from": 2989.07,
            "to": 2990.97,
            "location": 2,
            "content": " 怎么把这个vision transformer啊 "
        },
        {
            "from": 2990.97,
            "to": 2993.93,
            "location": 2,
            "content": " 从这个图像领域迁移到视频领域里来 "
        },
        {
            "from": 2994.53,
            "to": 2995.5,
            "location": 2,
            "content": " 那具体来说呢 "
        },
        {
            "from": 2995.5,
            "to": 2997.37,
            "location": 2,
            "content": " 作者就尝试了这五种结构 "
        },
        {
            "from": 2997.57,
            "to": 2998.7,
            "location": 2,
            "content": " 那第一种结构呢 "
        },
        {
            "from": 2998.7,
            "to": 2999.67,
            "location": 2,
            "content": " space attention啊 "
        },
        {
            "from": 2999.67,
            "to": 3001.6,
            "location": 2,
            "content": " 就是只在这个空间特征图上 "
        },
        {
            "from": 3001.6,
            "to": 3002.87,
            "location": 2,
            "content": " 去做这种自注意力 "
        },
        {
            "from": 3002.97,
            "to": 3003.5,
            "location": 2,
            "content": " 那这个呢 "
        },
        {
            "from": 3003.5,
            "to": 3004.7,
            "location": 2,
            "content": " 其实就是图像里啊 "
        },
        {
            "from": 3004.7,
            "to": 3006.87,
            "location": 2,
            "content": " 这个vision transformer 用的这个自注意力 "
        },
        {
            "from": 3007.2,
            "to": 3009.33,
            "location": 2,
            "content": " 意思就是说你一个这个特征进来 "
        },
        {
            "from": 3009.57,
            "to": 3011.37,
            "location": 2,
            "content": " 做一次这个空间自注意力 "
        },
        {
            "from": 3011.6,
            "to": 3013.07,
            "location": 2,
            "content": " 然后再接一个 mlp 啊 "
        },
        {
            "from": 3013.07,
            "to": 3015.53,
            "location": 2,
            "content": " 然后通过残差连接最后得到这个输出 "
        },
        {
            "from": 3015.93,
            "to": 3018.53,
            "location": 2,
            "content": " 那这个就属于是图像上的baseline了 "
        },
        {
            "from": 3018.53,
            "to": 3019.2,
            "location": 2,
            "content": " 那接下来呢 "
        },
        {
            "from": 3019.2,
            "to": 3021.17,
            "location": 2,
            "content": " 就是说怎么用到这个视频上 "
        },
        {
            "from": 3021.5,
            "to": 3023,
            "location": 2,
            "content": " 那首先视频上第一个呢 "
        },
        {
            "from": 3023,
            "to": 3024.8,
            "location": 2,
            "content": " 就是我暴力地去 使用对吧 "
        },
        {
            "from": 3024.8,
            "to": 3026.33,
            "location": 2,
            "content": " 那我就是给一个视频 "
        },
        {
            "from": 3026.33,
            "to": 3027.4,
            "location": 2,
            "content": " 那我就在这个视频 "
        },
        {
            "from": 3027.4,
            "to": 3029.77,
            "location": 2,
            "content": " 三个维度上通通去做这个自注意力啊 "
        },
        {
            "from": 3029.77,
            "to": 3030.77,
            "location": 2,
            "content": " 我一起做啊 "
        },
        {
            "from": 3030.77,
            "to": 3032.8,
            "location": 2,
            "content": "也就是他这里说的这个joint space-time "
        },
        {
            "from": 3032.8,
            "to": 3033.67,
            "location": 2,
            "content": "  attention  "
        },
        {
            "from": 3033.93,
            "to": 3034.47,
            "location": 2,
            "content": " 那这样呢 "
        },
        {
            "from": 3034.47,
            "to": 3036.6,
            "location": 2,
            "content": " 一个输入进来过这个时空自注意力 "
        },
        {
            "from": 3036.6,
            "to": 3037.73,
            "location": 2,
            "content": " 然后再过一个 mlp "
        },
        {
            "from": 3037.73,
            "to": 3038.77,
            "location": 2,
            "content": " 然后通过残差连接 "
        },
        {
            "from": 3038.77,
            "to": 3040.27,
            "location": 2,
            "content": " 就得到最后的输出了 "
        },
        {
            "from": 3040.3,
            "to": 3041.27,
            "location": 2,
            "content": " 但是这种方式呢 "
        },
        {
            "from": 3041.27,
            "to": 3043.1,
            "location": 2,
            "content": " 其实我们肯定就能想到这个 "
        },
        {
            "from": 3043.1,
            "to": 3044.33,
            "location": 2,
            "content": " gpu 内存肯定塞不下 "
        },
        {
            "from": 3044.33,
            "to": 3044.87,
            "location": 2,
            "content": " 呀 "
        },
        {
            "from": 3044.87,
            "to": 3047.13,
            "location": 2,
            "content": " 那图像那边vision transformer都快塞不下了 "
        },
        {
            "from": 3047.13,
            "to": 3049.07,
            "location": 2,
            "content": " 那更别提你现在把这个视频啊 "
        },
        {
            "from": 3049.07,
            "to": 3051.7,
            "location": 2,
            "content": " 30帧、60帧扔给一个vision transformer "
        },
        {
            "from": 3051.9,
            "to": 3053.77,
            "location": 2,
            "content": " 你在三个维度上去算这个自注意力 "
        },
        {
            "from": 3053.77,
            "to": 3055.27,
            "location": 2,
            "content": " 他肯定是塞不下的 "
        },
        {
            "from": 3055.33,
            "to": 3057.5,
            "location": 2,
            "content": " 所以你一旦这个 gpu 内存塞不下 "
        },
        {
            "from": 3057.6,
            "to": 3058.87,
            "location": 2,
            "content": " 那该怎么办呢 "
        },
        {
            "from": 3058.93,
            "to": 3060.87,
            "location": 2,
            "content": " 那其实就像R(2+1)D 做的一样"
        },
        {
            "from": 3060.87,
            "to": 3063.37,
            "location": 2,
            "content": " 你3D塞不下我就把你拆分了吗"
        },
        {
            "from": 3063.37,
            "to": 3066.07,
            "location": 2,
            "content": " 我就把你拆成2D 和1D就行了 "
        },
        {
            "from": 3066.2,
            "to": 3068.37,
            "location": 2,
            "content": " 那这里呢其实还是同样的套路 "
        },
        {
            "from": 3068.67,
            "to": 3069.93,
            "location": 2,
            "content": " 那你既然一个3D的 "
        },
        {
            "from": 3069.93,
            "to": 3071.8,
            "location": 2,
            "content": " 这个时空的自注意力你做不动 "
        },
        {
            "from": 3071.93,
            "to": 3073.8,
            "location": 2,
            "content": " 那我就在时间上先做自注意力 "
        },
        {
            "from": 3073.8,
            "to": 3075.47,
            "location": 2,
            "content": " 然后再在空间上再做自注意力 "
        },
        {
            "from": 3075.47,
            "to": 3076.4,
            "location": 2,
            "content": " 不就行了吗 "
        },
        {
            "from": 3076.87,
            "to": 3079.57,
            "location": 2,
            "content": " 所以说啊就按照这个 R(2+1)D的方式啊"
        },
        {
            "from": 3079.57,
            "to": 3081.67,
            "location": 2,
            "content": " 作者就提出了他们这篇论文里的这个 "
        },
        {
            "from": 3081.67,
            "to": 3083.4,
            "location": 2,
            "content": " divided space-time attention "
        },
        {
            "from": 3083.7,
            "to": 3085.87,
            "location": 2,
            "content": " 就是把这个 时空啊分开来做啊 "
        },
        {
            "from": 3085.87,
            "to": 3087.8,
            "location": 2,
            "content": " 这里呢他没有用 factorize 个词 "
        },
        {
            "from": 3087.8,
            "to": 3089.47,
            "location": 2,
            "content": " 他换了个词换成 divided "
        },
        {
            "from": 3089.5,
            "to": 3091,
            "location": 2,
            "content": " 但其实呢都是一个意思 "
        },
        {
            "from": 3091.4,
            "to": 3093.4,
            "location": 2,
            "content": " 具体做法呢就是你一个特征进来 "
        },
        {
            "from": 3093.4,
            "to": 3094.93,
            "location": 2,
            "content": " 那我先在这个时间维度上 "
        },
        {
            "from": 3094.93,
            "to": 3096.33,
            "location": 2,
            "content": " 给你做一下自注意力 "
        },
        {
            "from": 3096.47,
            "to": 3097.6,
            "location": 2,
            "content": " 然后残差连接 "
        },
        {
            "from": 3097.87,
            "to": 3099.13,
            "location": 2,
            "content": " 然后我再在空间上呢 "
        },
        {
            "from": 3099.13,
            "to": 3100.33,
            "location": 2,
            "content": " 做一下这个自注意力 "
        },
        {
            "from": 3100.33,
            "to": 3102.93,
            "location": 2,
            "content": " 然后最后过一个 mlp 啊最后得到输出 "
        },
        {
            "from": 3103.07,
            "to": 3105.47,
            "location": 2,
            "content": " 这样这个计算复杂度呢就大大降低了 "
        },
        {
            "from": 3105.47,
            "to": 3106.7,
            "location": 2,
            "content": " 因为你每一个这个序列 "
        },
        {
            "from": 3106.7,
            "to": 3108,
            "location": 2,
            "content": " 长度都变得很小 "
        },
        {
            "from": 3108.67,
            "to": 3109.73,
            "location": 2,
            "content": " 当然了除了这种 "
        },
        {
            "from": 3109.73,
            "to": 3111.73,
            "location": 2,
            "content": " 时间和空间上的这种拆分之外呢 "
        },
        {
            "from": 3111.73,
            "to": 3113.9,
            "location": 2,
            "content": " 你还可以有很多别的拆分方式 "
        },
        {
            "from": 3114.3,
            "to": 3115.93,
            "location": 2,
            "content": " 那比如之前大家常用的呢 "
        },
        {
            "from": 3115.93,
            "to": 3118,
            "location": 2,
            "content": " 就是这种 local global 的形式 "
        },
        {
            "from": 3118.3,
            "to": 3120.47,
            "location": 2,
            "content": " 就是既然你全局的这个序列长度太长 "
        },
        {
            "from": 3120.47,
            "to": 3121.4,
            "location": 2,
            "content": " 你没法算啊 "
        },
        {
            "from": 3121.4,
            "to": 3122.77,
            "location": 2,
            "content": " 那我就先在局部算 "
        },
        {
            "from": 3122.77,
            "to": 3123.97,
            "location": 2,
            "content": " 那算好以后呢 "
        },
        {
            "from": 3123.97,
            "to": 3125.9,
            "location": 2,
            "content": " 我再在这个全局上去算啊 "
        },
        {
            "from": 3125.9,
            "to": 3127.33,
            "location": 2,
            "content": " 这个呢其实就有点这个swin "
        },
        {
            "from": 3127.33,
            "to": 3128.6,
            "location": 2,
            "content": " transformer的意思啊 "
        },
        {
            "from": 3128.73,
            "to": 3130.67,
            "location": 2,
            "content": " 我在一个局部的一个小窗口里 "
        },
        {
            "from": 3130.67,
            "to": 3131.9,
            "location": 2,
            "content": " 去算这个自注意力 "
        },
        {
            "from": 3132.07,
            "to": 3134.33,
            "location": 2,
            "content": " 他这个计算复杂度呢也会变得很低 "
        },
        {
            "from": 3134.73,
            "to": 3136.9,
            "location": 2,
            "content": " 所以说这里就是说我先一个特征进来 "
        },
        {
            "from": 3136.9,
            "to": 3138.3,
            "location": 2,
            "content": " 我先局部算特征 "
        },
        {
            "from": 3138.53,
            "to": 3140.27,
            "location": 2,
            "content": " 然后我再去全局算特征 "
        },
        {
            "from": 3140.3,
            "to": 3141.97,
            "location": 2,
            "content": " 那这个复杂度也就会降低 "
        },
        {
            "from": 3142.53,
            "to": 3144.77,
            "location": 2,
            "content": " 最后一种呢也就是这个 axial attention "
        },
        {
            "from": 3144.93,
            "to": 3147.07,
            "location": 2,
            "content": " 就是说我只沿着你特定的这个轴 "
        },
        {
            "from": 3147.07,
            "to": 3147.93,
            "location": 2,
            "content": " 去做attention "
        },
        {
            "from": 3148.13,
            "to": 3148.4,
            "location": 2,
            "content": " 这个 "
        },
        {
            "from": 3148.4,
            "to": 3150.17,
            "location": 2,
            "content": " 之前我们在讲vision transformer的时候呢 "
        },
        {
            "from": 3150.17,
            "to": 3151.1,
            "location": 2,
            "content": " 也提到过 "
        },
        {
            "from": 3151.33,
            "to": 3152.9,
            "location": 2,
            "content": " 就是说呢我一个特征进来 "
        },
        {
            "from": 3152.9,
            "to": 3155.6,
            "location": 2,
            "content": " 我先沿着这个时间轴去做自注意力 "
        },
        {
            "from": 3155.9,
            "to": 3157.53,
            "location": 2,
            "content": " 然后我再沿着这个横轴 "
        },
        {
            "from": 3157.77,
            "to": 3160.1,
            "location": 2,
            "content": " 啊就是这个图像的宽去做自注意力 "
        },
        {
            "from": 3160.4,
            "to": 3162.17,
            "location": 2,
            "content": " 然后再沿着这个图像的高度啊 "
        },
        {
            "from": 3162.17,
            "to": 3163.9,
            "location": 2,
            "content": " 这个竖轴去做自注意力 "
        },
        {
            "from": 3163.97,
            "to": 3165.9,
            "location": 2,
            "content": " 那意思就是说把一个三维的问题呢 "
        },
        {
            "from": 3165.9,
            "to": 3167.67,
            "location": 2,
            "content": " 拆成了三个一维的问题 "
        },
        {
            "from": 3167.67,
            "to": 3168.6,
            "location": 2,
            "content": " 那这个复杂度呢 "
        },
        {
            "from": 3168.6,
            "to": 3170.33,
            "location": 2,
            "content": " 一下也会降的很低很低 "
        },
        {
            "from": 3170.77,
            "to": 3172.4,
            "location": 2,
            "content": " 但总之呢你一看这个图 "
        },
        {
            "from": 3172.4,
            "to": 3173.73,
            "location": 2,
            "content": " 你就会立马联想起来 "
        },
        {
            "from": 3173.73,
            "to": 3175.73,
            "location": 2,
            "content": " 跟 r 2+1 d 这篇论文的联想 "
        },
        {
            "from": 3175.97,
            "to": 3177.87,
            "location": 2,
            "content": " r 2+1 d 呢也画了5个图 "
        },
        {
            "from": 3178.13,
            "to": 3180.8,
            "location": 2,
            "content": " 分别讲了讲这个2 d 和3 d 该怎么融合啊 "
        },
        {
            "from": 3180.8,
            "to": 3182.5,
            "location": 2,
            "content": " 到底哪种结构好啊 "
        },
        {
            "from": 3182.5,
            "to": 3183.8,
            "location": 2,
            "content": " 那这篇timesformer 呢 "
        },
        {
            "from": 3183.8,
            "to": 3185.5,
            "location": 2,
            "content": " 他们也是画了5个图啊 "
        },
        {
            "from": 3185.5,
            "to": 3186.87,
            "location": 2,
            "content": " 讲了讲这个vision transformer "
        },
        {
            "from": 3186.87,
            "to": 3188.37,
            "location": 2,
            "content": " 怎么能用到视频里来 "
        },
        {
            "from": 3188.5,
            "to": 3190.33,
            "location": 2,
            "content": " 套路呢是非常相似的 "
        },
        {
            "from": 3191,
            "to": 3192.97,
            "location": 2,
            "content": " 然后呢反正是实验性论文 "
        },
        {
            "from": 3193.17,
            "to": 3195.27,
            "location": 2,
            "content": " 可以写的这个方法部分呢并不多 "
        },
        {
            "from": 3195.47,
            "to": 3197.7,
            "location": 2,
            "content": " 这作者呢为了让这个读者更好理解 "
        },
        {
            "from": 3197.7,
            "to": 3199.13,
            "location": 2,
            "content": " 所以把刚才的五个图呢 "
        },
        {
            "from": 3199.13,
            "to": 3201.57,
            "location": 2,
            "content": " 又用可视化的方式展现了出来啊 "
        },
        {
            "from": 3201.57,
            "to": 3202.53,
            "location": 2,
            "content": " 形象的告诉你 "
        },
        {
            "from": 3202.53,
            "to": 3204.13,
            "location": 2,
            "content": " 这五种自注意力的方式 "
        },
        {
            "from": 3204.13,
            "to": 3205.47,
            "location": 2,
            "content": " 到底是怎么做的 "
        },
        {
            "from": 3205.5,
            "to": 3207.2,
            "location": 2,
            "content": " 这个图啊确实画的也很好 "
        },
        {
            "from": 3207.7,
            "to": 3208.4,
            "location": 2,
            "content": " 首先我们来看啊 "
        },
        {
            "from": 3208.4,
            "to": 3210.37,
            "location": 2,
            "content": " 就是单纯用这种图像上的这种 "
        },
        {
            "from": 3210.37,
            "to": 3211.47,
            "location": 2,
            "content": " 空间自注意力 "
        },
        {
            "from": 3211.57,
            "to": 3213.47,
            "location": 2,
            "content": " 那意思就是说啊如果我们有啊 "
        },
        {
            "from": 3213.47,
            "to": 3215.47,
            "location": 2,
            "content": " 前一帧那 frame t 减1啊 "
        },
        {
            "from": 3215.47,
            "to": 3216.73,
            "location": 2,
            "content": " 中间这一帧 frame t "
        },
        {
            "from": 3216.73,
            "to": 3218.8,
            "location": 2,
            "content": " 和下一帧 frame t 加1的话呢 "
        },
        {
            "from": 3219.1,
            "to": 3221.87,
            "location": 2,
            "content": " 如果我们拿这个蓝色的 patch 当基准点 "
        },
        {
            "from": 3222,
            "to": 3224.77,
            "location": 2,
            "content": " 那其实他会跟谁去算这个自注意力呢 "
        },
        {
            "from": 3224.87,
            "to": 3226.77,
            "location": 2,
            "content": " 他只会跟他当前的这一帧 "
        },
        {
            "from": 3226.77,
            "to": 3227.9,
            "location": 2,
            "content": " 去算自注意力 "
        },
        {
            "from": 3228.3,
            "to": 3230.17,
            "location": 2,
            "content": " 因为他就是一个图像的自注意力 "
        },
        {
            "from": 3230.27,
            "to": 3231.9,
            "location": 2,
            "content": " 他不牵扯这个时间轴上的 "
        },
        {
            "from": 3231.9,
            "to": 3234.17,
            "location": 2,
            "content": " 所以说呢他看不到前后这两帧 "
        },
        {
            "from": 3234.17,
            "to": 3236.87,
            "location": 2,
            "content": " 他只是跟本帧上所有的别的 patch "
        },
        {
            "from": 3236.87,
            "to": 3238.5,
            "location": 2,
            "content": " 去做这个自注意力操作 "
        },
        {
            "from": 3238.87,
            "to": 3240.3,
            "location": 2,
            "content": " 那接下来的这四种方法呢 "
        },
        {
            "from": 3240.3,
            "to": 3242.37,
            "location": 2,
            "content": " 这全是跟视频有一些关系了 "
        },
        {
            "from": 3242.37,
            "to": 3244.3,
            "location": 2,
            "content": " 那比如说接下来的这个啊 "
        },
        {
            "from": 3244.3,
            "to": 3246.67,
            "location": 2,
            "content": " 在时空上一起做自注意力的方式 "
        },
        {
            "from": 3246.9,
            "to": 3248.13,
            "location": 2,
            "content": " 那这个当然是最好了 "
        },
        {
            "from": 3248.13,
            "to": 3248.93,
            "location": 2,
            "content": " 因为我们可以看到 "
        },
        {
            "from": 3248.93,
            "to": 3251.13,
            "location": 2,
            "content": " 如果拿这个蓝色的patch当基准点 "
        },
        {
            "from": 3251.27,
            "to": 3252.07,
            "location": 2,
            "content": " 前一帧 "
        },
        {
            "from": 3252.07,
            "to": 3254.73,
            "location": 2,
            "content": " 这一帧和后面一帧所有的这个patch呢 "
        },
        {
            "from": 3254.73,
            "to": 3256.53,
            "location": 2,
            "content": " 他都要去做自注意力 "
        },
        {
            "from": 3256.7,
            "to": 3258.33,
            "location": 2,
            "content": " 效果肯定应该是最好的 "
        },
        {
            "from": 3258.33,
            "to": 3260.77,
            "location": 2,
            "content": " 但是这个复杂度呢也是你承受不起的 "
        },
        {
            "from": 3260.8,
            "to": 3262.3,
            "location": 2,
            "content": " 那我们就来看看后面三种 "
        },
        {
            "from": 3262.3,
            "to": 3264.07,
            "location": 2,
            "content": " 这个简化方式是怎么做 "
        },
        {
            "from": 3264.73,
            "to": 3265.5,
            "location": 2,
            "content": " 那第三种呢 "
        },
        {
            "from": 3265.5,
            "to": 3266.77,
            "location": 2,
            "content": " 也就是他们这篇论文中 "
        },
        {
            "from": 3266.77,
            "to": 3268.13,
            "location": 2,
            "content": " 主要提出的方法啊 "
        },
        {
            "from": 3268.13,
            "to": 3269.4,
            "location": 2,
            "content": " 这个 divided 啊 "
        },
        {
            "from": 3269.4,
            "to": 3270.7,
            "location": 2,
            "content": " space time 自注意力 "
        },
        {
            "from": 3270.97,
            "to": 3271.53,
            "location": 2,
            "content": " 那同样呢 "
        },
        {
            "from": 3271.53,
            "to": 3273.87,
            "location": 2,
            "content": " 我们还是以这个蓝色的 patch 作为基准 "
        },
        {
            "from": 3274.17,
            "to": 3276.13,
            "location": 2,
            "content": " 那先做这个时间上的自注意力呢 "
        },
        {
            "from": 3276.13,
            "to": 3279,
            "location": 2,
            "content": " 也就是说他先做这个patch对应的 "
        },
        {
            "from": 3279,
            "to": 3280.7,
            "location": 2,
            "content": " 前一帧的这个patch上啊 "
        },
        {
            "from": 3280.7,
            "to": 3282.57,
            "location": 2,
            "content": " 他去跟这个patch去做自注意力 "
        },
        {
            "from": 3282.67,
            "to": 3283.47,
            "location": 2,
            "content": " 然后同样呢 "
        },
        {
            "from": 3283.47,
            "to": 3285.3,
            "location": 2,
            "content": " 在下一帧同样的位置上啊 "
        },
        {
            "from": 3285.3,
            "to": 3286.93,
            "location": 2,
            "content": " 这个patch上去做自注意力 "
        },
        {
            "from": 3286.97,
            "to": 3289.73,
            "location": 2,
            "content": " 也就是这个这个这个他们在 "
        },
        {
            "from": 3289.73,
            "to": 3291.17,
            "location": 2,
            "content": " 做这个自注意力操作 "
        },
        {
            "from": 3291.57,
            "to": 3293.9,
            "location": 2,
            "content": " 他跟前一帧剩下所有的这些 patch "
        },
        {
            "from": 3294.27,
            "to": 3295.73,
            "location": 2,
            "content": " 和下一帧所有这些 patch 呢 "
        },
        {
            "from": 3295.73,
            "to": 3297.67,
            "location": 2,
            "content": " 都是不做主自注意力的啊 "
        },
        {
            "from": 3297.67,
            "to": 3298.47,
            "location": 2,
            "content": " 没有关系 "
        },
        {
            "from": 3298.5,
            "to": 3299.47,
            "location": 2,
            "content": " 那做完了这一步 "
        },
        {
            "from": 3299.47,
            "to": 3300.73,
            "location": 2,
            "content": " 这个时间上的自注意力 "
        },
        {
            "from": 3300.73,
            "to": 3302.73,
            "location": 2,
            "content": " 接下就该做空间自注意力了 "
        },
        {
            "from": 3302.73,
            "to": 3304.33,
            "location": 2,
            "content": " 那这个空间自注意力呢 "
        },
        {
            "from": 3304.33,
            "to": 3305.2,
            "location": 2,
            "content": " 就跟第一个 "
        },
        {
            "from": 3305.2,
            "to": 3307.87,
            "location": 2,
            "content": " 这个2 d 的空间自注意力是一样的啊 "
        },
        {
            "from": 3307.87,
            "to": 3310.13,
            "location": 2,
            "content": " 他跟这个图像里的所有的别的 patch "
        },
        {
            "from": 3310.13,
            "to": 3311.77,
            "location": 2,
            "content": " 都会去算一下自注意力 "
        },
        {
            "from": 3312.33,
            "to": 3313.9,
            "location": 2,
            "content": " 那接下来第四种方式呢 "
        },
        {
            "from": 3313.9,
            "to": 3316,
            "location": 2,
            "content": " 这种先局部再全局的方式 "
        },
        {
            "from": 3316.3,
            "to": 3317,
            "location": 2,
            "content": " 就说首先 "
        },
        {
            "from": 3317,
            "to": 3318.17,
            "location": 2,
            "content": " 我先去算这个局部 "
        },
        {
            "from": 3318.17,
            "to": 3319.6,
            "location": 2,
            "content": " 小窗口里的自注意力 "
        },
        {
            "from": 3319.6,
            "to": 3321.3,
            "location": 2,
            "content": " 那如果我们拿这个蓝色 patch "
        },
        {
            "from": 3321.3,
            "to": 3322.33,
            "location": 2,
            "content": " 当这个基准点 "
        },
        {
            "from": 3322.4,
            "to": 3323.67,
            "location": 2,
            "content": " 那对于当前帧来说呢 "
        },
        {
            "from": 3323.67,
            "to": 3325.4,
            "location": 2,
            "content": " 我们就算这个小窗口里 "
        },
        {
            "from": 3325.47,
            "to": 3327.3,
            "location": 2,
            "content": " 那前一帧呢也是这个小窗口 "
        },
        {
            "from": 3327.3,
            "to": 3329.1,
            "location": 2,
            "content": " 后一帧呢也是这个小窗口 "
        },
        {
            "from": 3329.27,
            "to": 3331.33,
            "location": 2,
            "content": " 那当算完了所有这个小窗口之后呢 "
        },
        {
            "from": 3331.33,
            "to": 3333.3,
            "location": 2,
            "content": " 接下来就该算这个全局的了 "
        },
        {
            "from": 3333.4,
            "to": 3335.2,
            "location": 2,
            "content": " 全局呢为了减少这个计算量 "
        },
        {
            "from": 3335.2,
            "to": 3337.2,
            "location": 2,
            "content": " 他就得变得非常的稀疏啊 "
        },
        {
            "from": 3337.2,
            "to": 3338.73,
            "location": 2,
            "content": " 所以也就是这些点 "
        },
        {
            "from": 3341.3,
            "to": 3343.2,
            "location": 2,
            "content": " 是要去做这个自注意力操作的 "
        },
        {
            "from": 3343.4,
            "to": 3345.87,
            "location": 2,
            "content": " 那最后呢就到了这个轴自注意力 "
        },
        {
            "from": 3345.87,
            "to": 3346.7,
            "location": 2,
            "content": " 那也就是说 "
        },
        {
            "from": 3346.73,
            "to": 3349.47,
            "location": 2,
            "content": " 把一个三维问题变成了三个一维问题 "
        },
        {
            "from": 3349.5,
            "to": 3351.13,
            "location": 2,
            "content": " 啊这里呢也非常形象啊 "
        },
        {
            "from": 3351.13,
            "to": 3353.27,
            "location": 2,
            "content": " 就说如果这个是基准 patch的话呢 "
        },
        {
            "from": 3353.57,
            "to": 3354.3,
            "location": 2,
            "content": " 他的时间上 "
        },
        {
            "from": 3354.3,
            "to": 3356.77,
            "location": 2,
            "content": " 是跟前后这两层绿色去做自注意力 "
        },
        {
            "from": 3356.9,
            "to": 3357.97,
            "location": 2,
            "content": " 那他在横轴上呢 "
        },
        {
            "from": 3357.97,
            "to": 3359.9,
            "location": 2,
            "content": " 是跟这个黄色的去做自注意力 "
        },
        {
            "from": 3360.1,
            "to": 3360.87,
            "location": 2,
            "content": " 在竖轴上呢 "
        },
        {
            "from": 3360.87,
            "to": 3362.7,
            "location": 2,
            "content": " 是跟这个紫色去做自注意力 "
        },
        {
            "from": 3363,
            "to": 3364.67,
            "location": 2,
            "content": " 那其实呢这个 axial attention "
        },
        {
            "from": 3364.67,
            "to": 3365.73,
            "location": 2,
            "content": " 也就是这个 divided "
        },
        {
            "from": 3365.73,
            "to": 3368.13,
            "location": 2,
            "content": " spacetime attention 的一个极端情况 "
        },
        {
            "from": 3368.2,
            "to": 3370.67,
            "location": 2,
            "content": " 就说为了进一步的减少这个消耗呢 "
        },
        {
            "from": 3370.67,
            "to": 3371.87,
            "location": 2,
            "content": " 那在当前帧上呢 "
        },
        {
            "from": 3371.87,
            "to": 3373.9,
            "location": 2,
            "content": " 也不做所有patch的这个自注意力 "
        },
        {
            "from": 3373.9,
            "to": 3376.1,
            "location": 2,
            "content": " 而是专门去选这个轴上去做 "
        },
        {
            "from": 3376.27,
            "to": 3378.3,
            "location": 2,
            "content": " 但这个效果呢肯定是会有trade off "
        },
        {
            "from": 3379.13,
            "to": 3379.6,
            "location": 2,
            "content": " 总之呢 "
        },
        {
            "from": 3379.6,
            "to": 3382,
            "location": 2,
            "content": " 作者就是详尽的把这些设计方案呢 "
        },
        {
            "from": 3382,
            "to": 3383.2,
            "location": 2,
            "content": " 全部都试了一遍 "
        },
        {
            "from": 3383.4,
            "to": 3385.07,
            "location": 2,
            "content": " 看看到底哪个设计方案 "
        },
        {
            "from": 3385.07,
            "to": 3386.37,
            "location": 2,
            "content": " 最后的效果最好 "
        },
        {
            "from": 3386.57,
            "to": 3389.3,
            "location": 2,
            "content": " 最后呢就依据中间的这个divided space time "
        },
        {
            "from": 3389.3,
            "to": 3391.8,
            "location": 2,
            "content": " attention提出了他们这个 times former 的架构 "
        },
        {
            "from": 3392.67,
            "to": 3394.77,
            "location": 2,
            "content": " 那我们简单来看一下这个消融实验 "
        },
        {
            "from": 3394.97,
            "to": 3396.57,
            "location": 2,
            "content": " 那消融实验这个表1里呢 "
        },
        {
            "from": 3396.57,
            "to": 3398.67,
            "location": 2,
            "content": " 就是把刚才说的这五种设计方案呢 "
        },
        {
            "from": 3398.67,
            "to": 3399.93,
            "location": 2,
            "content": " 全对比了一下 "
        },
        {
            "from": 3400.17,
            "to": 3401.27,
            "location": 2,
            "content": " 那从结果上来看呢 "
        },
        {
            "from": 3401.27,
            "to": 3402.6,
            "location": 2,
            "content": " 这个 divided space time 呢 "
        },
        {
            "from": 3402.6,
            "to": 3404.53,
            "location": 2,
            "content": " 确实取得的效果是最好的 "
        },
        {
            "from": 3404.6,
            "to": 3405.73,
            "location": 2,
            "content": " 那在 k-400上呢 "
        },
        {
            "from": 3405.73,
            "to": 3407.87,
            "location": 2,
            "content": " 单纯用这种2d 的这种自注意力 "
        },
        {
            "from": 3407.87,
            "to": 3409.1,
            "location": 2,
            "content": " 效果也不错啊 "
        },
        {
            "from": 3409.1,
            "to": 3411.7,
            "location": 2,
            "content": " 或者说这种 joint 的这种时空自注意力 "
        },
        {
            "from": 3411.7,
            "to": 3412.77,
            "location": 2,
            "content": " 效果也不错 "
        },
        {
            "from": 3413.17,
            "to": 3413.6,
            "location": 2,
            "content": " 但是呢 "
        },
        {
            "from": 3413.6,
            "to": 3416.07,
            "location": 2,
            "content": " 单纯用2d 的这自注意力之所以效果好 "
        },
        {
            "from": 3416.07,
            "to": 3417.67,
            "location": 2,
            "content": " 是因为 k-400这个数据集呢 "
        },
        {
            "from": 3417.67,
            "to": 3420.33,
            "location": 2,
            "content": " 是一个比较偏重这个静态图像的 "
        },
        {
            "from": 3420.57,
            "to": 3422.2,
            "location": 2,
            "content": " 那如果我们换到这个 SSv2 "
        },
        {
            "from": 3422.2,
            "to": 3422.9,
            "location": 2,
            "content": " 数据集上了 "
        },
        {
            "from": 3422.9,
            "to": 3423.93,
            "location": 2,
            "content": " 我们就可以看到 "
        },
        {
            "from": 3423.93,
            "to": 3425.77,
            "location": 2,
            "content": " 光用这个2 d 的这个自注意力呢 "
        },
        {
            "from": 3425.77,
            "to": 3427.77,
            "location": 2,
            "content": " 效果一下就下降了很多啊 "
        },
        {
            "from": 3427.77,
            "to": 3429.9,
            "location": 2,
            "content": " 我们还是要把这个时间维度考虑上 "
        },
        {
            "from": 3430.1,
            "to": 3430.67,
            "location": 2,
            "content": " 所以说呢 "
        },
        {
            "from": 3430.67,
            "to": 3431.87,
            "location": 2,
            "content": " 唯一表现比较好的 "
        },
        {
            "from": 3431.87,
            "to": 3434.13,
            "location": 2,
            "content": " 就剩下这个 joint space time 和 divided "
        },
        {
            "from": 3434.13,
            "to": 3435.67,
            "location": 2,
            "content": " space time 这两种方式 "
        },
        {
            "from": 3436.1,
            "to": 3437.17,
            "location": 2,
            "content": " 但是我们之前也说过啊 "
        },
        {
            "from": 3437.17,
            "to": 3439.3,
            "location": 2,
            "content": " 这个joint的这种时空的自注意力啊 "
        },
        {
            "from": 3439.3,
            "to": 3441.97,
            "location": 2,
            "content": " 他的这个内存消耗是非常巨大的啊 "
        },
        {
            "from": 3441.97,
            "to": 3444.1,
            "location": 2,
            "content": " 作者也就在这个图三里画了一下 "
        },
        {
            "from": 3444.37,
            "to": 3445.4,
            "location": 2,
            "content": " 就是如果我们把这个视频 "
        },
        {
            "from": 3445.4,
            "to": 3446.6,
            "location": 2,
            "content": " 帧的大小变大啊 "
        },
        {
            "from": 3446.6,
            "to": 3449.57,
            "location": 2,
            "content": " 从224变成336,448或者更大呢 "
        },
        {
            "from": 3449.8,
            "to": 3450.87,
            "location": 2,
            "content": " 他们这个 timesformer "
        },
        {
            "from": 3450.87,
            "to": 3452.13,
            "location": 2,
            "content": " 这个计算量的增长呢 "
        },
        {
            "from": 3452.13,
            "to": 3453.67,
            "location": 2,
            "content": " 是基本成线性的 "
        },
        {
            "from": 3453.8,
            "to": 3455.57,
            "location": 2,
            "content": " 但是这个 joint 的自注意力呢 "
        },
        {
            "from": 3455.57,
            "to": 3457.1,
            "location": 2,
            "content": " 就会增长得非常快啊 "
        },
        {
            "from": 3457.1,
            "to": 3458.53,
            "location": 2,
            "content": " 尤其是后面这个灰色部分呢 "
        },
        {
            "from": 3458.53,
            "to": 3460,
            "location": 2,
            "content": " 其实就已经是 gpu "
        },
        {
            "from": 3460.07,
            "to": 3462.1,
            "location": 2,
            "content": " out of memory 就已经爆显存了 "
        },
        {
            "from": 3462.1,
            "to": 3463.77,
            "location": 2,
            "content": " 其实是没法进行训练的 "
        },
        {
            "from": 3464.13,
            "to": 3465,
            "location": 2,
            "content": " 那同样的道理 "
        },
        {
            "from": 3465.1,
            "to": 3466.5,
            "location": 2,
            "content": " 如果我们把这个输入加长 "
        },
        {
            "from": 3466.5,
            "to": 3469.33,
            "location": 2,
            "content": " 从8帧变成32帧一直到最后的96帧 "
        },
        {
            "from": 3469.47,
            "to": 3472.1,
            "location": 2,
            "content": " 我们可以看到这个 joint space time attention "
        },
        {
            "from": 3472.17,
            "to": 3474.87,
            "location": 2,
            "content": " 其实从32帧开始就已经爆显存了 "
        },
        {
            "from": 3474.97,
            "to": 3476.33,
            "location": 2,
            "content": " 你也是没法训练的 "
        },
        {
            "from": 3476.57,
            "to": 3478.57,
            "location": 2,
            "content": " 所以最后总结下来就是说啊 "
        },
        {
            "from": 3478.57,
            "to": 3480.1,
            "location": 2,
            "content": " 即使这个joint space time "
        },
        {
            "from": 3480.1,
            "to": 3482.27,
            "location": 2,
            "content": " 他的这个结果呢也不错啊 "
        },
        {
            "from": 3482.27,
            "to": 3484.33,
            "location": 2,
            "content": " 而且他这个参数量呢稍微少一点 "
        },
        {
            "from": 3484.4,
            "to": 3486.2,
            "location": 2,
            "content": " 但是呢因为他这个占用的 gpu "
        },
        {
            "from": 3486.2,
            "to": 3487.47,
            "location": 2,
            "content": " 显存实在是太大了 "
        },
        {
            "from": 3487.47,
            "to": 3488.77,
            "location": 2,
            "content": " 我们根本训练不动 "
        },
        {
            "from": 3489,
            "to": 3490.37,
            "location": 2,
            "content": " 那最后最好的方案呢 "
        },
        {
            "from": 3490.37,
            "to": 3493.27,
            "location": 2,
            "content": " 就只剩下这个divided space time attention了 "
        },
        {
            "from": 3494.1,
            "to": 3495.9,
            "location": 2,
            "content": " 那最后呢我们来看一下结果 "
        },
        {
            "from": 3495.97,
            "to": 3497.97,
            "location": 2,
            "content": " 首先呢我们来看一下这个表2 "
        },
        {
            "from": 3498.13,
            "to": 3500.47,
            "location": 2,
            "content": " 作者这里呢就是对比一下times former啊 "
        },
        {
            "from": 3500.47,
            "to": 3502.47,
            "location": 2,
            "content": " 和之前的这两种3d 网络 "
        },
        {
            "from": 3502.7,
            "to": 3504.27,
            "location": 2,
            "content": "I3D呢是最经典的啊 "
        },
        {
            "from": 3504.27,
            "to": 3505.87,
            "location": 2,
            "content": " slow fast呢是最新的啊 "
        },
        {
            "from": 3505.87,
            "to": 3508,
            "location": 2,
            "content": " 所以说他就跟这两种就做了一个对比 "
        },
        {
            "from": 3508.1,
            "to": 3509.5,
            "location": 2,
            "content": " 那其实我们这里可以发现啊 "
        },
        {
            "from": 3509.5,
            "to": 3510.93,
            "location": 2,
            "content": " 如果单纯从这个 "
        },
        {
            "from": 3510.93,
            "to": 3512.5,
            "location": 2,
            "content": " 准确度的角度上来说呢 "
        },
        {
            "from": 3512.5,
            "to": 3514.47,
            "location": 2,
            "content": " 啊这个 times former 呢不是太行 "
        },
        {
            "from": 3514.57,
            "to": 3515.53,
            "location": 2,
            "content": " 所以他这里啊 "
        },
        {
            "from": 3515.53,
            "to": 3518.1,
            "location": 2,
            "content": " 用这个78黑体 说他们是最高的 "
        },
        {
            "from": 3518.2,
            "to": 3519.67,
            "location": 2,
            "content": " 但我们也知道这个 slow fast "
        },
        {
            "from": 3519.67,
            "to": 3521.1,
            "location": 2,
            "content": " 如果你换成 res 101啊 "
        },
        {
            "from": 3521.1,
            "to": 3522.47,
            "location": 2,
            "content": " 或者换成 non local 之后呢 "
        },
        {
            "from": 3522.47,
            "to": 3524.33,
            "location": 2,
            "content": " 他这个准确度已经到80了 "
        },
        {
            "from": 3524.5,
            "to": 3525.47,
            "location": 2,
            "content": " 那作者这里呢 "
        },
        {
            "from": 3525.47,
            "to": 3528.1,
            "location": 2,
            "content": " 为了突出使用这个vision transformer的好处 "
        },
        {
            "from": 3528.53,
            "to": 3529.53,
            "location": 2,
            "content": " 作者这里就发现啊 "
        },
        {
            "from": 3529.53,
            "to": 3531.37,
            "location": 2,
            "content": " 他的这个训练的时间啊 "
        },
        {
            "from": 3531.37,
            "to": 3532.4,
            "location": 2,
            "content": " 和这个做推理的 "
        },
        {
            "from": 3532.4,
            "to": 3534.2,
            "location": 2,
            "content": " 这个 flops 呢都变低了 "
        },
        {
            "from": 3534.33,
            "to": 3535.87,
            "location": 2,
            "content": " 那比如说训练时间的话呢 "
        },
        {
            "from": 3535.87,
            "to": 3539,
            "location": 2,
            "content": " slow fast一个 res 50就要训练6,000多个小时 "
        },
        {
            "from": 3539.13,
            "to": 3540.5,
            "location": 2,
            "content": " 但是他们这个 times former 呢 "
        },
        {
            "from": 3540.5,
            "to": 3542.1,
            "location": 2,
            "content": " 只需要训练400个小时 "
        },
        {
            "from": 3542.27,
            "to": 3544.47,
            "location": 2,
            "content": " 这个vision transformer 拿来做微调啊 "
        },
        {
            "from": 3544.47,
            "to": 3546.2,
            "location": 2,
            "content": " 这个确实效果非常好 "
        },
        {
            "from": 3546.53,
            "to": 3547.3,
            "location": 2,
            "content": " 那推理上呢 "
        },
        {
            "from": 3547.3,
            "to": 3549.53,
            "location": 2,
            "content": " 因为transformer需要的这个输入更少 "
        },
        {
            "from": 3549.53,
            "to": 3551.7,
            "location": 2,
            "content": " 所以说他推理时候用的这个 t flops 呢 "
        },
        {
            "from": 3551.7,
            "to": 3554.5,
            "location": 2,
            "content": " 也更低也就说啊从效率角度而言 "
        },
        {
            "from": 3554.5,
            "to": 3557.27,
            "location": 2,
            "content": " times former是优于之前的这个3 d 网络的 "
        },
        {
            "from": 3557.77,
            "to": 3559.13,
            "location": 2,
            "content": " 但是呢大家也知道啊 "
        },
        {
            "from": 3559.13,
            "to": 3561.93,
            "location": 2,
            "content": " cv 领域的人呢一般只认这个效果啊 "
        },
        {
            "from": 3561.93,
            "to": 3564.13,
            "location": 2,
            "content": " 不太认这些效率这些东西啊 "
        },
        {
            "from": 3564.13,
            "to": 3566.7,
            "location": 2,
            "content": " 所以说作者肯定还是得再刷一刷分的 "
        },
        {
            "from": 3566.73,
            "to": 3567.33,
            "location": 2,
            "content": " 那作者呢 "
        },
        {
            "from": 3567.33,
            "to": 3569.2,
            "location": 2,
            "content": " 就是把这个 timesformer 变得更大啊 "
        },
        {
            "from": 3569.2,
            "to": 3570.37,
            "location": 2,
            "content": " 用了 timesformer large "
        },
        {
            "from": 3570.73,
            "to": 3572.37,
            "location": 2,
            "content": " 然后又用了image net21 k "
        },
        {
            "from": 3572.37,
            "to": 3573.27,
            "location": 2,
            "content": " 去做预训练 "
        },
        {
            "from": 3573.37,
            "to": 3575.9,
            "location": 2,
            "content": " 最后呢还是把 k 400刷到这个上80了 "
        },
        {
            "from": 3575.9,
            "to": 3578.13,
            "location": 2,
            "content": " 那这样子的话呢就别人无话可说了 "
        },
        {
            "from": 3578.13,
            "to": 3579.9,
            "location": 2,
            "content": " 这个效果确实是最好的 "
        },
        {
            "from": 3580.1,
            "to": 3581.27,
            "location": 2,
            "content": " 在ssv2上呢 "
        },
        {
            "from": 3581.27,
            "to": 3582.53,
            "location": 2,
            "content": " 这个结果也是不错 "
        },
        {
            "from": 3583.2,
            "to": 3584.47,
            "location": 2,
            "content": " 总之呢作为第一篇 "
        },
        {
            "from": 3584.47,
            "to": 3585.07,
            "location": 2,
            "content": " 把这个vision "
        },
        {
            "from": 3585.07,
            "to": 3587.07,
            "location": 2,
            "content": " transformer 用到视频理解领域来 "
        },
        {
            "from": 3587.17,
            "to": 3589.53,
            "location": 2,
            "content": " 本文的结果呢其实已经算不错了 "
        },
        {
            "from": 3589.8,
            "to": 3590.87,
            "location": 2,
            "content": " 接下来很快啊 "
        },
        {
            "from": 3590.87,
            "to": 3592.57,
            "location": 2,
            "content": " 我们组这边呢也有一篇啊 "
        },
        {
            "from": 3592.57,
            "to": 3593.5,
            "location": 2,
            "content": " vidtr "
        },
        {
            "from": 3593.9,
            "to": 3596.5,
            "location": 2,
            "content": " 也是用类似的思想去做video transformer 的 "
        },
        {
            "from": 3596.87,
            "to": 3599.53,
            "location": 2,
            "content": " 然后 facebook 那边呢还有另外一片 mvit 啊 "
        },
        {
            "from": 3599.53,
            "to": 3600.93,
            "location": 2,
            "content": " multi scale vision transformer "
        },
        {
            "from": 3600.93,
            "to": 3602.33,
            "location": 2,
            "content": " 也是做video transformer的 "
        },
        {
            "from": 3602.33,
            "to": 3603.33,
            "location": 2,
            "content": " 效果会更好 "
        },
        {
            "from": 3603.4,
            "to": 3605.57,
            "location": 2,
            "content": " 然后 google 那边呢还有一个 vivit "
        },
        {
            "from": 3605.9,
            "to": 3607.4,
            "location": 2,
            "content": " 想法呢都差不多 "
        },
        {
            "from": 3607.47,
            "to": 3609.73,
            "location": 2,
            "content": " 都是把这种时空自注意力呢拆分 "
        },
        {
            "from": 3609.8,
            "to": 3612,
            "location": 2,
            "content": " 只不过用了拆分的方式呢不太一样 "
        },
        {
            "from": 3612.13,
            "to": 3613.37,
            "location": 2,
            "content": " 所以其他的这些工作呢 "
        },
        {
            "from": 3613.37,
            "to": 3614.57,
            "location": 2,
            "content": " 我这里就不讲了 "
        },
        {
            "from": 3615.33,
            "to": 3617.6,
            "location": 2,
            "content": " 那最后呢我们来总结一下这篇论文 "
        },
        {
            "from": 3617.9,
            "to": 3619.73,
            "location": 2,
            "content": " 那其实作者在这里也总结说 "
        },
        {
            "from": 3619.73,
            "to": 3622.33,
            "location": 2,
            "content": " 他们的这个times former呢有四个好处啊 "
        },
        {
            "from": 3622.33,
            "to": 3624.53,
            "location": 2,
            "content": " 第一个呢就是想法非常的简单 "
        },
        {
            "from": 3624.77,
            "to": 3626.7,
            "location": 2,
            "content": " 第二个呢就是效果非常好啊 "
        },
        {
            "from": 3626.7,
            "to": 3627.33,
            "location": 2,
            "content": " 在好几个 "
        },
        {
            "from": 3627.33,
            "to": 3628.93,
            "location": 2,
            "content": " 这个动作识别的这个数据集上呢 "
        },
        {
            "from": 3628.93,
            "to": 3630.47,
            "location": 2,
            "content": " 都取得了最好的效果 "
        },
        {
            "from": 3630.87,
            "to": 3632.7,
            "location": 2,
            "content": " 第三个呢就是不论是训练啊 "
        },
        {
            "from": 3632.7,
            "to": 3633.9,
            "location": 2,
            "content": " 还是在做推理的时候 "
        },
        {
            "from": 3633.9,
            "to": 3635.77,
            "location": 2,
            "content": " 他这个开销呢都是非常小的 "
        },
        {
            "from": 3635.77,
            "to": 3637.2,
            "location": 2,
            "content": " 这点对于视频理解来说 "
        },
        {
            "from": 3637.2,
            "to": 3638.9,
            "location": 2,
            "content": " 还是非常具有吸引力的 "
        },
        {
            "from": 3638.93,
            "to": 3640.73,
            "location": 2,
            "content": " 然后最后呢其实我并没有讲 "
        },
        {
            "from": 3640.73,
            "to": 3642,
            "location": 2,
            "content": " 就是说这个times former呢 "
        },
        {
            "from": 3642,
            "to": 3644.3,
            "location": 2,
            "content": " 可以用于处理超过一分钟的视频 "
        },
        {
            "from": 3644.33,
            "to": 3645.27,
            "location": 2,
            "content": " 也就意味着说呢 "
        },
        {
            "from": 3645.27,
            "to": 3647.3,
            "location": 2,
            "content": " 我们之后可以做这种长时间的这 "
        },
        {
            "from": 3647.3,
            "to": 3648.37,
            "location": 2,
            "content": " 个视频理解了 "
        },
        {
            "from": 3648.87,
            "to": 3649.2,
            "location": 2,
            "content": " 这个呢 "
        },
        {
            "from": 3649.2,
            "to": 3651.6,
            "location": 2,
            "content": " 其实视频理解里非常重要的一个部分 "
        },
        {
            "from": 3651.6,
            "to": 3653.73,
            "location": 2,
            "content": " 啊但是之前呢很少有工作做 "
        },
        {
            "from": 3654.07,
            "to": 3655.7,
            "location": 2,
            "content": " 因为确实这个训练成本啊 "
        },
        {
            "from": 3655.7,
            "to": 3657.13,
            "location": 2,
            "content": " 各方面都非常的高啊 "
        },
        {
            "from": 3657.13,
            "to": 3658.5,
            "location": 2,
            "content": " 这个任务也比较困难 "
        },
        {
            "from": 3658.5,
            "to": 3660.4,
            "location": 2,
            "content": " 而且也没有合适的一个数据集啊 "
        },
        {
            "from": 3660.4,
            "to": 3661.5,
            "location": 2,
            "content": " 去做这种测试 "
        },
        {
            "from": 3661.8,
            "to": 3663.9,
            "location": 2,
            "content": " 所以说啊综合以上这些优点 "
        },
        {
            "from": 3663.97,
            "to": 3664.97,
            "location": 2,
            "content": " 而且vision transformer "
        },
        {
            "from": 3664.97,
            "to": 3666.93,
            "location": 2,
            "content": " 们在视觉这方面大杀四方 "
        },
        {
            "from": 3666.93,
            "to": 3669.37,
            "location": 2,
            "content": " 这个扩展性稳健性都这么的好 "
        },
        {
            "from": 3669.77,
            "to": 3670.67,
            "location": 2,
            "content": " 我觉得接下来呢 "
        },
        {
            "from": 3670.67,
            "to": 3672.73,
            "location": 2,
            "content": " video transformer 确实是大有可为 "
        },
        {
            "from": 3672.93,
            "to": 3674.13,
            "location": 2,
            "content": " 而且更重要的是呢 "
        },
        {
            "from": 3674.13,
            "to": 3676.57,
            "location": 2,
            "content": " 视频本身就是一个多模态的信号 "
        },
        {
            "from": 3676.73,
            "to": 3679.1,
            "location": 2,
            "content": " 他可能会有字幕啊这种文字信息 "
        },
        {
            "from": 3679.1,
            "to": 3681.17,
            "location": 2,
            "content": " 然后他可能会有这种音频信息 "
        },
        {
            "from": 3681.3,
            "to": 3683.37,
            "location": 2,
            "content": " 然后你如果从中抽取这种光流 "
        },
        {
            "from": 3683.37,
            "to": 3685,
            "location": 2,
            "content": " 或者抽取这种深度图啊 "
        },
        {
            "from": 3685,
            "to": 3687.37,
            "location": 2,
            "content": " 他就是属于别的这种多模态信息 "
        },
        {
            "from": 3687.47,
            "to": 3688.1,
            "location": 2,
            "content": " 他自己呢 "
        },
        {
            "from": 3688.1,
            "to": 3690.47,
            "location": 2,
            "content": " 就是一个非常丰富的这个输入来源 "
        },
        {
            "from": 3690.7,
            "to": 3692.77,
            "location": 2,
            "content": " 从中啊可以设计成各种各样的这个自 "
        },
        {
            "from": 3692.77,
            "to": 3693.67,
            "location": 2,
            "content": " 监督信号 "
        },
        {
            "from": 3693.8,
            "to": 3695.53,
            "location": 2,
            "content": " 如果我们再和这个transformer结合 "
        },
        {
            "from": 3695.53,
            "to": 3698.2,
            "location": 2,
            "content": " 起来很有可能就能达到 cv 里面啊 "
        },
        {
            "from": 3698.2,
            "to": 3700.87,
            "location": 2,
            "content": " 像 nlp 那样的这个 bert gpt 时代 "
        },
        {
            "from": 3701.47,
            "to": 3703.73,
            "location": 2,
            "content": " 那说完了最新的这个 video transformer啊 "
        },
        {
            "from": 3703.73,
            "to": 3704.17,
            "location": 2,
            "tag": "总结",
            "content": " 最后呢 "
        },
        {
            "from": 3704.17,
            "to": 3706.13,
            "location": 2,
            "content": " 我们就来把之前讲过的所有东西呢 "
        },
        {
            "from": 3706.13,
            "to": 3707.27,
            "location": 2,
            "content": " 大概代串一下 "
        },
        {
            "from": 3707.93,
            "to": 3709.8,
            "location": 2,
            "content": " 首先呢就是从14年开始啊 "
        },
        {
            "from": 3709.8,
            "to": 3711.77,
            "location": 2,
            "content": " 最早的在 zlexnet 之后啊 "
        },
        {
            "from": 3711.77,
            "to": 3712.37,
            "location": 2,
            "content": " 把这个卷积 "
        },
        {
            "from": 3712.37,
            "to": 3714.07,
            "location": 2,
            "content": " 神经网络用到视频领域里来 "
        },
        {
            "from": 3714.07,
            "to": 3715.6,
            "location": 2,
            "content": " 就是 deep video 这篇论文 "
        },
        {
            "from": 3715.7,
            "to": 3716.2,
            "location": 2,
            "content": " 但是呢 "
        },
        {
            "from": 3716.2,
            "to": 3718.7,
            "location": 2,
            "content": " deep video 没有很好的利用这种运动信息 "
        },
        {
            "from": 3718.7,
            "to": 3721.07,
            "location": 2,
            "content": " 所以说他刚开始的效果呢不是很好啊 "
        },
        {
            "from": 3721.07,
            "to": 3723.6,
            "location": 2,
            "content": " 他还没有这种手工特征 idt 的效果好 "
        },
        {
            "from": 3724.13,
            "to": 3724.87,
            "location": 2,
            "content": " 所以说呢 "
        },
        {
            "from": 3724.87,
            "to": 3727.27,
            "location": 2,
            "content": " 这个双流网络的作者就想了一下 "
        },
        {
            "from": 3727.27,
            "to": 3728.27,
            "location": 2,
            "content": " 那为什么不把 idt "
        },
        {
            "from": 3728.4,
            "to": 3730.8,
            "location": 2,
            "content": " 里用的这种运动特征加进来呢 "
        },
        {
            "from": 3730.93,
            "to": 3732.9,
            "location": 2,
            "content": " 所以说这两个方法结合起来 "
        },
        {
            "from": 3732.9,
            "to": 3734.67,
            "location": 2,
            "content": " 就造就了这个双流网络 "
        },
        {
            "from": 3735.13,
            "to": 3737.47,
            "location": 2,
            "content": " 所以双流网络的结果呢就变得很高 "
        },
        {
            "from": 3737.7,
            "to": 3739.8,
            "location": 2,
            "content": " 那从此就开始了用这个深度学习 "
        },
        {
            "from": 3739.8,
            "to": 3741.37,
            "location": 2,
            "content": " 做这个视频理解的时代 "
        },
        {
            "from": 3741.67,
            "to": 3741.9,
            "location": 2,
            "content": " 那 "
        },
        {
            "from": 3741.9,
            "to": 3744.2,
            "location": 2,
            "content": " 因为双流网络证明了他的这个有效性 "
        },
        {
            "from": 3744.2,
            "to": 3746.13,
            "location": 2,
            "content": " 啊所以说接下来大家就在他之上呢 "
        },
        {
            "from": 3746.13,
            "to": 3747.5,
            "location": 2,
            "content": " 去做各种各样的改进 "
        },
        {
            "from": 3747.87,
            "to": 3749.5,
            "location": 2,
            "content": " 那首先最常见的一个改进呢 "
        },
        {
            "from": 3749.5,
            "to": 3750.87,
            "location": 2,
            "content": " 就是说对视频来说啊 "
        },
        {
            "from": 3750.87,
            "to": 3753.53,
            "location": 2,
            "content": " 我们想要更长的这种时序理解的能力 "
        },
        {
            "from": 3753.6,
            "to": 3755.3,
            "location": 2,
            "content": " 所以说我们加上这个 lstm "
        },
        {
            "from": 3755.3,
            "to": 3756.5,
            "location": 2,
            "content": " 就有了这个 cvpr15 "
        },
        {
            "from": 3756.5,
            "to": 3758.8,
            "location": 2,
            "content": " 的 beyond short snippts 这篇论文 "
        },
        {
            "from": 3759.17,
            "to": 3759.67,
            "location": 2,
            "content": " 然后呢 "
        },
        {
            "from": 3759.67,
            "to": 3761.67,
            "location": 2,
            "content": " 因为这个双流网络又是做的这种 "
        },
        {
            "from": 3761.67,
            "to": 3762.5,
            "location": 2,
            "content": " late fusion 啊 "
        },
        {
            "from": 3762.5,
            "to": 3764.07,
            "location": 2,
            "content": " 就在最后把这个结果 "
        },
        {
            "from": 3764.07,
            "to": 3765.57,
            "location": 2,
            "content": " 加做了个加权平均 "
        },
        {
            "from": 3765.8,
            "to": 3767.33,
            "location": 2,
            "content": " 那所以肯定就会有人想啊 "
        },
        {
            "from": 3767.33,
            "to": 3769,
            "location": 2,
            "content": " 我们能不能做一下 early fusion 呢 "
        },
        {
            "from": 3769,
            "to": 3771.2,
            "location": 2,
            "content": " 那于是就有了这个cvpr16的这个 "
        },
        {
            "from": 3771.2,
            "to": 3772.57,
            "location": 2,
            "content": " early fusion 这篇论文 "
        },
        {
            "from": 3773,
            "to": 3774.5,
            "location": 2,
            "content": " 然后呢因为双流方法里 "
        },
        {
            "from": 3774.5,
            "to": 3776.33,
            "location": 2,
            "content": " 只是简单的利用了这个光流啊 "
        },
        {
            "from": 3776.33,
            "to": 3778.73,
            "location": 2,
            "content": " 并没有真的根据光流的这个轨迹啊 "
        },
        {
            "from": 3778.73,
            "to": 3780.93,
            "location": 2,
            "content": " 去做这种视频特征的叠加 "
        },
        {
            "from": 3781.53,
            "to": 3783.5,
            "location": 2,
            "content": " 所以说在双流网络的基础上啊 "
        },
        {
            "from": 3783.5,
            "to": 3785.37,
            "location": 2,
            "content": " cvpr15的 tdd 这篇论文 "
        },
        {
            "from": 3785.37,
            "to": 3787.27,
            "location": 2,
            "content": " 就按照轨迹去直接加特征啊 "
        },
        {
            "from": 3787.27,
            "to": 3788.73,
            "location": 2,
            "content": " 得到了非常好的效果 "
        },
        {
            "from": 3789.13,
            "to": 3791.17,
            "location": 2,
            "content": " 那最后一点呢就是对于视频啊 "
        },
        {
            "from": 3791.17,
            "to": 3793.57,
            "location": 2,
            "content": " 我们想要处理这种长时间的视频信息 "
        },
        {
            "from": 3793.57,
            "to": 3796,
            "location": 2,
            "content": " 而且要让他变得更加的这个高效 "
        },
        {
            "from": 3796.3,
            "to": 3799.3,
            "location": 2,
            "content": " 这就有了 eccv 16的这个 tsn 这篇论文啊 "
        },
        {
            "from": 3799.3,
            "to": 3800.8,
            "location": 2,
            "content": " temporal segment networks "
        },
        {
            "from": 3800.8,
            "to": 3802.8,
            "location": 2,
            "content": " 就是把一个视频呢打成几个段 "
        },
        {
            "from": 3802.93,
            "to": 3804.57,
            "location": 2,
            "content": " 然后每一段你去做这个分析 "
        },
        {
            "from": 3804.57,
            "to": 3806.4,
            "location": 2,
            "content": " 最后把这个分析呢取一个合并 "
        },
        {
            "from": 3807.13,
            "to": 3809.27,
            "location": 2,
            "content": " 那因为 tsn 这个做的呢比较简单 "
        },
        {
            "from": 3809.27,
            "to": 3810.97,
            "location": 2,
            "content": " 所以很快在 tsn 的基础上 "
        },
        {
            "from": 3810.97,
            "to": 3813.53,
            "location": 2,
            "content": " 大家又纷纷的去做各种改进和尝试 "
        },
        {
            "from": 3813.97,
            "to": 3814.67,
            "location": 2,
            "content": " 就是把之前 "
        },
        {
            "from": 3814.67,
            "to": 3816.93,
            "location": 2,
            "content": " 传统学习里的这种全局建模啊 "
        },
        {
            "from": 3816.93,
            "to": 3817.9,
            "location": 2,
            "content": " 已经加了进来 "
        },
        {
            "from": 3817.9,
            "to": 3819.17,
            "location": 2,
            "content": " 那比如说全局建模 "
        },
        {
            "from": 3819.27,
            "to": 3820.9,
            "location": 2,
            "content": " 有这个 face reacting coding 啊 "
        },
        {
            "from": 3820.9,
            "to": 3822.87,
            "location": 2,
            "content": " vlad encoding 这些方法 "
        },
        {
            "from": 3822.97,
            "to": 3824.3,
            "location": 2,
            "content": " 那像这个dovf 呢 "
        },
        {
            "from": 3824.3,
            "to": 3826.7,
            "location": 2,
            "content": " 就是把这个 face reacting coding 用了进来 "
        },
        {
            "from": 3826.9,
            "to": 3827.73,
            "location": 2,
            "content": " 这个 tle 呢 "
        },
        {
            "from": 3827.73,
            "to": 3829.93,
            "location": 2,
            "content": " 就是把这个bi-linearing encoding 给用了进来 "
        },
        {
            "from": 3829.93,
            "to": 3831.4,
            "location": 2,
            "content": " 那这个 action vlad 呢 "
        },
        {
            "from": 3831.4,
            "to": 3834.27,
            "location": 2,
            "content": " 其实顾名思义就是把 vlad 给用了进来 "
        },
        {
            "from": 3834.5,
            "to": 3835.9,
            "location": 2,
            "content": " 那基本到这个阶段呢 "
        },
        {
            "from": 3835.9,
            "to": 3838.1,
            "location": 2,
            "content": " 其实这个2 d 的双流网络 "
        },
        {
            "from": 3838.1,
            "to": 3840.2,
            "location": 2,
            "content": " 就已经把 ucf 101和 hmdb "
        },
        {
            "from": 3840.27,
            "to": 3842.3,
            "location": 2,
            "content": " 51呢基本给刷的非常高了 "
        },
        {
            "from": 3842.37,
            "to": 3844.27,
            "location": 2,
            "content": " 也没有什么太多可以做的了 "
        },
        {
            "from": 3844.53,
            "to": 3845.27,
            "location": 2,
            "content": " 然后同时呢 "
        },
        {
            "from": 3845.27,
            "to": 3846.47,
            "location": 2,
            "content": " 也就是在2017年 "
        },
        {
            "from": 3846.47,
            "to": 3848.37,
            "location": 2,
            "content": " 这个 i 3 d 这个网络就出来了 "
        },
        {
            "from": 3848.37,
            "to": 3850.8,
            "location": 2,
            "content": " 那所以我们现在再来看3 d 网络这条线 "
        },
        {
            "from": 3851.4,
            "to": 3853.57,
            "location": 2,
            "content": " 在这个 deepvideo 提出这个 sports one million "
        },
        {
            "from": 3853.57,
            "to": 3855.6,
            "location": 2,
            "content": " 之后呢这个很多人就想啊 "
        },
        {
            "from": 3855.6,
            "to": 3857.67,
            "location": 2,
            "content": " 那既然这个视频是一个3 d 的输入 "
        },
        {
            "from": 3857.67,
            "to": 3858.93,
            "location": 2,
            "content": " 我们为什么不用一个3 d "
        },
        {
            "from": 3858.93,
            "to": 3860.3,
            "location": 2,
            "content": " 的网络来处理它呢 "
        },
        {
            "from": 3860.37,
            "to": 3862.8,
            "location": 2,
            "content": " 那用一个3 d 的卷积神经网络来学习 "
        },
        {
            "from": 3862.8,
            "to": 3864.93,
            "location": 2,
            "content": " 肯定听起来是一个更合理的事情 "
        },
        {
            "from": 3865.37,
            "to": 3867.4,
            "location": 2,
            "content": " 很快呢就有人做了这个 c 3 d 啊 "
        },
        {
            "from": 3867.4,
            "to": 3870.13,
            "location": 2,
            "content": " 就是纯粹的用一个3 d 神经网络来学习 "
        },
        {
            "from": 3870.13,
            "to": 3872.5,
            "location": 2,
            "content": " 视频而且因为有了 sports one million "
        },
        {
            "from": 3872.5,
            "to": 3873.73,
            "location": 2,
            "content": " 这么大一个数据集啊 "
        },
        {
            "from": 3873.73,
            "to": 3875.33,
            "location": 2,
            "content": " 他觉得他还是能训练出来一个 "
        },
        {
            "from": 3875.33,
            "to": 3876.5,
            "location": 2,
            "content": " 非常好的网络的 "
        },
        {
            "from": 3876.73,
            "to": 3877.53,
            "location": 2,
            "content": " 那事实上呢 "
        },
        {
            "from": 3877.53,
            "to": 3879.9,
            "location": 2,
            "content": " 这个网络抽取特征效果还可以啊 "
        },
        {
            "from": 3879.9,
            "to": 3882.3,
            "location": 2,
            "content": " 但是如果在一些刷分比较厉害的这个 "
        },
        {
            "from": 3882.3,
            "to": 3883.1,
            "location": 2,
            "content": " 数据集上呢 "
        },
        {
            "from": 3883.1,
            "to": 3885.27,
            "location": 2,
            "content": " 他跟别的方法效果还是差的比较远 "
        },
        {
            "from": 3885.47,
            "to": 3886.9,
            "location": 2,
            "content": " 那接下来大家就想啊 "
        },
        {
            "from": 3886.9,
            "to": 3888.9,
            "location": 2,
            "content": " 那为什么3 d 就是训练不好呢 "
        },
        {
            "from": 3888.97,
            "to": 3890.93,
            "location": 2,
            "content": " 可能还是因为初始化做的不好 "
        },
        {
            "from": 3891.37,
            "to": 3893.13,
            "location": 2,
            "content": " 那如果我能把这个初始化做的再 "
        },
        {
            "from": 3893.13,
            "to": 3894.3,
            "location": 2,
            "content": " 好一点这个训练啊 "
        },
        {
            "from": 3894.3,
            "to": 3896.57,
            "location": 2,
            "content": " 这个优化就会变得更简单啊 "
        },
        {
            "from": 3896.57,
            "to": 3898.53,
            "location": 2,
            "content": " 于是就有了 i 3 d 这篇论文啊 "
        },
        {
            "from": 3898.53,
            "to": 3900.33,
            "location": 2,
            "content": " 就是 inflated 3 d network "
        },
        {
            "from": 3900.53,
            "to": 3903.2,
            "location": 2,
            "content": " 它呢可以借助这个2 d 网络的初始化 "
        },
        {
            "from": 3903.2,
            "to": 3904.9,
            "location": 2,
            "content": " 和2 d 网络的这个结构 "
        },
        {
            "from": 3905.2,
            "to": 3907.33,
            "location": 2,
            "content": " 很快呢就能得到一个很好的结果 "
        },
        {
            "from": 3907.53,
            "to": 3908.1,
            "location": 2,
            "content": " 所以说呢 "
        },
        {
            "from": 3908.1,
            "to": 3908.67,
            "location": 2,
            "content": " i 3 d 呢 "
        },
        {
            "from": 3908.67,
            "to": 3911.47,
            "location": 2,
            "content": " 把 ucf 101和 hmdb 51这两个数据集呢 "
        },
        {
            "from": 3911.47,
            "to": 3912.97,
            "location": 2,
            "content": " 直接就给刷爆了啊 "
        },
        {
            "from": 3912.97,
            "to": 3913.8,
            "location": 2,
            "content": " 在那之后呢 "
        },
        {
            "from": 3913.8,
            "to": 3916.9,
            "location": 2,
            "content": " 大家就开始用这个 k 400啊去汇报结果 "
        },
        {
            "from": 3917.4,
            "to": 3918.93,
            "location": 2,
            "content": " 所以说在 3 d 网络这边呢 "
        },
        {
            "from": 3918.93,
            "to": 3920.4,
            "location": 2,
            "content": " 基本上所有的这些工作呢 "
        },
        {
            "from": 3920.4,
            "to": 3922.13,
            "location": 2,
            "content": " 都是在 k 400或者说 somethingsomething "
        },
        {
            "from": 3922.2,
            "to": 3924.47,
            "location": 2,
            "content": "  这几个数据集上去汇报结果 "
        },
        {
            "from": 3924.93,
            "to": 3926.27,
            "location": 2,
            "content": " 那在3 d 网络这边呢 "
        },
        {
            "from": 3926.27,
            "to": 3928.77,
            "location": 2,
            "content": " 一旦证明了这个 i3d 网络的有效性 "
        },
        {
            "from": 3928.97,
            "to": 3930.57,
            "location": 2,
            "content": " 那接下来呢就有几个方向 "
        },
        {
            "from": 3930.97,
            "to": 3932.57,
            "location": 2,
            "content": " 那首先第一个方向就是说 "
        },
        {
            "from": 3932.57,
            "to": 3933.67,
            "location": 2,
            "content": " 那你这个i 3 d 呢 "
        },
        {
            "from": 3933.67,
            "to": 3936.57,
            "location": 2,
            "content": " 是从一个2 d 的inceptionnet 搬到3 d 的 "
        },
        {
            "from": 3936.8,
            "to": 3939.47,
            "location": 2,
            "content": " 那其实我也可以把别的2 d 网络搬过来 "
        },
        {
            "from": 3939.57,
            "to": 3941.7,
            "location": 2,
            "content": " 那所以说把一个2 d 的 resnet 搬过来 "
        },
        {
            "from": 3941.7,
            "to": 3943.3,
            "location": 2,
            "content": " 就成了 r 3 d 啊 "
        },
        {
            "from": 3943.3,
            "to": 3946.6,
            "location": 2,
            "content": " 把一个2 d 的 resnext 的搬过来就是 mfnet "
        },
        {
            "from": 3946.8,
            "to": 3949.33,
            "location": 2,
            "content": " 那如果把一个2 d 的 senet 搬过来啊 "
        },
        {
            "from": 3949.33,
            "to": 3950.5,
            "location": 2,
            "content": " 那就是 stc "
        },
        {
            "from": 3951.17,
            "to": 3952.13,
            "location": 2,
            "content": " 那第二个思路呢 "
        },
        {
            "from": 3952.13,
            "to": 3954.77,
            "location": 2,
            "content": " 就是说这个2 d 网络呢表现也不错 "
        },
        {
            "from": 3954.93,
            "to": 3957.4,
            "location": 2,
            "content": " 而且呢2 d 比3 d 呢要便宜很多 "
        },
        {
            "from": 3957.4,
            "to": 3959.2,
            "location": 2,
            "content": " 那我们能不能把这个2 d 和3 d "
        },
        {
            "from": 3959.2,
            "to": 3960.47,
            "location": 2,
            "content": " 结合起来使用呢 "
        },
        {
            "from": 3960.6,
            "to": 3962.6,
            "location": 2,
            "content": " 所以这也就有了接下来几个工作啊 "
        },
        {
            "from": 3962.6,
            "to": 3965.67,
            "location": 2,
            "content": " 就是 s3d 、r（2+1）d、eco 和这个 p3d "
        },
        {
            "from": 3966,
            "to": 3967.6,
            "location": 2,
            "content": " 他们的想法呢都很像啊 "
        },
        {
            "from": 3967.6,
            "to": 3970.7,
            "location": 2,
            "content": " 基本都是把这个3 d 呢给 p 成2 d 和1 d 了 "
        },
        {
            "from": 3971,
            "to": 3972.57,
            "location": 2,
            "content": " 准确度上呢没什么降低 "
        },
        {
            "from": 3972.57,
            "to": 3974.7,
            "location": 2,
            "content": " 但是这个计算效率和训练速度上呢 "
        },
        {
            "from": 3974.7,
            "to": 3976.13,
            "location": 2,
            "content": " 都有了大幅度的提高 "
        },
        {
            "from": 3976.4,
            "to": 3977.53,
            "location": 2,
            "content": " 那第三个方向呢 "
        },
        {
            "from": 3977.53,
            "to": 3979.97,
            "location": 2,
            "content": " 当然跟2 d 或者双流网络也一样啊 "
        },
        {
            "from": 3979.97,
            "to": 3981.9,
            "location": 2,
            "content": " 我呢想去尝试这种 lstm "
        },
        {
            "from": 3981.9,
            "to": 3983.13,
            "location": 2,
            "content": " 或者尝试这种 tsn "
        },
        {
            "from": 3983.13,
            "to": 3985.3,
            "location": 2,
            "content": " 去处理更长的这种时间序列 "
        },
        {
            "from": 3985.77,
            "to": 3987.67,
            "location": 2,
            "content": " 那所以说呢也有对应的一系列工作 "
        },
        {
            "from": 3987.67,
            "to": 3988.77,
            "location": 2,
            "content": " 比如说这个 ltc "
        },
        {
            "from": 3988.77,
            "to": 3990.9,
            "location": 2,
            "content": " 就已经使用了120帧所输入 "
        },
        {
            "from": 3991,
            "to": 3993.93,
            "location": 2,
            "content": " 而接下来这个 t3d 啊non local、 v4d 啊 "
        },
        {
            "from": 3993.93,
            "to": 3994.53,
            "location": 2,
            "content": " 这些工作 "
        },
        {
            "from": 3994.53,
            "to": 3995.8,
            "location": 2,
            "content": " 通通都是为了能处理 "
        },
        {
            "from": 3995.8,
            "to": 3997.07,
            "location": 2,
            "content": " 更长的这个时序信息 "
        },
        {
            "from": 3997.07,
            "to": 3997.9,
            "location": 2,
            "content": " 而设计的 "
        },
        {
            "from": 3998.4,
            "to": 3999.87,
            "location": 2,
            "content": " 那最后一个方向呢就是做这 "
        },
        {
            "from": 3999.87,
            "to": 4000.9,
            "location": 2,
            "content": " 种高效率的 "
        },
        {
            "from": 4000.93,
            "to": 4004.1,
            "location": 2,
            "content": " 比如说这种 csn 啊就是 channel separate network "
        },
        {
            "from": 4004.37,
            "to": 4006.67,
            "location": 2,
            "content": " 还有我们今天刚才说过的这个 slow fast "
        },
        {
            "from": 4006.7,
            "to": 4008.13,
            "location": 2,
            "content": " 啊还有通过这个 auto ml "
        },
        {
            "from": 4008.13,
            "to": 4010.2,
            "location": 2,
            "content": " 搜出来的是 x3d 这个网络啊 "
        },
        {
            "from": 4010.2,
            "to": 4011.97,
            "location": 2,
            "content": " 非常小但是效果也很好 "
        },
        {
            "from": 4012.4,
            "to": 4013.87,
            "location": 2,
            "content": " 然后呢因为 x 3 d 啊 "
        },
        {
            "from": 4013.87,
            "to": 4015.47,
            "location": 2,
            "content": " 使用了这种auto ml的方式 "
        },
        {
            "from": 4015.47,
            "to": 4016.6,
            "location": 2,
            "content": " 去搜索这个网络 "
        },
        {
            "from": 4016.6,
            "to": 4018.2,
            "location": 2,
            "content": " 所以说搜出来的这个网络呢 "
        },
        {
            "from": 4018.2,
            "to": 4019.37,
            "location": 2,
            "content": " 不仅效果好 "
        },
        {
            "from": 4019.4,
            "to": 4021.27,
            "location": 2,
            "content": " 而且参数量呢特别的小 "
        },
        {
            "from": 4021.37,
            "to": 4023.97,
            "location": 2,
            "content": " 那基本上就很难再有人能打过他了 "
        },
        {
            "from": 4024.13,
            "to": 4025.33,
            "location": 2,
            "content": " 那正当大家发愁 "
        },
        {
            "from": 4025.33,
            "to": 4027.73,
            "location": 2,
            "content": " 这个视频理解该怎么往下做的时候呢 "
        },
        {
            "from": 4027.73,
            "to": 4028.93,
            "location": 2,
            "content": " 大救星来了 "
        },
        {
            "from": 4028.93,
            "to": 4030.4,
            "location": 2,
            "content": " vision transformer出现了 "
        },
        {
            "from": 4030.7,
            "to": 4032.97,
            "location": 2,
            "content": " 所以大家迅速就抛弃了3 d 网络啊 "
        },
        {
            "from": 4032.97,
            "to": 4034.3,
            "location": 2,
            "content": " 全去搞vision transformer "
        },
        {
            "from": 4034.3,
            "to": 4036.33,
            "location": 2,
            "content": " 因为反正3 d 网络我也刷不动 "
        },
        {
            "from": 4036.57,
            "to": 4038.33,
            "location": 2,
            "content": " 那在短短几个月的时间里呢 "
        },
        {
            "from": 4038.33,
            "to": 4040.13,
            "location": 2,
            "content": " 在2月份就有了times former 啊 "
        },
        {
            "from": 4040.13,
            "to": 4041.47,
            "location": 2,
            "content": " 3月份有了 vivit "
        },
        {
            "from": 4041.47,
            "to": 4042.3,
            "location": 2,
            "content": " 然后4月份呢 "
        },
        {
            "from": 4042.3,
            "to": 4042.97,
            "location": 2,
            "content": " 我们的 vidtr "
        },
        {
            "from": 4042.97,
            "to": 4045.67,
            "location": 2,
            "content": "  和这个 facebook mvit 也就都放出来了 "
        },
        {
            "from": 4045.73,
            "to": 4047.57,
            "location": 2,
            "content": " 基本上方法呢都差不多 "
        },
        {
            "from": 4047.93,
            "to": 4049.4,
            "location": 2,
            "content": " 就说这个 joint spacetime "
        },
        {
            "from": 4049.4,
            "to": 4050.93,
            "location": 2,
            "content": " attention啊这种合并起来的 "
        },
        {
            "from": 4050.93,
            "to": 4052.1,
            "location": 2,
            "content": " 这个时空自注意力呢 "
        },
        {
            "from": 4052.1,
            "to": 4052.97,
            "location": 2,
            "content": " 太贵了啊 "
        },
        {
            "from": 4052.97,
            "to": 4053.73,
            "location": 2,
            "content": " 这个视频里呢 "
        },
        {
            "from": 4053.73,
            "to": 4055.73,
            "location": 2,
            "content": " 直接做这种transformer做不起 "
        },
        {
            "from": 4055.87,
            "to": 4057.27,
            "location": 2,
            "content": " 所以我们就要拆分它 "
        },
        {
            "from": 4057.27,
            "to": 4058.73,
            "location": 2,
            "content": " 那要么我先做一下时间 "
        },
        {
            "from": 4058.73,
            "to": 4059.9,
            "location": 2,
            "content": " 再做一下空间啊 "
        },
        {
            "from": 4059.9,
            "to": 4062.8,
            "location": 2,
            "content": " 就跟 r （2+1） d 一样在这个维度上去拆分 "
        },
        {
            "from": 4063.13,
            "to": 4064.8,
            "location": 2,
            "content": " 要么呢我就是先做一下局部 "
        },
        {
            "from": 4064.8,
            "to": 4065.73,
            "location": 2,
            "content": " 再做一下全局 "
        },
        {
            "from": 4065.73,
            "to": 4067.8,
            "location": 2,
            "content": " 就是在用小窗口大窗口之上啊 "
        },
        {
            "from": 4067.8,
            "to": 4068.77,
            "location": 2,
            "content": " 去拆分一下 "
        },
        {
            "from": 4069,
            "to": 4069.6,
            "location": 2,
            "content": " 总之呢 "
        },
        {
            "from": 4069.6,
            "to": 4071.87,
            "location": 2,
            "content": " vision transformer在视频理解里的应用呢 "
        },
        {
            "from": 4071.87,
            "to": 4073.27,
            "location": 2,
            "content": " 还是比较初级的 "
        },
        {
            "from": 4073.5,
            "to": 4074.97,
            "location": 2,
            "content": " 我能想象到的方向呢 "
        },
        {
            "from": 4075.07,
            "to": 4076.27,
            "location": 2,
            "content": " 就是利用transformer "
        },
        {
            "from": 4076.27,
            "to": 4078.37,
            "location": 2,
            "content": " 这种长时间序列建模的能力啊 "
        },
        {
            "from": 4078.37,
            "to": 4079.37,
            "location": 2,
            "content": " 去做这种长时间 "
        },
        {
            "from": 4079.37,
            "to": 4080.3,
            "location": 2,
            "content": " 的视频理解 "
        },
        {
            "from": 4080.47,
            "to": 4082.7,
            "location": 2,
            "content": " 而且呢还有就是这种多模态的学习 "
        },
        {
            "from": 4082.73,
            "to": 4084.3,
            "location": 2,
            "content": " 还有这种自监督的学习 "
        },
        {
            "from": 4084.93,
            "to": 4085.5,
            "location": 2,
            "content": " 总之呢 "
        },
        {
            "from": 4085.5,
            "to": 4087.8,
            "location": 2,
            "content": " 虽然我关注了视频学习这么多年 "
        },
        {
            "from": 4087.87,
            "to": 4088.67,
            "location": 2,
            "content": " 但我觉得呢 "
        },
        {
            "from": 4088.67,
            "to": 4089.33,
            "location": 2,
            "content": " 视频领域 "
        },
        {
            "from": 4089.33,
            "to": 4091.47,
            "location": 2,
            "content": " 还是处在一个非常初级的阶段 "
        },
        {
            "from": 4091.73,
            "to": 4093.8,
            "location": 2,
            "content": " 接下来呢有太多太多可以做的 "
        },
        {
            "from": 4093.8,
            "to": 4096.1,
            "location": 2,
            "content": " 而且有太多太多需要做的任务了 "
        },
        {
            "from": 4096.57,
            "to": 4097.47,
            "location": 2,
            "content": " 我虽然不知道啊 "
        },
        {
            "from": 4097.47,
            "to": 4098.87,
            "location": 2,
            "content": " 真实的这个视觉应用里 "
        },
        {
            "from": 4098.87,
            "to": 4101.17,
            "location": 2,
            "content": " 到底有多少需要这种视频理解 "
        },
        {
            "from": 4101.3,
            "to": 4103.1,
            "location": 2,
            "content": " 但是我非常赞同Andrej Karpathy "
        },
        {
            "from": 4103.1,
            "to": 4105,
            "location": 2,
            "content": " 之前在twitter上说过的一句话 "
        },
        {
            "from": 4105.3,
            "to": 4105.8,
            "location": 2,
            "content": " 如果想 "
        },
        {
            "from": 4105.8,
            "to": 4108.13,
            "location": 2,
            "content": " 训练一个非常强大的这个视觉模型 "
        },
        {
            "from": 4108.47,
            "to": 4109.8,
            "location": 2,
            "content": " 拿视频数据做输入 "
        }
    ]
}